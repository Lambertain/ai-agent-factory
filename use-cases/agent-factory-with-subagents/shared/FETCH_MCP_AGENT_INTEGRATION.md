# ü§ñ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Fetch MCP —Å –∞–≥–µ–Ω—Ç–∞–º–∏ AI Agent Factory

## üéØ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–æ –∞–≥–µ–Ω—Ç–∞–º

–ü–æ—Å–ª–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Fetch MCP —Å –∫–∞–∂–¥—ã–º —Ç–∏–ø–æ–º –∞–≥–µ–Ω—Ç–∞ –≤ —Ñ–∞–±—Ä–∏–∫–µ.

## üîí Security Audit Agent

### –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
```python
@agent.tool
async def analyze_website_security(
    ctx: RunContext[SecurityAuditDependencies],
    target_url: str,
    scan_depth: str = "comprehensive"
) -> str:
    """–ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤–µ–±-—Å–∞–π—Ç–∞ —á–µ—Ä–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    result = await extract_web_content(
        url=target_url,
        content_type="documentation" if scan_depth == "comprehensive" else "lightweight",
        mcp_fetch_function=mcp__fetch__imageFetch
    )

    if not result["success"]:
        return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {result['error']}"

    content = result["content"]

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
    security_issues = []

    # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    if "password" in content.lower() and "form" in content.lower():
        security_issues.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ñ–æ—Ä–º—ã —Å –ø–∞—Ä–æ–ª—è–º–∏ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å HTTPS")

    if "admin" in content.lower() and "login" in content.lower():
        security_issues.append("–ù–∞–π–¥–µ–Ω—ã –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø")

    if "api" in content.lower() and "key" in content.lower():
        security_issues.append("–í–æ–∑–º–æ–∂–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ API –∫–ª—é—á–µ–π - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —ç–∫—Å–ø–æ–∑–∏—Ü–∏—é")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    headers_check = await extract_web_content(
        url=target_url,
        content_type="lightweight",
        custom_params={"maxLength": 500},
        mcp_fetch_function=mcp__fetch__imageFetch
    )

    return f"""
üîí –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {target_url}

üìä –°—Ç–∞—Ç—É—Å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {'‚úÖ –£—Å–ø–µ—à–Ω–æ' if result['success'] else '‚ùå –û—à–∏–±–∫–∞'}
üìÑ –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤

üö® –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:
{chr(10).join(f"- {issue}" for issue in security_issues) if security_issues else "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"}

üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å SSL/TLS —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã
- –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤
- –ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—ã–π –ø–µ–Ω—Ç–µ—Å—Ç –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Ö–æ–¥–æ–∫
"""

@agent.tool
async def scan_competitor_security(
    ctx: RunContext[SecurityAuditDependencies],
    competitor_urls: List[str]
) -> str:
    """–ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""

    security_analysis = await analyze_competitor_sites(
        urls=competitor_urls,
        mcp_fetch_function=mcp__fetch__imageFetch,
        focus_areas=["security", "privacy", "compliance"]
    )

    results = []
    for result in security_analysis["results"]:
        if result.get("success"):
            content = result["content"]

            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            security_mentions = []
            if "privacy policy" in content.lower():
                security_mentions.append("Privacy Policy")
            if "terms of service" in content.lower():
                security_mentions.append("Terms of Service")
            if "security" in content.lower():
                security_mentions.append("Security Information")
            if "gdpr" in content.lower():
                security_mentions.append("GDPR Compliance")

            results.append({
                "url": result["url"],
                "security_features": security_mentions,
                "compliance_indicators": len(security_mentions)
            })

    return f"""
üîç –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤:

üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
{chr(10).join(f"üåê {r['url']}: {', '.join(r['security_features']) or '–ù–µ —É–∫–∞–∑–∞–Ω–æ'}" for r in results)}

üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {sum(r['compliance_indicators'] for r in results) / len(results) if results else 0:.1f}

üí° –í—ã–≤–æ–¥—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è:
- –î–æ–±–∞–≤–∏—Ç—å —á–µ—Ç–∫—É—é –ø–æ–ª–∏—Ç–∏–∫—É –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏
- –†–∞–∑–º–µ—Å—Ç–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –Ω–∞ –≤–∏–¥–Ω–æ–º –º–µ—Å—Ç–µ
- –û–±–µ—Å–ø–µ—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º GDPR/CCPA
"""
```

## üîç RAG Agent

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–Ω–∞–Ω–∏–π:
```python
@agent.tool
async def research_web_knowledge(
    ctx: RunContext[RAGDependencies],
    research_query: str,
    sources: List[str],
    depth: str = "comprehensive"
) -> str:
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ –≤–µ–±-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è RAG."""

    research_results = await research_technical_topics(
        urls=sources,
        topic=research_query,
        mcp_fetch_function=mcp__fetch__imageFetch,
        depth=depth
    )

    # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –∑–Ω–∞–Ω–∏—è –¥–ª—è RAG
    knowledge_synthesis = []
    for result in research_results["research_results"]:
        knowledge_synthesis.append({
            "source": result["url"],
            "relevance": result["relevance_score"],
            "key_concepts": result["key_concepts"],
            "content_summary": result["content"][:500] + "..." if len(result["content"]) > 500 else result["content"]
        })

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    knowledge_synthesis.sort(key=lambda x: x["relevance"], reverse=True)

    return f"""
üß† –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π: {research_query}

üìö –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {research_results['sources_processed']}
‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π: {research_results['successful_extractions']}

üéØ –ù–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:
{chr(10).join(f"üìñ {k['source']} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {k['relevance']:.2f})" for k in knowledge_synthesis[:3])}

üí° –ö–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏:
{chr(10).join(research_results['synthesis']['key_findings'])}

üîÑ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è RAG:
- –î–æ–±–∞–≤–∏—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º–∏
"""

@agent.tool
async def update_knowledge_base_from_web(
    ctx: RunContext[RAGDependencies],
    topic_urls: Dict[str, List[str]],
    knowledge_tags: List[str]
) -> str:
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ –≤–µ–±-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤."""

    all_extractions = []

    for topic, urls in topic_urls.items():
        for url in urls:
            result = await extract_web_content(
                url=url,
                content_type="research",
                mcp_fetch_function=mcp__fetch__imageFetch
            )

            if result["success"]:
                all_extractions.append({
                    "topic": topic,
                    "url": url,
                    "content": result["content"],
                    "tags": knowledge_tags + [topic]
                })

    return f"""
üìö –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:

üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –¢–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(topic_urls)}
- –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(all_extractions)}
- –û–±—â–∏–π –æ–±—ä–µ–º –∑–Ω–∞–Ω–∏–π: {sum(len(e['content']) for e in all_extractions)} —Å–∏–º–≤–æ–ª–æ–≤

üè∑Ô∏è –¢–µ–≥–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {', '.join(knowledge_tags)}

üíæ –ì–æ—Ç–æ–≤–æ –∫ –∑–∞–≥—Ä—É–∑–∫–µ –≤ Archon Knowledge Base:
{chr(10).join(f"üìÑ {e['topic']}: {e['url'][:50]}..." for e in all_extractions[:5])}

{"...–∏ –µ—â–µ " + str(len(all_extractions) - 5) + " –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤" if len(all_extractions) > 5 else ""}
"""
```

## üé® UI/UX Enhancement Agent

### –î–∏–∑–∞–π–Ω-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ:
```python
@agent.tool
async def gather_ui_inspiration(
    ctx: RunContext[UIUXDependencies],
    design_categories: List[str],
    inspiration_urls: List[str] = None
) -> str:
    """–°–±–æ—Ä UI/UX –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è –µ—Å–ª–∏ URL –Ω–µ —É–∫–∞–∑–∞–Ω—ã
    if not inspiration_urls:
        inspiration_urls = [
            "https://dribbble.com",
            "https://unsplash.com",
            "https://www.behance.net"
        ]

    inspiration = await gather_design_inspiration(
        urls=inspiration_urls,
        mcp_fetch_function=mcp__fetch__imageFetch,
        design_categories=design_categories
    )

    return f"""
üé® –î–∏–∑–∞–π–Ω-–≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ —Å–æ–±—Ä–∞–Ω–æ:

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
- –°–∞–π—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {inspiration['successful_extractions']}
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {inspiration['summary']['total_images_saved']}
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(inspiration['categories'])}

üéØ –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:
{chr(10).join(f"‚Ä¢ {pattern}" for pattern in inspiration['summary']['design_patterns'])}

üí° –î–ª—è UI/UX –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è:
- –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ —Ü–≤–µ—Ç–æ–≤—ã–µ —Å—Ö–µ–º—ã
- –ú–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- –ú–∏–∫—Ä–æ–∞–Ω–∏–º–∞—Ü–∏–∏ –∏ –ø–µ—Ä–µ—Ö–æ–¥—ã

üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: C:\\Users\\Admin\\Downloads\\mcp-fetch\\{datetime.now().strftime('%Y-%m-%d')}\\
"""

@agent.tool
async def analyze_ui_accessibility(
    ctx: RunContext[UIUXDependencies],
    target_urls: List[str]
) -> str:
    """–ê–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤."""

    accessibility_analysis = []

    for url in target_urls:
        result = await extract_web_content(
            url=url,
            content_type="documentation",
            mcp_fetch_function=mcp__fetch__imageFetch
        )

        if result["success"]:
            content = result["content"]

            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç–µ–Ω—Ç
            accessibility_features = []

            if "alt=" in content:
                accessibility_features.append("Alt text –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            if "aria-" in content:
                accessibility_features.append("ARIA –∞—Ç—Ä–∏–±—É—Ç—ã")
            if "role=" in content:
                accessibility_features.append("–†–æ–ª–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            if "skip" in content.lower() and "content" in content.lower():
                accessibility_features.append("Skip links")

            accessibility_analysis.append({
                "url": url,
                "features": accessibility_features,
                "score": len(accessibility_features)
            })

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ñ—É–Ω–∫—Ü–∏–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
    accessibility_analysis.sort(key=lambda x: x["score"], reverse=True)

    return f"""
‚ôø –ê–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ UI:

üèÜ –õ–∏–¥–µ—Ä—ã –ø–æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏:
{chr(10).join(f"üåê {a['url']}: {a['score']} —Ñ—É–Ω–∫—Ü–∏–π" for a in accessibility_analysis[:3])}

üìã –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
{chr(10).join(f"‚Ä¢ {feature}" for a in accessibility_analysis for feature in a['features'])}

üìä –°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏: {sum(a['score'] for a in accessibility_analysis) / len(accessibility_analysis) if accessibility_analysis else 0:.1f}

üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –î–æ–±–∞–≤–∏—Ç—å alt –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å ARIA labels –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
- –î–æ–±–∞–≤–∏—Ç—å skip links –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
- –û–±–µ—Å–ø–µ—á–∏—Ç—å –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å —Ü–≤–µ—Ç–æ–≤
"""
```

## ‚ö° Performance Optimization Agent

### –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–µ–±-—Å–∞–π—Ç–æ–≤:
```python
@agent.tool
async def analyze_web_performance_patterns(
    ctx: RunContext[PerformanceDependencies],
    benchmark_urls: List[str],
    focus_metrics: List[str] = None
) -> str:
    """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —É –ª–∏–¥–µ—Ä–æ–≤ —Ä—ã–Ω–∫–∞."""

    if not focus_metrics:
        focus_metrics = ["loading", "images", "scripts", "css"]

    performance_insights = []

    for url in benchmark_urls:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        result = await extract_web_content(
            url=url,
            content_type="documentation",
            mcp_fetch_function=mcp__fetch__imageFetch
        )

        if result["success"]:
            content = result["content"]

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–µ—Ö–Ω–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            optimization_techniques = []

            if "lazy" in content.lower() and "load" in content.lower():
                optimization_techniques.append("Lazy loading")
            if "cache" in content.lower():
                optimization_techniques.append("Caching")
            if "compress" in content.lower() or "gzip" in content.lower():
                optimization_techniques.append("Compression")
            if "cdn" in content.lower():
                optimization_techniques.append("CDN usage")
            if "minif" in content.lower():
                optimization_techniques.append("Minification")

            performance_insights.append({
                "url": url,
                "techniques": optimization_techniques,
                "performance_score": len(optimization_techniques)
            })

    return f"""
‚ö° –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–µ–±-—Å–∞–π—Ç–æ–≤:

üéØ –§–æ–∫—É—Å –º–µ—Ç—Ä–∏–∫–∏: {', '.join(focus_metrics)}

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:
{chr(10).join(f"üåê {p['url']}: {p['performance_score']} —Ç–µ—Ö–Ω–∏–∫" for p in performance_insights)}

üõ†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
{chr(10).join(f"‚Ä¢ {tech}" for p in performance_insights for tech in p['techniques'])}

üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è:
- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å lazy loading –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CDN –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
- –ú–∏–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å CSS/JS —Ñ–∞–π–ª—ã
- –í–∫–ª—é—á–∏—Ç—å —Å–∂–∞—Ç–∏–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
"""

@agent.tool
async def benchmark_loading_strategies(
    ctx: RunContext[PerformanceDependencies],
    case_study_urls: List[str]
) -> str:
    """–ò–∑—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∑–∞–≥—Ä—É–∑–∫–∏ —É —É—Å–ø–µ—à–Ω—ã—Ö —Å–∞–π—Ç–æ–≤."""

    loading_strategies = await analyze_competitor_sites(
        urls=case_study_urls,
        mcp_fetch_function=mcp__fetch__imageFetch,
        focus_areas=["performance", "loading", "optimization"]
    )

    strategies_found = []
    for result in loading_strategies["results"]:
        if result.get("success"):
            content = result["content"]

            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∑–∞–≥—Ä—É–∑–∫–∏
            strategies = []
            if "critical" in content.lower() and "css" in content.lower():
                strategies.append("Critical CSS inline")
            if "async" in content.lower() or "defer" in content.lower():
                strategies.append("Async/Defer scripts")
            if "preload" in content.lower():
                strategies.append("Resource preloading")
            if "progressive" in content.lower():
                strategies.append("Progressive enhancement")

            strategies_found.extend(strategies)

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    strategy_frequency = {}
    for strategy in strategies_found:
        strategy_frequency[strategy] = strategy_frequency.get(strategy, 0) + 1

    return f"""
üìà –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∑–∞–≥—Ä—É–∑–∫–∏:

üîç –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–æ —Å–∞–π—Ç–æ–≤: {len(case_study_urls)}
‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤: {loading_strategies['successful_extractions']}

üìä –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:
{chr(10).join(f"‚Ä¢ {strategy}: {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π" for strategy, count in sorted(strategy_frequency.items(), key=lambda x: x[1], reverse=True))}

üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è:
1. Critical CSS inline (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1)
2. Async/Defer –¥–ª—è JavaScript
3. Preloading –∫–ª—é—á–µ–≤—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
4. Progressive enhancement

üìà –û–∂–∏–¥–∞–µ–º—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: 20-40%
"""
```

## üìä –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### üó£Ô∏è –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤:

**‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç):**
```
Agent: "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–µ –∏–∑ —Å–ø–∏—Å–∫–∞?"
```

**‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å task_communication_utils):**
```python
from shared.task_communication_utils import (
    TaskCommunicationFormatter,
    parse_archon_task_to_task_info,
    get_next_priority_task
)

# –í –∫–æ–Ω—Ü–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–æ–º
async def complete_task_and_transition():
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Archon
    archon_response = await mcp__archon__find_tasks(
        project_id="c75ef8e3-6f4d-4da2-9e81-8d38d04a341a",
        filter_by="status",
        filter_value="todo"
    )

    # –ù–∞—Ö–æ–¥–∏–º —Å–ª–µ–¥—É—é—â—É—é –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É
    next_task = get_next_priority_task(archon_response["tasks"])

    if next_task:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        prompt = TaskCommunicationFormatter.format_next_task_prompt(next_task)
        print(prompt)
        # –í—ã–≤–æ–¥: "–°–ª–µ–¥—É—é—â–∞—è –∑–∞–¥–∞—á–∞: '–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Puppeteer MCP' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç P1-High/task_order 77, Implementation Engineer). –ü—Ä–∏—Å—Ç—É–ø–∞—Ç—å?"
    else:
        print("üìã –í—Å–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!")
```

**–ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:**
```
‚úÖ "–°–ª–µ–¥—É—é—â–∞—è –∑–∞–¥–∞—á–∞: '–°–æ–∑–¥–∞—Ç—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ Security Audit Agent' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç P1-High/task_order 85, Implementation Engineer). –ü—Ä–∏—Å—Ç—É–ø–∞—Ç—å?"

‚úÖ "–°–ª–µ–¥—É—é—â–∞—è –∑–∞–¥–∞—á–∞: '–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å RAG –ø–æ–∏—Å–∫–∞' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç P2-Medium/task_order 65, Performance Optimization Agent). –ü—Ä–∏—Å—Ç—É–ø–∞—Ç—å?"

‚úÖ "–°–ª–µ–¥—É—é—â–∞—è –∑–∞–¥–∞—á–∞: '–î–æ–±–∞–≤–∏—Ç—å accessibility features –≤ UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç P1-High/task_order 78, UI/UX Enhancement Agent). –ü—Ä–∏—Å—Ç—É–ø–∞—Ç—å?"

‚ùå "–ö–∞–∫—É—é –∑–∞–¥–∞—á—É –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–ª–µ–¥—É—é—â–µ–π?"
‚ùå "–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –¥—Ä—É–≥–∏–º –∑–∞–¥–∞—á–∞–º?"
‚ùå "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É?"
```

### –ë–∞–∑–æ–≤—ã–π —à–∞–±–ª–æ–Ω –¥–ª—è –ª—é–±–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ —Å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏:
```python
from shared.fetch_mcp_utils import extract_web_content, FetchMCPOptimizer
from shared.task_communication_utils import (
    TaskCommunicationFormatter,
    parse_archon_task_to_task_info,
    get_next_priority_task,
    create_agent_task_communication_mixin
)

class AgentFetchIntegration:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Fetch MCP –≤ –∞–≥–µ–Ω—Ç—ã —Å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏."""

    def __init__(self, agent_type: str, archon_project_id: str = "c75ef8e3-6f4d-4da2-9e81-8d38d04a341a"):
        self.agent_type = agent_type
        self.archon_project_id = archon_project_id
        self.default_content_type = self._get_default_content_type()

    def _get_default_content_type(self) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –∞–≥–µ–Ω—Ç–∞."""
        mapping = {
            "security_audit": "documentation",
            "rag_agent": "research",
            "uiux_enhancement": "design_inspiration",
            "performance_optimization": "documentation",
            "typescript_architecture": "documentation"
        }
        return mapping.get(self.agent_type, "documentation")

    async def smart_web_extraction(
        self,
        url: str,
        purpose: str = "analysis",
        custom_params: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """–£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è."""

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—é
        content_type_mapping = {
            "security": "documentation",
            "research": "research",
            "design": "design_inspiration",
            "competitor": "competitor_analysis",
            "quick": "lightweight"
        }

        content_type = content_type_mapping.get(purpose, self.default_content_type)

        return await extract_web_content(
            url=url,
            content_type=content_type,
            custom_params=custom_params,
            mcp_fetch_function=mcp__fetch__imageFetch
        )

    async def get_next_task_formatted(self) -> str:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â—É—é –∑–∞–¥–∞—á—É –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –∫ —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–¥–∞—á–µ –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∑–∞–¥–∞—á
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ –∏–∑ Archon
            archon_response = await mcp__archon__find_tasks(
                project_id=self.archon_project_id,
                filter_by="status",
                filter_value="todo"
            )

            if not archon_response.get("success", False):
                return "‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á –∏–∑ Archon"

            # –ù–∞—Ö–æ–¥–∏–º —Å–ª–µ–¥—É—é—â—É—é –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É
            next_task = get_next_priority_task(archon_response.get("tasks", []))

            if next_task:
                return TaskCommunicationFormatter.format_next_task_prompt(next_task)
            else:
                return "üìã –í—Å–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!"

        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–¥–∞—á–∏: {e}"

    def format_task_completion_with_transition(self, completed_task_title: str) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ —Å –ø–µ—Ä–µ—Ö–æ–¥–æ–º –∫ —Å–ª–µ–¥—É—é—â–µ–π.

        Args:
            completed_task_title: –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∏ –ø–µ—Ä–µ—Ö–æ–¥–µ
        """
        return f"""‚úÖ **–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:** '{completed_task_title}'

üîÑ **–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ –∏–∑ Archon.
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ get_next_task_formatted() –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã."""

# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
@agent.tool
async def transition_to_next_task(
    ctx: RunContext[AgentDependencies],
    completed_task_title: str = ""
) -> str:
    """
    –ó–∞–≤–µ—Ä—à–∏—Ç—å —Ç–µ–∫—É—â—É—é –∑–∞–¥–∞—á—É –∏ –ø–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π.

    –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞.
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ –∏–∑ Archon
        archon_response = await mcp__archon__find_tasks(
            project_id=ctx.deps.archon_project_id,
            filter_by="status",
            filter_value="todo"
        )

        if not archon_response.get("success", False):
            return "‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á –∏–∑ Archon"

        # –ù–∞—Ö–æ–¥–∏–º —Å–ª–µ–¥—É—é—â—É—é –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É
        next_task = get_next_priority_task(archon_response.get("tasks", []))

        if next_task:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–µ—Ä–µ—Ö–æ–¥ —Å –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ–π (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)
            if completed_task_title:
                completed_task_info = TaskInfo(
                    id="completed",
                    title=completed_task_title,
                    assignee="Current Agent",
                    task_order=0,
                    status="done"
                )

                return TaskCommunicationFormatter.format_task_transition_announcement(
                    completed_task_info, next_task
                )
            else:
                # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –∫ —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–¥–∞—á–µ
                return TaskCommunicationFormatter.format_next_task_prompt(next_task)
        else:
            completion_msg = ""
            if completed_task_title:
                completion_msg = f"‚úÖ **–ó–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞–¥–∞—á–∞:** '{completed_task_title}'\n\n"

            return f"{completion_msg}üìã –í—Å–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!"

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–¥–∞—á–µ: {e}"
```

## üîÑ Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤:
```python
async def batch_web_analysis(
    urls: List[str],
    analysis_type: str,
    agent_context: str,
    max_concurrent: int = 3
) -> List[Dict[str, Any]]:
    """Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ URL —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏."""

    import asyncio
    from itertools import islice

    results = []

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
    def batched(iterable, batch_size):
        iterator = iter(iterable)
        while batch := list(islice(iterator, batch_size)):
            yield batch

    for url_batch in batched(urls, max_concurrent):
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        batch_tasks = [
            extract_web_content(
                url=url,
                content_type=analysis_type,
                mcp_fetch_function=mcp__fetch__imageFetch
            )
            for url in url_batch
        ]

        batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)

        for url, result in zip(url_batch, batch_results):
            if isinstance(result, Exception):
                results.append({
                    "url": url,
                    "success": False,
                    "error": str(result)
                })
            else:
                results.append({
                    "url": url,
                    "success": result.get("success", False),
                    "content": result.get("content", ""),
                    "analysis_type": analysis_type
                })

        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
        await asyncio.sleep(1)

    return results
```

## üìà –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø–æ –∞–≥–µ–Ω—Ç–∞–º:
- **Security Audit**: 90%+ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è, <5—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑
- **RAG Agent**: 95%+ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏, >15K —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å
- **UI/UX Enhancement**: 100% –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, <3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞ —Å–∞–π—Ç
- **Performance**: 85%+ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

---

*–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ v1.0*
*–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è*