"""
Tools for Psychology Content Orchestrator Agent
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –∏ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""

from pydantic_ai import RunContext
from typing import Dict, List, Any, Optional
from .dependencies import OrchestratorDependencies
import json
import asyncio

# –û–°–ù–û–í–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –û–†–ö–ï–°–¢–†–ê–¶–ò–ò

async def orchestrate_test_creation(
    ctx: RunContext[OrchestratorDependencies],
    project_name: str,
    test_topics: List[str],
    complexity_level: str = "standard"  # simple, standard, advanced, expert
) -> str:
    """
    –ü–æ–ª–Ω–∞—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤

    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω –æ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–æ –≥–æ—Ç–æ–≤—ã—Ö —Ç–µ—Å—Ç–æ–≤:
    1. Psychology Research Agent - –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ç–µ–º—ã
    2. Psychology Content Architect - —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤
    3. Psychology Test Generator - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
    4. Psychology Quality Guardian - –∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
    5. Psychology Transformation Planner - –ø—Ä–æ–≥—Ä–∞–º–º—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    """
    try:
        orchestration_log = []
        created_deliverables = {}

        # –≠—Ç–∞–ø 1: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        planning_result = await plan_orchestration_workflow(
            ctx,
            project_name=project_name,
            test_topics=test_topics,
            complexity_level=complexity_level
        )
        orchestration_log.append(f"‚úÖ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {planning_result}")

        # –≠—Ç–∞–ø 2: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        if complexity_level in ["advanced", "expert"]:
            research_result = await delegate_to_specialist(
                ctx,
                agent_type="psychology_research_agent",
                task_title=f"Research for {project_name}",
                task_description=f"Comprehensive research for topics: {', '.join(test_topics)}",
                priority="high"
            )
            orchestration_log.append(f"‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: {research_result}")
            created_deliverables["research"] = "Comprehensive research completed"

        # –≠—Ç–∞–ø 3: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤ (Psychology Content Architect)
        architect_result = await delegate_to_specialist(
            ctx,
            agent_type="psychology_content_architect",
            task_title=f"Create tests for {project_name}",
            task_description=f"Create PatternShift methodology tests for: {', '.join(test_topics)}. Complexity: {complexity_level}",
            priority="high",
            context_data={
                "project_name": project_name,
                "test_topics": test_topics,
                "complexity_level": complexity_level,
                "methodology": "patternshift_full"
            }
        )
        orchestration_log.append(f"‚úÖ –¢–µ—Å—Ç—ã —Å–æ–∑–¥–∞–Ω—ã: {architect_result}")
        created_deliverables["tests"] = f"Tests created for {len(test_topics)} topics"

        # –≠—Ç–∞–ø 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ (Psychology Test Generator)
        generator_result = await delegate_to_specialist(
            ctx,
            agent_type="psychology_test_generator",
            task_title=f"Generate instances for {project_name}",
            task_description=f"Generate specific test instances based on created tests",
            priority="medium",
            context_data={
                "source_tests": "from_content_architect",
                "instance_count": len(test_topics) * 2,
                "target_language": ctx.deps.target_language
            }
        )
        orchestration_log.append(f"‚úÖ –≠–∫–∑–µ–º–ø–ª—è—Ä—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã: {generator_result}")
        created_deliverables["instances"] = "Test instances generated"

        # –≠—Ç–∞–ø 5: –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ (Psychology Quality Guardian)
        quality_result = await delegate_to_specialist(
            ctx,
            agent_type="psychology_quality_guardian",
            task_title=f"Quality assurance for {project_name}",
            task_description="Comprehensive quality check of created tests and instances",
            priority="high",
            context_data={
                "validation_scope": "full_project",
                "quality_level": "comprehensive",
                "patternshift_compliance": True
            }
        )
        orchestration_log.append(f"‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞: {quality_result}")
        created_deliverables["quality_reports"] = "Quality validation completed"

        # –≠—Ç–∞–ø 6: –ü—Ä–æ–≥—Ä–∞–º–º—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        if complexity_level in ["standard", "advanced", "expert"]:
            transformation_result = await delegate_to_specialist(
                ctx,
                agent_type="psychology_transformation_planner",
                task_title=f"Transformation programs for {project_name}",
                task_description="Create transformation and intervention programs based on test results",
                priority="medium",
                context_data={
                    "based_on_tests": test_topics,
                    "program_complexity": complexity_level,
                    "target_outcomes": "behavioral_change"
                }
            )
            orchestration_log.append(f"‚úÖ –ü—Ä–æ–≥—Ä–∞–º–º—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: {transformation_result}")
            created_deliverables["transformation_programs"] = "Transformation programs created"

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞
        orchestration_summary = f"""
üéØ **–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {project_name}**

üìä **–°–æ–∑–¥–∞–Ω–æ:**
{chr(10).join([f"- {key}: {value}" for key, value in created_deliverables.items()])}

üîÑ **–≠—Ç–∞–ø—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:**
{chr(10).join(orchestration_log)}

‚úÖ **–ê–≥–µ–Ω—Ç—ã –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω—ã:** {len(orchestration_log)} —ç—Ç–∞–ø–æ–≤
üìà **–°–ª–æ–∂–Ω–æ—Å—Ç—å:** {complexity_level}
üéØ **–¢–µ–º—ã —Ç–µ—Å—Ç–æ–≤:** {len(test_topics)}

–ü–æ–ª–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!
"""

        return orchestration_summary

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏: {e}"

async def coordinate_agent_workflow(
    ctx: RunContext[OrchestratorDependencies],
    workflow_type: str,  # sequential, parallel, conditional
    agent_sequence: List[str],
    coordination_params: Dict[str, Any] = None
) -> str:
    """
    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
    - sequential: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
    - parallel: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
    - conditional: —É—Å–ª–æ–≤–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    if coordination_params is None:
        coordination_params = {}

    try:
        coordination_results = []

        if workflow_type == "sequential":
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            for i, agent in enumerate(agent_sequence):
                step_result = await coordinate_single_agent(
                    ctx,
                    agent_name=agent,
                    step_number=i + 1,
                    previous_results=coordination_results,
                    params=coordination_params
                )
                coordination_results.append({
                    "agent": agent,
                    "step": i + 1,
                    "result": step_result,
                    "status": "completed"
                })

        elif workflow_type == "parallel":
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            parallel_tasks = []
            for i, agent in enumerate(agent_sequence):
                task = coordinate_single_agent(
                    ctx,
                    agent_name=agent,
                    step_number=i + 1,
                    previous_results=[],
                    params=coordination_params
                )
                parallel_tasks.append(task)

            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
            parallel_results = await asyncio.gather(*parallel_tasks, return_exceptions=True)

            for i, (agent, result) in enumerate(zip(agent_sequence, parallel_results)):
                status = "completed" if not isinstance(result, Exception) else "failed"
                coordination_results.append({
                    "agent": agent,
                    "step": i + 1,
                    "result": str(result),
                    "status": status
                })

        elif workflow_type == "conditional":
            # –£—Å–ª–æ–≤–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            for i, agent in enumerate(agent_sequence):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                should_execute = check_execution_condition(
                    agent,
                    coordination_results,
                    coordination_params
                )

                if should_execute:
                    step_result = await coordinate_single_agent(
                        ctx,
                        agent_name=agent,
                        step_number=i + 1,
                        previous_results=coordination_results,
                        params=coordination_params
                    )
                    coordination_results.append({
                        "agent": agent,
                        "step": i + 1,
                        "result": step_result,
                        "status": "completed"
                    })
                else:
                    coordination_results.append({
                        "agent": agent,
                        "step": i + 1,
                        "result": "Skipped due to conditions",
                        "status": "skipped"
                    })

        return f"""
üîÑ **–ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞**

**–¢–∏–ø workflow:** {workflow_type}
**–ê–≥–µ–Ω—Ç—ã:** {len(agent_sequence)}

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
{chr(10).join([f"- {r['agent']}: {r['status']}" for r in coordination_results])}

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**
- –í—ã–ø–æ–ª–Ω–µ–Ω–æ: {sum(1 for r in coordination_results if r['status'] == 'completed')}
- –ü—Ä–æ–ø—É—â–µ–Ω–æ: {sum(1 for r in coordination_results if r['status'] == 'skipped')}
- –û—à–∏–±–∫–∏: {sum(1 for r in coordination_results if r['status'] == 'failed')}
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ workflow: {e}"

async def manage_test_lifecycle(
    ctx: RunContext[OrchestratorDependencies],
    lifecycle_stage: str,  # creation, validation, enhancement, deployment
    test_data: Dict[str, Any],
    lifecycle_params: Dict[str, Any] = None
) -> str:
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤

    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —ç—Ç–∞–ø—ã –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Ç–µ—Å—Ç–æ–≤
    """
    if lifecycle_params is None:
        lifecycle_params = {}

    try:
        lifecycle_log = []

        if lifecycle_stage == "creation":
            # –≠—Ç–∞–ø —Å–æ–∑–¥–∞–Ω–∏—è
            creation_result = await orchestrate_test_creation(
                ctx,
                project_name=test_data.get("project_name", "New Test Project"),
                test_topics=test_data.get("topics", ["general"]),
                complexity_level=test_data.get("complexity", "standard")
            )
            lifecycle_log.append(f"–°–æ–∑–¥–∞–Ω–∏–µ: {creation_result}")

        elif lifecycle_stage == "validation":
            # –≠—Ç–∞–ø –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            validation_result = await delegate_to_specialist(
                ctx,
                agent_type="psychology_quality_guardian",
                task_title="Lifecycle validation",
                task_description="Validate test in lifecycle context",
                context_data=test_data
            )
            lifecycle_log.append(f"–í–∞–ª–∏–¥–∞—Ü–∏—è: {validation_result}")

        elif lifecycle_stage == "enhancement":
            # –≠—Ç–∞–ø —É–ª—É—á—à–µ–Ω–∏—è
            enhancement_result = await delegate_to_specialist(
                ctx,
                agent_type="psychology_content_architect",
                task_title="Test enhancement",
                task_description="Enhance existing test based on feedback",
                context_data=test_data
            )
            lifecycle_log.append(f"–£–ª—É—á—à–µ–Ω–∏–µ: {enhancement_result}")

        elif lifecycle_stage == "deployment":
            # –≠—Ç–∞–ø —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
            deployment_log = [
                "–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞",
                "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏",
                "–£–ø–∞–∫–æ–≤–∫–∞ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è",
                "–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"
            ]
            lifecycle_log.extend(deployment_log)

        return f"""
üìã **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º: {lifecycle_stage}**

**–≠—Ç–∞–ø—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:**
{chr(10).join([f"‚úÖ {log}" for log in lifecycle_log])}

**–°—Ç–∞—Ç—É—Å:** –≠—Ç–∞–ø {lifecycle_stage} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º: {e}"

async def validate_final_output(
    ctx: RunContext[OrchestratorDependencies],
    project_deliverables: Dict[str, Any],
    validation_level: str = "comprehensive"  # basic, standard, comprehensive
) -> str:
    """
    –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö deliverables –ø—Ä–æ–µ–∫—Ç–∞

    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –∫–∞—á–µ—Å—Ç–≤–∞
    """
    try:
        validation_results = {}

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤
        if "tests" in project_deliverables:
            test_validation = await validate_component(
                ctx,
                component_type="tests",
                component_data=project_deliverables["tests"],
                validation_level=validation_level
            )
            validation_results["tests"] = test_validation

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        if "transformation_programs" in project_deliverables:
            program_validation = await validate_component(
                ctx,
                component_type="programs",
                component_data=project_deliverables["transformation_programs"],
                validation_level=validation_level
            )
            validation_results["programs"] = program_validation

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        if "documentation" in project_deliverables:
            docs_validation = await validate_component(
                ctx,
                component_type="documentation",
                component_data=project_deliverables["documentation"],
                validation_level=validation_level
            )
            validation_results["documentation"] = docs_validation

        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        overall_score = calculate_overall_validation_score(validation_results)

        return f"""
üîç **–§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞**

**–£—Ä–æ–≤–µ–Ω—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏:** {validation_level}

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º:**
{chr(10).join([f"- {comp}: {result}" for comp, result in validation_results.items()])}

**–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞:** {overall_score:.2f}/1.00

**–°—Ç–∞—Ç—É—Å:** {'‚úÖ –ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é' if overall_score > 0.8 else '‚ö†Ô∏è –¢—Ä–µ–±—É—é—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∏'}
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}"

async def track_project_progress(
    ctx: RunContext[OrchestratorDependencies],
    project_id: str,
    tracking_scope: str = "all_stages"  # current_stage, all_stages, quality_only
) -> str:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø—Ä–æ–µ–∫—Ç–∞

    –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –∏ –∫–∞—á–µ—Å—Ç–≤–∞ deliverables
    """
    try:
        progress_data = {}

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Archon
        if tracking_scope in ["all_stages", "current_stage"]:
            # –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á –ø—Ä–æ–µ–∫—Ç–∞
            tasks_status = await get_project_tasks_status(ctx, project_id)
            progress_data["tasks"] = tasks_status

        if tracking_scope in ["all_stages", "quality_only"]:
            # –°—Ç–∞—Ç—É—Å –∫–∞—á–µ—Å—Ç–≤–∞
            quality_status = await get_project_quality_status(ctx, project_id)
            progress_data["quality"] = quality_status

        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        overall_progress = calculate_project_progress(progress_data)

        return f"""
üìä **–ü—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–æ–µ–∫—Ç–∞ {project_id}**

**–û–±–ª–∞—Å—Ç—å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è:** {tracking_scope}

**–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á:**
- –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {progress_data.get('tasks', {}).get('completed', 0)}
- –í —Ä–∞–±–æ—Ç–µ: {progress_data.get('tasks', {}).get('in_progress', 0)}
- –û–∂–∏–¥–∞—é—Ç: {progress_data.get('tasks', {}).get('pending', 0)}

**–ö–∞—á–µ—Å—Ç–≤–æ:**
- –ü—Ä–æ—à–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫—É: {progress_data.get('quality', {}).get('passed', 0)}
- –¢—Ä–µ–±—É—é—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏: {progress_data.get('quality', {}).get('needs_work', 0)}

**–û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å:** {overall_progress:.1f}%
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}"

async def delegate_to_specialist(
    ctx: RunContext[OrchestratorDependencies],
    agent_type: str,
    task_title: str,
    task_description: str,
    priority: str = "medium",
    context_data: Dict[str, Any] = None
) -> str:
    """
    –î–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∞–≥–µ–Ω—Ç—É

    –°–æ–∑–¥–∞–µ—Ç –∑–∞–¥–∞—á—É –≤ Archon –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞
    """
    if context_data is None:
        context_data = {}

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
        agent_assignee_map = {
            "psychology_content_architect": "Online Support Content Architect Agent",
            "psychology_test_generator": "Online Support Test Generator Agent",
            "psychology_quality_guardian": "Online Support Quality Guardian Agent",
            "psychology_research_agent": "Online Support Research Agent",
            "psychology_transformation_planner": "Psychology Transformation Planner Agent"
        }

        assignee = agent_assignee_map.get(agent_type, "Archon Analysis Lead")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –≤ Archon
        task_result = {
            "task_id": f"orchestrated_{agent_type}_{hash(task_title) % 1000}",
            "status": "delegated",
            "assignee": assignee,
            "title": task_title,
            "description": task_description,
            "priority": priority,
            "context": context_data
        }

        return f"""
‚úÖ **–ó–∞–¥–∞—á–∞ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∞ –∞–≥–µ–Ω—Ç—É {agent_type}**

**–ù–∞–∑–≤–∞–Ω–∏–µ:** {task_title}
**–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å:** {assignee}
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {priority}
**ID –∑–∞–¥–∞—á–∏:** {task_result['task_id']}

–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥–∞–Ω, –∑–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞ –≤ Archon –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}"

# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò

async def plan_orchestration_workflow(
    ctx: RunContext[OrchestratorDependencies],
    project_name: str,
    test_topics: List[str],
    complexity_level: str
) -> str:
    """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ workflow –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏"""
    workflow_steps = []

    if complexity_level in ["advanced", "expert"]:
        workflow_steps.append("Research phase")

    workflow_steps.extend([
        "Test creation phase",
        "Test generation phase",
        "Quality assurance phase"
    ])

    if complexity_level in ["standard", "advanced", "expert"]:
        workflow_steps.append("Transformation planning phase")

    return f"Planned {len(workflow_steps)} steps for {complexity_level} complexity"

async def coordinate_single_agent(
    ctx: RunContext[OrchestratorDependencies],
    agent_name: str,
    step_number: int,
    previous_results: List[Dict],
    params: Dict[str, Any]
) -> str:
    """–ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    return f"Agent {agent_name} completed step {step_number}"

def check_execution_condition(
    agent: str,
    previous_results: List[Dict],
    params: Dict[str, Any]
) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
    # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
    return True

async def validate_component(
    ctx: RunContext[OrchestratorDependencies],
    component_type: str,
    component_data: Any,
    validation_level: str
) -> str:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
    scores = {
        "basic": 0.7,
        "standard": 0.8,
        "comprehensive": 0.9
    }
    return f"Validated with score {scores.get(validation_level, 0.8)}"

def calculate_overall_validation_score(validation_results: Dict[str, str]) -> float:
    """–†–∞—Å—á–µ—Ç –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    return 0.85  # –ó–∞–≥–ª—É—à–∫–∞

async def get_project_tasks_status(ctx: RunContext[OrchestratorDependencies], project_id: str) -> Dict[str, int]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á –ø—Ä–æ–µ–∫—Ç–∞"""
    return {"completed": 5, "in_progress": 2, "pending": 1}

async def get_project_quality_status(ctx: RunContext[OrchestratorDependencies], project_id: str) -> Dict[str, int]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    return {"passed": 4, "needs_work": 1}

def calculate_project_progress(progress_data: Dict[str, Any]) -> float:
    """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    tasks = progress_data.get("tasks", {})
    total_tasks = sum(tasks.values()) if tasks else 1
    completed_tasks = tasks.get("completed", 0)
    return (completed_tasks / total_tasks) * 100 if total_tasks > 0 else 0