"""
Psychology Content Orchestrator Agent
Агент-оркестратор для координации создания психологических тестов

Координирует работу всех агентов в цепочке создания психологических тестов:
- Psychology Content Architect (создание тестов)
- Psychology Test Generator (генерация конкретных экземпляров)
- Psychology Quality Guardian (проверка качества)
- Psychology Transformation Planner (программы трансформации)
"""

from pydantic_ai import Agent, RunContext
from pydantic_ai.models import Model
from .dependencies import OrchestratorDependencies, get_orchestrator_config
from .tools import (
    orchestrate_test_creation,
    coordinate_agent_workflow,
    manage_test_lifecycle,
    validate_final_output,
    track_project_progress,
    delegate_to_specialist
)
from .prompts import get_orchestrator_prompt
from .settings import OrchestratorSettings
from typing import Any, Dict, List, Optional

psychology_content_orchestrator = Agent(
    model='openai:gpt-4o',
    deps_type=OrchestratorDependencies,
    result_type=str,
    system_prompt=get_orchestrator_prompt,
    tools=[
        orchestrate_test_creation,
        coordinate_agent_workflow,
        manage_test_lifecycle,
        validate_final_output,
        track_project_progress,
        delegate_to_specialist
    ]
)

@psychology_content_orchestrator.system_prompt
def system_prompt(ctx: RunContext[OrchestratorDependencies]) -> str:
    """Системный промпт для оркестратора"""
    return get_orchestrator_prompt(
        orchestration_level=ctx.deps.orchestration_level,
        project_type=ctx.deps.project_type,
        target_language=ctx.deps.target_language,
        workflow_complexity=ctx.deps.workflow_complexity
    )

async def create_complete_psychology_project(
    project_name: str,
    project_description: str,
    test_topics: List[str],
    target_audience: str = "general",
    complexity_level: str = "standard",
    **kwargs
) -> Dict[str, Any]:
    """
    Создать полный проект психологических тестов с оркестрацией всех агентов

    Args:
        project_name: Название проекта
        project_description: Описание проекта и целей
        test_topics: Список тем для тестов (депрессия, тревога, стресс и т.д.)
        target_audience: Целевая аудитория
        complexity_level: Уровень сложности (simple, standard, advanced)
        **kwargs: Дополнительные параметры

    Returns:
        Полный проект с тестами, программами трансформации и отчетами
    """
    settings = OrchestratorSettings(
        project_name=project_name,
        project_description=project_description,
        test_topics=test_topics,
        target_audience=target_audience,
        complexity_level=complexity_level,
        **{k: v for k, v in kwargs.items() if hasattr(OrchestratorSettings, k)}
    )

    orchestrator_config = OrchestratorDependencies(
        project_type="psychology_testing",
        orchestration_level="full_pipeline",
        target_language=settings.target_language,
        workflow_complexity=complexity_level,
        agent_workflow=settings.get_agent_workflow(),
        quality_gates=settings.get_quality_gates(),
        project_specification={
            "name": project_name,
            "description": project_description,
            "topics": test_topics,
            "audience": target_audience,
            "complexity": complexity_level,
            "deliverables": settings.get_deliverables()
        },
        knowledge_tags=["psychology-content", "orchestration", "pydantic-ai"],
        agent_name="psychology_content_orchestrator"
    )

    # Полная оркестрация проекта
    result = await psychology_content_orchestrator.run(
        f"Orchestrate complete psychology project: {project_name}",
        deps=orchestrator_config
    )

    # Парсинг и структурирование результата
    orchestrated_project = parse_orchestration_result(result.data)

    return {
        "success": True,
        "project": orchestrated_project,
        "settings": settings.to_dict(),
        "metadata": {
            "project_name": project_name,
            "topics_count": len(test_topics),
            "agents_used": orchestrated_project.get("agents_involved", []),
            "deliverables": orchestrated_project.get("deliverables", {}),
            "orchestration_report": orchestrated_project.get("orchestration_log", [])
        },
        "message": "Psychology project orchestrated successfully"
    }

async def coordinate_existing_project(
    project_id: str,
    coordination_type: str = "quality_check",
    specific_agents: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    Координировать работу с существующим проектом

    Args:
        project_id: ID существующего проекта
        coordination_type: Тип координации (quality_check, enhancement, adaptation)
        specific_agents: Конкретные агенты для привлечения

    Returns:
        Результаты координации
    """
    coordination_config = OrchestratorDependencies(
        project_type="coordination",
        orchestration_level="targeted",
        workflow_complexity="medium",
        project_specification={
            "existing_project_id": project_id,
            "coordination_type": coordination_type,
            "target_agents": specific_agents or []
        },
        knowledge_tags=["psychology-content", "coordination", "project-management"],
        agent_name="psychology_content_orchestrator"
    )

    result = await psychology_content_orchestrator.run(
        f"Coordinate existing project {project_id} - {coordination_type}",
        deps=coordination_config
    )

    coordination_results = parse_coordination_result(result.data)

    return {
        "success": True,
        "coordination_results": coordination_results,
        "project_id": project_id,
        "coordination_type": coordination_type,
        "agents_involved": coordination_results.get("agents_used", []),
        "message": f"Project coordination completed: {coordination_type}"
    }

async def quality_orchestration(
    test_data: Dict[str, Any],
    quality_level: str = "comprehensive"
) -> Dict[str, Any]:
    """
    Оркестрация проверки качества тестов

    Args:
        test_data: Данные теста для проверки
        quality_level: Уровень проверки (basic, standard, comprehensive)

    Returns:
        Результаты проверки качества
    """
    quality_config = OrchestratorDependencies(
        project_type="quality_assurance",
        orchestration_level="quality_focused",
        workflow_complexity="high",
        project_specification={
            "test_for_validation": test_data,
            "quality_level": quality_level,
            "validation_criteria": [
                "patternshift_compliance",
                "clinical_accuracy",
                "vak_adaptations",
                "age_appropriateness",
                "language_quality"
            ]
        },
        knowledge_tags=["psychology-content", "quality-assurance", "validation"],
        agent_name="psychology_content_orchestrator"
    )

    result = await psychology_content_orchestrator.run(
        f"Quality orchestration for test validation - {quality_level}",
        deps=quality_config
    )

    quality_results = parse_quality_result(result.data)

    return {
        "success": True,
        "quality_assessment": quality_results,
        "quality_level": quality_level,
        "compliance_score": quality_results.get("overall_score", 0),
        "recommendations": quality_results.get("improvements", []),
        "message": "Quality orchestration completed"
    }

def parse_orchestration_result(result_text: str) -> Dict[str, Any]:
    """Парсинг результата полной оркестрации"""
    return {
        "project_info": extract_project_info(result_text),
        "tests_created": extract_tests_created(result_text),
        "transformation_programs": extract_transformation_programs(result_text),
        "agents_involved": extract_agents_involved(result_text),
        "deliverables": extract_deliverables(result_text),
        "orchestration_log": extract_orchestration_log(result_text),
        "quality_reports": extract_quality_reports(result_text)
    }

def parse_coordination_result(result_text: str) -> Dict[str, Any]:
    """Парсинг результата координации"""
    return {
        "coordination_summary": extract_coordination_summary(result_text),
        "agents_used": extract_agents_used(result_text),
        "task_assignments": extract_task_assignments(result_text),
        "progress_tracking": extract_progress_tracking(result_text),
        "issues_resolved": extract_issues_resolved(result_text)
    }

def parse_quality_result(result_text: str) -> Dict[str, Any]:
    """Парсинг результата проверки качества"""
    return {
        "overall_score": extract_quality_score(result_text),
        "patternshift_score": extract_patternshift_score(result_text),
        "clinical_accuracy": extract_clinical_accuracy(result_text),
        "vak_compliance": extract_vak_compliance(result_text),
        "improvements": extract_quality_improvements(result_text),
        "validation_details": extract_validation_details(result_text)
    }

# Вспомогательные функции извлечения данных
def extract_project_info(text: str) -> Dict[str, str]:
    return {"name": "Generated Psychology Project", "version": "1.0"}

def extract_tests_created(text: str) -> List[Dict[str, Any]]:
    return [{"topic": "Sample Test", "questions": 16, "status": "created"}]

def extract_transformation_programs(text: str) -> List[Dict[str, Any]]:
    return [{"program": "Sample Program", "steps": 7, "status": "planned"}]

def extract_agents_involved(text: str) -> List[str]:
    return ["Psychology Content Architect", "Psychology Test Generator"]

def extract_deliverables(text: str) -> Dict[str, Any]:
    return {"tests": 1, "programs": 1, "reports": 1}

def extract_orchestration_log(text: str) -> List[str]:
    return ["Orchestration started", "Agents coordinated", "Quality checks passed"]

def extract_quality_reports(text: str) -> List[Dict[str, Any]]:
    return [{"component": "tests", "quality_score": 0.85}]

def extract_coordination_summary(text: str) -> str:
    return "Coordination completed successfully"

def extract_agents_used(text: str) -> List[str]:
    return ["Content Architect", "Quality Guardian"]

def extract_task_assignments(text: str) -> List[Dict[str, str]]:
    return [{"task": "Quality Check", "agent": "Quality Guardian"}]

def extract_progress_tracking(text: str) -> Dict[str, float]:
    return {"overall_progress": 0.85, "quality_progress": 0.90}

def extract_issues_resolved(text: str) -> List[str]:
    return ["Quality issues addressed"]

def extract_quality_score(text: str) -> float:
    return 0.85

def extract_patternshift_score(text: str) -> float:
    return 0.90

def extract_clinical_accuracy(text: str) -> float:
    return 0.88

def extract_vak_compliance(text: str) -> float:
    return 0.92

def extract_quality_improvements(text: str) -> List[str]:
    return ["Improve VAK adaptations", "Enhance clinical references"]

def extract_validation_details(text: str) -> Dict[str, Any]:
    return {"methodology": "PatternShift", "compliance": True}

if __name__ == "__main__":
    import asyncio

    async def test_orchestrator():
        result = await create_complete_psychology_project(
            project_name="Stress Management Test Suite",
            project_description="Comprehensive stress assessment and management tools",
            test_topics=["stress", "burnout", "work_anxiety"],
            target_audience="working_professionals",
            complexity_level="advanced"
        )
        print("Проект оркестрирован:", result)

    asyncio.run(test_orchestrator())