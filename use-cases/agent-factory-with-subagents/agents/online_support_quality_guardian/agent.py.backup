"""
Psychology Quality Guardian Agent

Универсальный агент для контроля качества психологического контента.
Обеспечивает этическое соответствие, научную валидность и безопасность
психологических программ, тестов и интервенций.
"""

import asyncio
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Union
from pydantic_ai import Agent, RunContext
from pydantic_ai.messages import Message

from .settings import PsychologyQualityGuardianSettings, load_settings
from .providers import get_llm_model
from .dependencies import QualityGuardianDependencies
from .tools import (
    search_quality_guardian_knowledge,
    evaluate_ethical_compliance,
    assess_scientific_validity,
    analyze_content_safety,
    validate_psychometric_properties,
    check_cultural_sensitivity,
    generate_quality_report,
    create_improvement_recommendations
)
from .prompts import get_system_prompt


# Загрузка настроек
settings = load_settings()

# Создание агента с универсальной конфигурацией
psychology_quality_guardian_agent = Agent(
    model=get_llm_model(),
    deps_type=QualityGuardianDependencies,
    system_prompt=get_system_prompt(),
    tools=[
        search_quality_guardian_knowledge,
        evaluate_ethical_compliance,
        assess_scientific_validity,
        analyze_content_safety,
        validate_psychometric_properties,
        check_cultural_sensitivity,
        generate_quality_report,
        create_improvement_recommendations
    ]
)


@dataclass
class QualityEvaluationRequest:
    """Запрос на оценку качества психологического контента."""

    content_type: str  # "test", "intervention", "program", "assessment"
    content_data: Dict[str, Any]
    evaluation_scope: List[str]  # ["ethical", "scientific", "safety", "cultural"]
    target_population: str = "adults"
    domain: str = "general"
    standards_level: str = "standard"  # "basic", "standard", "comprehensive"

    def __post_init__(self):
        """Валидация параметров запроса."""
        valid_content_types = ["test", "intervention", "program", "assessment", "survey", "screening"]
        if self.content_type not in valid_content_types:
            raise ValueError(f"content_type должен быть одним из: {valid_content_types}")

        valid_scopes = ["ethical", "scientific", "safety", "cultural", "psychometric", "usability"]
        invalid_scopes = [scope for scope in self.evaluation_scope if scope not in valid_scopes]
        if invalid_scopes:
            raise ValueError(f"Недопустимые области оценки: {invalid_scopes}")


@dataclass
class ComplianceAuditRequest:
    """Запрос на аудит соответствия стандартам."""

    content_data: Dict[str, Any]
    compliance_standards: List[str]  # ["APA", "BPS", "ITC", "GDPR", "HIPAA"]
    audit_depth: str = "standard"  # "basic", "standard", "comprehensive"
    target_certification: Optional[str] = None

    def __post_init__(self):
        """Валидация стандартов соответствия."""
        valid_standards = ["APA", "BPS", "ITC", "GDPR", "HIPAA", "ISO27001", "RPA"]
        invalid_standards = [std for std in self.compliance_standards if std not in valid_standards]
        if invalid_standards:
            raise ValueError(f"Неподдерживаемые стандарты: {invalid_standards}")


@dataclass
class SafetyAssessmentRequest:
    """Запрос на оценку безопасности контента."""

    content_data: Dict[str, Any]
    risk_categories: List[str] = None  # ["psychological", "privacy", "technical", "ethical"]
    vulnerability_groups: List[str] = None  # ["children", "elderly", "clinical", "vulnerable"]
    severity_threshold: str = "medium"  # "low", "medium", "high"

    def __post_init__(self):
        """Установка значений по умолчанию."""
        if self.risk_categories is None:
            self.risk_categories = ["psychological", "privacy", "ethical"]
        if self.vulnerability_groups is None:
            self.vulnerability_groups = ["clinical", "vulnerable"]


async def evaluate_content_quality(
    request: QualityEvaluationRequest,
    dependencies: QualityGuardianDependencies
) -> Dict[str, Any]:
    """
    Комплексная оценка качества психологического контента.

    Args:
        request: Параметры запроса на оценку
        dependencies: Зависимости агента

    Returns:
        Детальный отчет о качестве с оценками и рекомендациями
    """

    # Формируем prompt для агента
    evaluation_prompt = f"""
    Проведи комплексную оценку качества психологического контента:

    **Тип контента:** {request.content_type}
    **Целевая популяция:** {request.target_population}
    **Домен:** {request.domain}
    **Области оценки:** {', '.join(request.evaluation_scope)}
    **Уровень стандартов:** {request.standards_level}

    **Контент для оценки:**
    {request.content_data}

    Выполни оценку по каждой указанной области и предоставь:
    1. Детальный анализ соответствия стандартам
    2. Выявленные проблемы и риски
    3. Конкретные рекомендации по улучшению
    4. Общую оценку качества с обоснованием
    """

    # Запуск агента
    result = await psychology_quality_guardian_agent.run(
        user_prompt=evaluation_prompt,
        deps=dependencies
    )

    return {
        "evaluation_request": request,
        "quality_assessment": result.data,
        "evaluation_metadata": {
            "timestamp": dependencies.get_current_timestamp(),
            "evaluator": "Psychology Quality Guardian Agent",
            "standards_version": dependencies.standards_version,
            "confidence_level": "high"
        }
    }


async def audit_compliance(
    request: ComplianceAuditRequest,
    dependencies: QualityGuardianDependencies
) -> Dict[str, Any]:
    """
    Аудит соответствия психологического контента установленным стандартам.

    Args:
        request: Параметры аудита соответствия
        dependencies: Зависимости агента

    Returns:
        Отчет об аудите с детализацией по каждому стандарту
    """

    compliance_prompt = f"""
    Проведи аудит соответствия психологического контента следующим стандартам:

    **Стандарты соответствия:** {', '.join(request.compliance_standards)}
    **Глубина аудита:** {request.audit_depth}
    **Целевая сертификация:** {request.target_certification or 'Не указана'}

    **Контент для аудита:**
    {request.content_data}

    Для каждого стандарта предоставь:
    1. Степень соответствия (%)
    2. Выполненные требования
    3. Нарушения и несоответствия
    4. Действия для достижения полного соответствия
    5. Приоритетность исправлений
    """

    result = await psychology_quality_guardian_agent.run(
        user_prompt=compliance_prompt,
        deps=dependencies
    )

    return {
        "audit_request": request,
        "compliance_report": result.data,
        "audit_metadata": {
            "timestamp": dependencies.get_current_timestamp(),
            "auditor": "Psychology Quality Guardian Agent",
            "standards_checked": request.compliance_standards,
            "audit_level": request.audit_depth
        }
    }


async def assess_content_safety(
    request: SafetyAssessmentRequest,
    dependencies: QualityGuardianDependencies
) -> Dict[str, Any]:
    """
    Оценка безопасности психологического контента для различных групп пользователей.

    Args:
        request: Параметры оценки безопасности
        dependencies: Зависимости агента

    Returns:
        Отчет по безопасности с оценкой рисков и мерами защиты
    """

    safety_prompt = f"""
    Проведи оценку безопасности психологического контента:

    **Категории рисков:** {', '.join(request.risk_categories)}
    **Уязвимые группы:** {', '.join(request.vulnerability_groups)}
    **Порог серьезности:** {request.severity_threshold}

    **Контент для оценки:**
    {request.content_data}

    Анализируй:
    1. Потенциальные психологические риски
    2. Риски для конфиденциальности
    3. Технические уязвимости
    4. Этические проблемы
    5. Меры защиты и минимизации рисков
    6. Протоколы действий при инцидентах
    """

    result = await psychology_quality_guardian_agent.run(
        user_prompt=safety_prompt,
        deps=dependencies
    )

    return {
        "safety_request": request,
        "safety_report": result.data,
        "safety_metadata": {
            "timestamp": dependencies.get_current_timestamp(),
            "assessor": "Psychology Quality Guardian Agent",
            "risk_level": dependencies.assess_overall_risk_level(result.data),
            "requires_review": dependencies.requires_expert_review(result.data)
        }
    }


async def batch_quality_evaluation(
    content_items: List[Dict[str, Any]],
    evaluation_parameters: Dict[str, Any],
    dependencies: QualityGuardianDependencies
) -> Dict[str, Any]:
    """
    Пакетная оценка качества множественного контента.

    Args:
        content_items: Список элементов контента для оценки
        evaluation_parameters: Общие параметры оценки
        dependencies: Зависимости агента

    Returns:
        Сводный отчет по всем элементам с общими рекомендациями
    """

    batch_results = []

    for i, content_item in enumerate(content_items):
        print(f"Оценка элемента {i+1}/{len(content_items)}: {content_item.get('name', f'Item_{i+1}')}")

        # Создаем запрос для каждого элемента
        request = QualityEvaluationRequest(
            content_type=content_item.get('type', 'assessment'),
            content_data=content_item,
            evaluation_scope=evaluation_parameters.get('scope', ['ethical', 'scientific', 'safety']),
            target_population=evaluation_parameters.get('population', 'adults'),
            domain=evaluation_parameters.get('domain', 'general'),
            standards_level=evaluation_parameters.get('standards_level', 'standard')
        )

        # Выполняем оценку
        result = await evaluate_content_quality(request, dependencies)
        batch_results.append(result)

        # Небольшая пауза между оценками
        await asyncio.sleep(1)

    # Генерируем сводный отчет
    summary_prompt = f"""
    Проанализируй результаты пакетной оценки качества {len(content_items)} элементов контента:

    **Параметры оценки:** {evaluation_parameters}
    **Результаты оценки:** {batch_results}

    Предоставь:
    1. Общую статистику качества
    2. Наиболее частые проблемы
    3. Лучшие практики из оцененного контента
    4. Приоритетные области для улучшения
    5. Рекомендации для всей коллекции контента
    """

    summary_result = await psychology_quality_guardian_agent.run(
        user_prompt=summary_prompt,
        deps=dependencies
    )

    return {
        "batch_evaluation": {
            "total_items": len(content_items),
            "evaluation_parameters": evaluation_parameters,
            "individual_results": batch_results,
            "summary_analysis": summary_result.data
        },
        "batch_metadata": {
            "timestamp": dependencies.get_current_timestamp(),
            "evaluator": "Psychology Quality Guardian Agent",
            "batch_id": dependencies.generate_batch_id(),
            "processing_time": dependencies.get_processing_time()
        }
    }


async def create_quality_improvement_plan(
    current_content: Dict[str, Any],
    quality_issues: List[Dict[str, Any]],
    target_standards: List[str],
    dependencies: QualityGuardianDependencies
) -> Dict[str, Any]:
    """
    Создание плана улучшения качества контента.

    Args:
        current_content: Текущий контент для улучшения
        quality_issues: Выявленные проблемы качества
        target_standards: Целевые стандарты для соответствия
        dependencies: Зависимости агента

    Returns:
        Детальный план улучшения с этапами и метриками
    """

    improvement_prompt = f"""
    Создай детальный план улучшения качества психологического контента:

    **Текущий контент:**
    {current_content}

    **Выявленные проблемы:**
    {quality_issues}

    **Целевые стандарты:**
    {', '.join(target_standards)}

    Разработай план, включающий:
    1. Приоритизированный список улучшений
    2. Пошаговые действия для каждого улучшения
    3. Необходимые ресурсы и экспертизу
    4. Временные рамки реализации
    5. Метрики успеха и критерии оценки
    6. Риски и mitigation стратегии
    7. Процедуры валидации улучшений
    """

    result = await psychology_quality_guardian_agent.run(
        user_prompt=improvement_prompt,
        deps=dependencies
    )

    return {
        "improvement_plan": result.data,
        "plan_metadata": {
            "timestamp": dependencies.get_current_timestamp(),
            "planner": "Psychology Quality Guardian Agent",
            "target_standards": target_standards,
            "issues_count": len(quality_issues),
            "estimated_complexity": dependencies.estimate_implementation_complexity(quality_issues)
        }
    }


# Экспорт основных функций
__all__ = [
    "psychology_quality_guardian_agent",
    "QualityEvaluationRequest",
    "ComplianceAuditRequest",
    "SafetyAssessmentRequest",
    "evaluate_content_quality",
    "audit_compliance",
    "assess_content_safety",
    "batch_quality_evaluation",
    "create_quality_improvement_plan"
]


if __name__ == "__main__":
    # Пример использования агента
    import json

    async def main():
        # Создание зависимостей
        deps = QualityGuardianDependencies(
            api_key="demo_key",
            domain_type="clinical",
            target_population="adults",
            quality_standards=["APA", "ethical_guidelines"]
        )

        # Пример оценки теста
        test_content = {
            "name": "Anxiety Assessment Scale",
            "type": "test",
            "questions": [
                {
                    "id": 1,
                    "text": "How often do you feel worried?",
                    "response_format": "frequency",
                    "scale": ["Never", "Rarely", "Sometimes", "Often", "Always"]
                }
            ],
            "scoring": {
                "method": "sum",
                "interpretation": "Higher scores indicate higher anxiety"
            }
        }

        request = QualityEvaluationRequest(
            content_type="test",
            content_data=test_content,
            evaluation_scope=["ethical", "scientific", "safety"],
            target_population="adults",
            domain="anxiety"
        )

        result = await evaluate_content_quality(request, deps)
        print(json.dumps(result, indent=2, ensure_ascii=False))

    # Запуск примера (закомментирован для production)
    # asyncio.run(main())