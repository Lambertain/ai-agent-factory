"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è Psychology Research Agent

–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π,
–∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–∞—É—á–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass
import json
import asyncio
from datetime import datetime
import re
import statistics

from pydantic_ai import RunContext
from pydantic import BaseModel, Field

from .dependencies import ResearchAgentDependencies


# ===== –ú–û–î–ï–õ–ò –î–ê–ù–ù–´–• =====

class StudyAnalysisRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."""
    study_data: Dict[str, Any] = Field(description="–î–∞–Ω–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    analysis_type: str = Field(description="–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞ (methodology, statistics, ethics, quality)")
    validation_level: str = Field(default="standard", description="–£—Ä–æ–≤–µ–Ω—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
    focus_areas: List[str] = Field(default_factory=list, description="–û–±–ª–∞—Å—Ç–∏ —Ñ–æ–∫—É—Å–∞ –∞–Ω–∞–ª–∏–∑–∞")


class LiteratureSearchRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã."""
    query: str = Field(description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    research_domain: str = Field(default="general", description="–î–æ–º–µ–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π")
    study_types: List[str] = Field(default_factory=list, description="–¢–∏–ø—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π")
    date_range: str = Field(default="last_5_years", description="–í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω")
    max_results: int = Field(default=50, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")


class StatisticalValidationRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é."""
    study_design: str = Field(description="–î–∏–∑–∞–π–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    sample_size: int = Field(description="–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏")
    statistical_methods: List[str] = Field(description="–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã")
    effect_sizes: List[float] = Field(default_factory=list, description="–†–∞–∑–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–æ–≤")
    power_analysis: Optional[Dict[str, Any]] = Field(default=None, description="–ê–Ω–∞–ª–∏–∑ –º–æ—â–Ω–æ—Å—Ç–∏")


class MethodologyAssessmentRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –æ—Ü–µ–Ω–∫—É –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏."""
    research_question: str = Field(description="–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å")
    study_design: str = Field(description="–î–∏–∑–∞–π–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    participants: Dict[str, Any] = Field(description="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—á–∞—Å—Ç–Ω–∏–∫–∞—Ö")
    procedures: Dict[str, Any] = Field(description="–ü—Ä–æ—Ü–µ–¥—É—Ä—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    measures: List[Dict[str, Any]] = Field(description="–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–µ—Ç–æ–¥–∏–∫–∏")


# ===== –û–°–ù–û–í–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ =====

async def search_research_knowledge(
    ctx: RunContext[ResearchAgentDependencies],
    query: str,
    research_domain: Optional[str] = None,
    match_count: int = 5
) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        research_domain: –î–æ–º–µ–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        match_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    Returns:
        –ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MCP Archon –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        from mcp__archon__rag_search_knowledge_base import rag_search_knowledge_base

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ç–µ–≥–∞–º–∏ –∞–≥–µ–Ω—Ç–∞
        enhanced_query = f"{query} {' '.join(ctx.deps.knowledge_tags)}"

        result = await rag_search_knowledge_base(
            query=enhanced_query,
            source_domain=ctx.deps.knowledge_domain,
            match_count=match_count
        )

        if result.get("success") and result.get("results"):
            knowledge = "\n".join([
                f"**{r['metadata'].get('title', '–î–æ–∫—É–º–µ–Ω—Ç')}:**\n{r['content']}"
                for r in result["results"]
            ])
            return f"üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π Psychology Research Agent:\n{knowledge}"
        else:
            # Fallback –ø–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏ –∞–≥–µ–Ω—Ç–∞
            fallback_result = await rag_search_knowledge_base(
                query=f"psychology research agent methodology {query}",
                match_count=3
            )

            if fallback_result.get("success") and fallback_result.get("results"):
                knowledge = "\n".join([
                    f"**{r['metadata'].get('title', '–î–æ–∫—É–º–µ–Ω—Ç')}:**\n{r['content']}"
                    for r in fallback_result["results"]
                ])
                return f"üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (–Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ fallback):\n{knowledge}"

            return f"""‚ö†Ô∏è **–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π**

üîç **–ó–∞–ø—Ä–æ—Å:** {query}
üìã **–¢–µ–≥–∏ –ø–æ–∏—Å–∫–∞:** {', '.join(ctx.deps.knowledge_tags)}
üéØ **–î–æ–º–µ–Ω:** {research_domain or ctx.deps.knowledge_domain}

üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
1. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –æ–±–ª–∞—Å—Ç–∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã: "RCT", "validity", "reliability", "effect size"
3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∏—Å–∫ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º: "CONSORT", "APA guidelines", "statistical power"

üõ†Ô∏è **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:**
- –ü–æ–∏—Å–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã —á–µ—Ä–µ–∑ search_literature()
- –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ validate_study_methodology()
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ validate_statistical_analysis()
"""

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π: {e}"


async def analyze_study_methodology(
    ctx: RunContext[ResearchAgentDependencies],
    request: MethodologyAssessmentRequest
) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.

    Args:
        request: –ó–∞–ø—Ä–æ—Å –Ω–∞ –æ—Ü–µ–Ω–∫—É –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏

    Returns:
        –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        model = ctx.deps.get_model_for_task("methodology_analysis", "complex")

        # –ü–æ–ª—É—á–∞–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        criteria = ctx.deps.get_validation_criteria()

        analysis_prompt = f"""
–ü—Ä–æ–≤–µ–¥–∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:

**–ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï:**
- –í–æ–ø—Ä–æ—Å: {request.research_question}
- –î–∏–∑–∞–π–Ω: {request.study_design}
- –£—á–∞—Å—Ç–Ω–∏–∫–∏: {json.dumps(request.participants, ensure_ascii=False, indent=2)}
- –ü—Ä–æ—Ü–µ–¥—É—Ä—ã: {json.dumps(request.procedures, ensure_ascii=False, indent=2)}
- –ú–µ—Ç–æ–¥–∏–∫–∏: {json.dumps(request.measures, ensure_ascii=False, indent=2)}

**–ö–†–ò–¢–ï–†–ò–ò –í–ê–õ–ò–î–ê–¶–ò–ò:**
{json.dumps(criteria, ensure_ascii=False, indent=2)}

**–î–û–ú–ï–ù:** {ctx.deps.research_domain}
**–£–†–û–í–ï–ù–¨ –í–ê–õ–ò–î–ê–¶–ò–ò:** {ctx.deps.validation_level}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –∞—Å–ø–µ–∫—Ç—ã:

1. **–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –î–ò–ó–ê–ô–ù–ê –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–û–ú–£ –í–û–ü–†–û–°–£**
   - –ê–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å –¥–∏–∑–∞–π–Ω–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å
   - –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –∏ –≤–Ω–µ—à–Ω—è—è –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
   - –ö–æ–Ω—Ç—Ä–æ–ª—å –º–µ—à–∞—é—â–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö

2. **–ö–ê–ß–ï–°–¢–í–û –í–´–ë–û–†–ö–ò**
   - –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ—â–Ω–æ—Å—Ç—å
   - –†–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ø—É–ª—è—Ü–∏–∏
   - –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∫–ª—é—á–µ–Ω–∏—è/–∏—Å–∫–ª—é—á–µ–Ω–∏—è

3. **–í–ê–õ–ò–î–ù–û–°–¢–¨ –ò–ó–ú–ï–†–ï–ù–ò–ô**
   - –ü—Å–∏—Ö–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ –º–µ—Ç–æ–¥–∏–∫
   - –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Ç–æ–¥–∏–∫ —Ü–µ–ª–µ–≤–æ–π –ø–æ–ø—É–ª—è—Ü–∏–∏

4. **–ü–†–û–¶–ï–î–£–†–ù–´–ï –ê–°–ü–ï–ö–¢–´**
   - –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ–¥—É—Ä
   - –ö–æ–Ω—Ç—Ä–æ–ª—å —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
   - –≠—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è

5. **–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –°–¢–ê–ù–î–ê–†–¢–ê–ú**
   - –°–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º ({', '.join(ctx.deps.reporting_standards)})
   - –≠—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ ({', '.join(ctx.deps.ethics_standards)})

–î–∞–π –æ—Ü–µ–Ω–∫—É –ø–æ 10-–±–∞–ª–ª—å–Ω–æ–π —à–∫–∞–ª–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Å–ø–µ–∫—Ç–∞ –∏ –æ–±—â—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é.
"""

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LLM
        from pydantic_ai import Agent

        analysis_agent = Agent(model)
        result = await analysis_agent.run(analysis_prompt)

        return f"""# –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

## –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
**–í–æ–ø—Ä–æ—Å:** {request.research_question}
**–î–∏–∑–∞–π–Ω:** {request.study_design}
**–î–æ–º–µ–Ω:** {ctx.deps.research_domain}

## –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
{result.data}

## –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
- **–î–æ–º–µ–Ω:** {ctx.deps.research_domain}
- **–£—Ä–æ–≤–µ–Ω—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏:** {ctx.deps.validation_level}
- **–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏:** {criteria.get('sample_size', '–Ω–µ —É–∫–∞–∑–∞–Ω')}
- **–°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏:** {', '.join(ctx.deps.reporting_standards)}

*–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º {model.__class__.__name__}*
"""

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏: {e}"


async def validate_statistical_analysis(
    ctx: RunContext[ResearchAgentDependencies],
    request: StatisticalValidationRequest
) -> str:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.

    Args:
        request: –ó–∞–ø—Ä–æ—Å –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é

    Returns:
        –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        model = ctx.deps.get_model_for_task("statistical_validation", "complex")

        # –ü—Ä–æ–≤–æ–¥–∏–º –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        basic_checks = _perform_basic_statistical_checks(request)

        validation_prompt = f"""
–ü—Ä–æ–≤–µ–¥–∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:

**–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ï –î–ê–ù–ù–´–ï:**
- –î–∏–∑–∞–π–Ω: {request.study_design}
- –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {request.sample_size}
- –ú–µ—Ç–æ–¥—ã: {', '.join(request.statistical_methods)}
- –†–∞–∑–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–æ–≤: {request.effect_sizes}
- –ê–Ω–∞–ª–∏–∑ –º–æ—â–Ω–æ—Å—Ç–∏: {json.dumps(request.power_analysis, ensure_ascii=False) if request.power_analysis else '–Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'}

**–ö–†–ò–¢–ï–†–ò–ò –í–ê–õ–ò–î–ê–¶–ò–ò:**
- –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –º–æ—â–Ω–æ—Å—Ç—å: {ctx.deps.min_power}
- –£—Ä–æ–≤–µ–Ω—å –∞–ª—å—Ñ–∞: {ctx.deps.alpha_level}
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞: {ctx.deps.min_effect_size}

**–ë–ê–ó–û–í–´–ï –ü–†–û–í–ï–†–ö–ò:**
{json.dumps(basic_checks, ensure_ascii=False, indent=2)}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:

1. **–ê–î–ï–ö–í–ê–¢–ù–û–°–¢–¨ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–• –ú–ï–¢–û–î–û–í**
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Ç–æ–¥–æ–≤ –¥–∏–∑–∞–π–Ω—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
   - –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π –º–µ—Ç–æ–¥–æ–≤
   - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ —Ç–µ—Å—Ç–æ–≤

2. **–ú–û–©–ù–û–°–¢–¨ –ò –†–ê–ó–ú–ï–† –í–´–ë–û–†–ö–ò**
   - –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏
   - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ—â–Ω–æ—Å—Ç—å
   - –ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

3. **–†–ê–ó–ú–ï–†–´ –≠–§–§–ï–ö–¢–û–í**
   - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
   - –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
   - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤

4. **–ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –°–†–ê–í–ù–ï–ù–ò–Ø**
   - –ö–æ–Ω—Ç—Ä–æ–ª—å —Å–µ–º–µ–π–Ω–æ–π –æ—à–∏–±–∫–∏ I —Ä–æ–¥–∞
   - –ü–æ–ø—Ä–∞–≤–∫–∏ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å
   - –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ vs. –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∞–Ω–∞–ª–∏–∑—ã

5. **–û–¢–ß–ï–¢–ù–û–°–¢–¨**
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º APA/CONSORT
   - –ü–æ–ª–Ω–æ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
   - –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏

–î–∞–π —Ä–µ–π—Ç–∏–Ω–≥ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (1-10) –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.
"""

        from pydantic_ai import Agent

        validation_agent = Agent(model)
        result = await validation_agent.run(validation_prompt)

        return f"""# –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

## –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- **–î–∏–∑–∞–π–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:** {request.study_design}
- **–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏:** {request.sample_size}
- **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã:** {', '.join(request.statistical_methods)}

## –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
{_format_basic_checks(basic_checks)}

## –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
{result.data}

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
{_generate_statistical_recommendations(basic_checks, ctx.deps)}

*–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º {model.__class__.__name__}*
"""

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}"


async def search_literature(
    ctx: RunContext[ResearchAgentDependencies],
    request: LiteratureSearchRequest
) -> str:
    """
    –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –Ω–∞—É—á–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã.

    Args:
        request: –ó–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–æ–≥–æ –æ–±–∑–æ—Ä–∞
        model = ctx.deps.get_model_for_task("literature_review", "standard")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–∏—Å–∫–∞
        search_strategy = ctx.deps.get_literature_search_strategy()

        search_prompt = f"""
–í—ã–ø–æ–ª–Ω–∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞—É—á–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:

**–ó–ê–ü–†–û–°:** {request.query}
**–î–û–ú–ï–ù:** {request.research_domain}
**–¢–ò–ü–´ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ô:** {', '.join(request.study_types) if request.study_types else '–≤—Å–µ —Ç–∏–ø—ã'}
**–í–†–ï–ú–ï–ù–ù–û–ô –î–ò–ê–ü–ê–ó–û–ù:** {request.date_range}
**–ú–ê–ö–°–ò–ú–£–ú –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:** {request.max_results}

**–°–¢–†–ê–¢–ï–ì–ò–Ø –ü–û–ò–°–ö–ê:**
{json.dumps(search_strategy, ensure_ascii=False, indent=2)}

**–ë–ê–ó–´ –î–ê–ù–ù–´–•:** {', '.join(ctx.deps.literature_search_databases)}

–í—ã–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

1. **–§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –ü–û–ò–°–ö–û–í–û–ì–û –ó–ê–ü–†–û–°–ê**
   - –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ —Å–∏–Ω–æ–Ω–∏–º—ã
   - –ë—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã
   - MeSH —Ç–µ—Ä–º–∏–Ω—ã (–¥–ª—è PubMed)
   - –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞

2. **–ö–†–ò–¢–ï–†–ò–ò –û–¢–ë–û–†–ê**
   - –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∫–ª—é—á–µ–Ω–∏—è
   - –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
   - –§–∏–ª—å—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞

3. **–ê–ù–ê–õ–ò–ó –õ–ò–¢–ï–†–ê–¢–£–†–´**
   - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
   - –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤
   - –ü—Ä–æ–±–µ–ª—ã –≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö
   - –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

4. **–°–ò–ù–¢–ï–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í**
   - –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
   - –ö–æ–Ω—Å–µ–Ω—Å—É—Å –∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
   - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
   - –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±—É–¥—É—â–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π

–ü—Ä–µ–¥—Å—Ç–∞–≤—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ —Å –æ—Ü–µ–Ω–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
"""

        from pydantic_ai import Agent

        search_agent = Agent(model)
        result = await search_agent.run(search_prompt)

        return f"""# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã

## –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
- **–ó–∞–ø—Ä–æ—Å:** {request.query}
- **–î–æ–º–µ–Ω:** {request.research_domain}
- **–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:** {', '.join(ctx.deps.literature_search_databases)}
- **–î–∏–∞–ø–∞–∑–æ–Ω:** {request.date_range}

## –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞
{_format_search_strategy(search_strategy)}

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
{result.data}

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏
{_generate_literature_recommendations(request, ctx.deps)}

*–ü–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º {model.__class__.__name__}*
"""

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã: {e}"


async def evaluate_study_quality(
    ctx: RunContext[ResearchAgentDependencies],
    study_data: Dict[str, Any],
    assessment_framework: str = "custom"
) -> str:
    """
    –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.

    Args:
        study_data: –î–∞–Ω–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        assessment_framework: –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ—Ü–µ–Ω–∫–∏

    Returns:
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        model = ctx.deps.get_model_for_task("methodology_analysis", "complex")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ—Ü–µ–Ω–∫–∏
        framework_criteria = _get_quality_assessment_framework(
            assessment_framework,
            ctx.deps.research_domain
        )

        quality_prompt = f"""
–ü—Ä–æ–≤–µ–¥–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—è {assessment_framework} –∫—Ä–∏—Ç–µ—Ä–∏–∏:

**–î–ê–ù–ù–´–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**
{json.dumps(study_data, ensure_ascii=False, indent=2)}

**–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:**
{json.dumps(framework_criteria, ensure_ascii=False, indent=2)}

**–î–û–ú–ï–ù:** {ctx.deps.research_domain}
**–£–†–û–í–ï–ù–¨ –í–ê–õ–ò–î–ê–¶–ò–ò:** {ctx.deps.validation_level}

–û—Ü–µ–Ω–∏ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º:

1. **–î–ò–ó–ê–ô–ù –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø** (0-10 –±–∞–ª–ª–æ–≤)
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–∏–∑–∞–π–Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Ü–µ–ª—è–º
   - –ö–æ–Ω—Ç—Ä–æ–ª—å —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
   - –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å

2. **–£–ß–ê–°–¢–ù–ò–ö–ò** (0-10 –±–∞–ª–ª–æ–≤)
   - –ê–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏
   - –†–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
   - –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤—ã–±–æ—Ä–∫–∏

3. **–ò–ó–ú–ï–†–ï–ù–ò–Ø** (0-10 –±–∞–ª–ª–æ–≤)
   - –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
   - –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–π
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ–ø—É–ª—è—Ü–∏–∏

4. **–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó** (0-10 –±–∞–ª–ª–æ–≤)
   - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤
   - –ö–æ–Ω—Ç—Ä–æ–ª—å –æ—à–∏–±–æ–∫
   - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

5. **–≠–¢–ò–ß–ï–°–ö–ò–ï –ê–°–ü–ï–ö–¢–´** (0-10 –±–∞–ª–ª–æ–≤)
   - –û–¥–æ–±—Ä–µ–Ω–∏–µ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–∏—Ç–µ—Ç–æ–≤
   - –ò–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ
   - –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫–æ–≤

6. **–û–¢–ß–ï–¢–ù–û–°–¢–¨** (0-10 –±–∞–ª–ª–æ–≤)
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
   - –ü–æ–ª–Ω–æ—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
   - –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å

–î–∞–π –æ–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞, –≤—ã–¥–µ–ª–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è.
"""

        from pydantic_ai import Agent

        quality_agent = Agent(model)
        result = await quality_agent.run(quality_prompt)

        return f"""# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

## –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –æ—Ü–µ–Ω–∫–∏
**–§—Ä–µ–π–º–≤–æ—Ä–∫:** {assessment_framework}
**–î–æ–º–µ–Ω:** {ctx.deps.research_domain}
**–ö—Ä–∏—Ç–µ—Ä–∏–∏:** {len(framework_criteria)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
{result.data}

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
{_generate_quality_improvement_recommendations(study_data, ctx.deps)}

## –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
{_check_standards_compliance(study_data, ctx.deps)}

*–û—Ü–µ–Ω–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º {model.__class__.__name__}*
"""

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {e}"


async def perform_meta_analysis_planning(
    ctx: RunContext[ResearchAgentDependencies],
    research_question: str,
    inclusion_criteria: List[str],
    databases: List[str] = None
) -> str:
    """
    –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–∑–æ—Ä–∞.

    Args:
        research_question: –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å
        inclusion_criteria: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∫–ª—é—á–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
        databases: –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞

    Returns:
        –ü–ª–∞–Ω –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        model = ctx.deps.get_model_for_task("methodology_analysis", "critical")

        databases = databases or ctx.deps.literature_search_databases

        planning_prompt = f"""
–†–∞–∑—Ä–∞–±–æ—Ç–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞/—Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–∑–æ—Ä–∞:

**–ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –í–û–ü–†–û–°:** {research_question}
**–ö–†–ò–¢–ï–†–ò–ò –í–ö–õ–Æ–ß–ï–ù–ò–Ø:** {', '.join(inclusion_criteria)}
**–ë–ê–ó–´ –î–ê–ù–ù–´–•:** {', '.join(databases)}
**–î–û–ú–ï–ù:** {ctx.deps.research_domain}

–°–æ–∑–¥–∞–π –ø–ª–∞–Ω –ø–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:

1. **–ü–†–û–¢–û–ö–û–õ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø**
   - –§–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ (PICOS)
   - –ü–µ—Ä–≤–∏—á–Ω—ã–µ –∏ –≤—Ç–æ—Ä–∏—á–Ω—ã–µ –∏—Å—Ö–æ–¥—ã
   - –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∫–ª—é—á–µ–Ω–∏—è –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
   - –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞

2. **–ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –ü–û–ò–°–ö–ê**
   - –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ —Å–∏–Ω–æ–Ω–∏–º—ã
   - –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
   - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
   - –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏

3. **–û–¢–ë–û–† –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ô**
   - –ü—Ä–æ—Ü–µ–¥—É—Ä–∞ —Å–∫—Ä–∏–Ω–∏–Ω–≥–∞
   - –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
   - –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π
   - –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞

4. **–ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–ê–ù–ù–´–•**
   - –§–æ—Ä–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
   - –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
   - –ö–æ–Ω—Ç–∞–∫—Ç —Å –∞–≤—Ç–æ—Ä–∞–º–∏
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏

5. **–û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê**
   - –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
   - –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤
   - –ù–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –æ—Ü–µ–Ω—â–∏–∫–∏
   - –ö–æ–Ω—Å–µ–Ω—Å—É—Å-–ø—Ä–æ—Ü–µ–¥—É—Ä—ã

6. **–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó**
   - –ú–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–∞
   - –ú–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ/—Å–ª—É—á–∞–π–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã)
   - –ê–Ω–∞–ª–∏–∑ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω–æ—Å—Ç–∏
   - –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–≥—Ä—É–ø–ø

7. **–ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í**
   - –ö–ª–∏–Ω–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
   - –î–æ–≤–µ—Ä–∏–µ –∫ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º (GRADE)
   - –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
   - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–í–∫–ª—é—á–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞.
"""

        from pydantic_ai import Agent

        planning_agent = Agent(model)
        result = await planning_agent.run(planning_prompt)

        return f"""# –ü–ª–∞–Ω –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞ / —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–∑–æ—Ä–∞

## –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å
{research_question}

## –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
{result.data}

## –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
{_generate_meta_analysis_checkpoints(ctx.deps)}

## –†–µ—Å—É—Ä—Å—ã –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
{_list_meta_analysis_resources()}

*–ü–ª–∞–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º {model.__class__.__name__}*
"""

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞: {e}"


# ===== –ö–û–õ–õ–ï–ö–¢–ò–í–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ =====

async def break_down_to_microtasks(
    ctx: RunContext[ResearchAgentDependencies],
    main_task: str,
    complexity_level: str = "medium"
) -> str:
    """
    –†–∞–∑–±–∏—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –∑–∞–¥–∞—á—É –Ω–∞ –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏.

    Args:
        main_task: –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞
        complexity_level: –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

    Returns:
        –°–ø–∏—Å–æ–∫ –º–∏–∫—Ä–æ–∑–∞–¥–∞—á –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    """
    if complexity_level == "simple":
        microtasks = [
            f"–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ —Ç–µ–º–µ: {main_task}",
            f"–ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π",
            f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
            f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"
        ]
    elif complexity_level == "medium":
        microtasks = [
            f"–ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏: {main_task}",
            f"–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤",
            f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –¥–æ–º–µ–Ω–∞ {ctx.deps.research_domain}",
            f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
            f"–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)",
            f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è",
            f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
            f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏"
        ]
    else:  # complex
        microtasks = [
            f"–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {main_task}",
            f"–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–æ–≤",
            f"–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ–Ω–∏–º—ã—Ö –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤",
            f"–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏ –¥—Ä—É–≥–∏—Ö –¥–æ–º–µ–Ω–æ–≤",
            f"–î–µ—Ç–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤",
            f"–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —ç—Ç–∏—á–µ—Å–∫–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞",
            f"–û—Ü–µ–Ω–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –∏ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏",
            f"–ê–Ω–∞–ª–∏–∑ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏",
            f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ä–µ—Ñ–ª–µ–∫—Å–∏—è –∏ peer review",
            f"–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è"
        ]

    output = "üìã **–ú–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏ –¥–ª—è Psychology Research Agent:**\n"
    for i, task in enumerate(microtasks, 1):
        output += f"{i}. {task}\n"
    output += f"\nüéØ **–î–æ–º–µ–Ω:** {ctx.deps.research_domain}\n"
    output += f"üìä **–£—Ä–æ–≤–µ–Ω—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏:** {ctx.deps.validation_level}\n"
    output += "\n‚úÖ –ë—É–¥—É –æ—Ç—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –∫–∞–∂–¥–æ–π –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏"

    return output


async def delegate_task_to_agent(
    ctx: RunContext[ResearchAgentDependencies],
    target_agent: str,
    task_title: str,
    task_description: str,
    priority: str = "medium",
    context_data: Dict[str, Any] = None
) -> str:
    """
    –î–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É –¥—Ä—É–≥–æ–º—É —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∞–≥–µ–Ω—Ç—É.

    Args:
        target_agent: –¶–µ–ª–µ–≤–æ–π –∞–≥–µ–Ω—Ç
        task_title: –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        task_description: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–¥–∞—á–∏
        context_data: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    try:
        # –ö–∞—Ä—Ç–∞ –∞–≥–µ–Ω—Ç–æ–≤
        agent_map = {
            "quality_guardian": "Psychology Quality Guardian Agent",
            "security_audit": "Security Audit Agent",
            "uiux_enhancement": "Archon UI/UX Designer",
            "performance_optimization": "Performance Optimization Agent"
        }

        assignee = agent_map.get(target_agent, "Archon Analysis Lead")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –≤ Archon
        from mcp__archon__manage_task import manage_task

        result = await manage_task(
            action="create",
            project_id=ctx.deps.archon_project_id,
            title=task_title,
            description=f"{task_description}\n\n**–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç Psychology Research Agent:**\n{json.dumps(context_data, ensure_ascii=False, indent=2) if context_data else '–ù–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞'}",
            assignee=assignee,
            status="todo",
            feature=f"–î–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç research_agent",
            task_order=50
        )

        return f"""‚úÖ **–ó–∞–¥–∞—á–∞ —É—Å–ø–µ—à–Ω–æ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∞ –∞–≥–µ–Ω—Ç—É {target_agent}**

üìã **–î–µ—Ç–∞–ª–∏ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:**
- **–ó–∞–¥–∞—á–∞ ID:** {result.get('task', {}).get('id', '–Ω–µ —É–∫–∞–∑–∞–Ω')}
- **–ù–∞–∑–Ω–∞—á–µ–Ω:** {assignee}
- **–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {priority}
- **–°—Ç–∞—Ç—É—Å:** —Å–æ–∑–¥–∞–Ω–∞ –≤ Archon

üîÑ **–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
- –ê–≥–µ–Ω—Ç {target_agent} –ø–æ–ª—É—á–∏—Ç –∑–∞–¥–∞—á—É –≤ Archon
- –†–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É Archon
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
"""

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}"


async def check_delegation_need(
    ctx: RunContext[ResearchAgentDependencies],
    current_task: str,
    current_agent_type: str = "research_agent"
) -> str:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–¥–∞—á–∏.

    Args:
        current_task: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏
        current_agent_type: –¢–∏–ø —Ç–µ–∫—É—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞

    Returns:
        –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—é
    """
    keywords = current_task.lower().split()
    suggestions = []

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤
    quality_keywords = ['–∫–∞—á–µ—Å—Ç–≤–æ', 'quality', '–≤–∞–ª–∏–¥–∞—Ü–∏—è', 'compliance', '—Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã']
    security_keywords = ['–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', 'security', 'privacy', 'data protection', 'gdpr']
    ui_keywords = ['–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å', 'ui', 'ux', '–¥–∏–∑–∞–π–Ω', '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å']
    performance_keywords = ['–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', 'performance', 'optimization']

    if any(kw in keywords for kw in quality_keywords) and 'research' not in keywords:
        suggestions.append("Psychology Quality Guardian Agent - –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞")

    if any(kw in keywords for kw in security_keywords):
        suggestions.append("Security Audit Agent - –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö")

    if any(kw in keywords for kw in ui_keywords):
        suggestions.append("UI/UX Enhancement Agent - –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏")

    if any(kw in keywords for kw in performance_keywords):
        suggestions.append("Performance Optimization Agent - –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

    if suggestions:
        result = "ü§ù **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:**\n"
        for suggestion in suggestions:
            result += f"- {suggestion}\n"
        result += "\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ delegate_task_to_agent() –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–¥–∞—á."
    else:
        result = "‚úÖ –ó–∞–¥–∞—á–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã."

    return result


# ===== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò =====

def _perform_basic_statistical_checks(request: StatisticalValidationRequest) -> Dict[str, Any]:
    """–í—ã–ø–æ–ª–Ω–∏—Ç—å –±–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏."""
    checks = {
        "sample_size_adequate": request.sample_size >= 30,
        "effect_sizes_provided": len(request.effect_sizes) > 0,
        "power_analysis_provided": request.power_analysis is not None,
        "multiple_methods": len(request.statistical_methods) > 1,
        "effect_size_magnitude": "not_assessed"
    }

    if request.effect_sizes:
        avg_effect = statistics.mean(request.effect_sizes)
        if avg_effect >= 0.8:
            checks["effect_size_magnitude"] = "large"
        elif avg_effect >= 0.5:
            checks["effect_size_magnitude"] = "medium"
        elif avg_effect >= 0.2:
            checks["effect_size_magnitude"] = "small"
        else:
            checks["effect_size_magnitude"] = "trivial"

    return checks


def _format_basic_checks(checks: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–∞–∑–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫."""
    status_map = {True: "‚úÖ", False: "‚ùå"}

    formatted = []
    for key, value in checks.items():
        if isinstance(value, bool):
            formatted.append(f"{status_map[value]} {key.replace('_', ' ').title()}")
        else:
            formatted.append(f"üìä {key.replace('_', ' ').title()}: {value}")

    return "\n".join(formatted)


def _generate_statistical_recommendations(
    checks: Dict[str, Any],
    deps: ResearchAgentDependencies
) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É."""
    recommendations = []

    if not checks.get("sample_size_adequate"):
        recommendations.append("üî¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∞–¥–µ–∫–≤–∞—Ç–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –º–æ—â–Ω–æ—Å—Ç–∏")

    if not checks.get("effect_sizes_provided"):
        recommendations.append("üìä –î–æ–±–∞–≤—å—Ç–µ —Ä–∞—Å—á–µ—Ç –∏ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏")

    if not checks.get("power_analysis_provided"):
        recommendations.append("‚ö° –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –º–æ—â–Ω–æ—Å—Ç–∏ a priori –∏–ª–∏ post hoc")

    if checks.get("effect_size_magnitude") == "trivial":
        recommendations.append("‚ö†Ô∏è –†–∞–∑–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –º–∞–ª—ã - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

    return "\n".join(recommendations) if recommendations else "‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –±–∞–∑–æ–≤—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º"


def _format_search_strategy(strategy: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã."""
    formatted = []
    for key, value in strategy.items():
        if isinstance(value, list):
            formatted.append(f"**{key.replace('_', ' ').title()}:** {', '.join(value)}")
        elif isinstance(value, dict):
            formatted.append(f"**{key.replace('_', ' ').title()}:** {json.dumps(value, ensure_ascii=False)}")
        else:
            formatted.append(f"**{key.replace('_', ' ').title()}:** {value}")

    return "\n".join(formatted)


def _generate_literature_recommendations(
    request: LiteratureSearchRequest,
    deps: ResearchAgentDependencies
) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–æ–º—É –ø–æ–∏—Å–∫—É."""
    recommendations = [
        f"üîç –†–∞—Å—à–∏—Ä—å—Ç–µ –ø–æ–∏—Å–∫ –≤–∫–ª—é—á–µ–Ω–∏–µ–º {', '.join(deps.literature_search_databases)}",
        f"üìÖ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã –æ–±–∑–æ—Ä–∞",
        f"üåê –í–∫–ª—é—á–∏—Ç–µ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –∫—É–ª—å—Ç—É—Ä–Ω–æ–π –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏",
        f"üìä –§–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ {deps.methodology_focus} –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö –¥–ª—è {deps.research_domain} –¥–æ–º–µ–Ω–∞"
    ]

    return "\n".join(recommendations)


def _get_quality_assessment_framework(framework: str, domain: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞."""
    frameworks = {
        "custom": {
            "design_quality": ["randomization", "blinding", "control_group"],
            "sample_quality": ["size", "representativeness", "attrition"],
            "measurement_quality": ["validity", "reliability", "standardization"],
            "analysis_quality": ["appropriate_methods", "effect_sizes", "confidence_intervals"],
            "reporting_quality": ["transparency", "completeness", "reproducibility"]
        },
        "cochrane": {
            "selection_bias": ["randomization", "allocation_concealment"],
            "performance_bias": ["blinding_participants", "blinding_personnel"],
            "detection_bias": ["blinding_outcomes"],
            "attrition_bias": ["incomplete_data"],
            "reporting_bias": ["selective_reporting"],
            "other_bias": ["other_sources"]
        }
    }

    return frameworks.get(framework, frameworks["custom"])


def _generate_quality_improvement_recommendations(
    study_data: Dict[str, Any],
    deps: ResearchAgentDependencies
) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞."""
    recommendations = [
        f"üìã –°–ª–µ–¥—É–π—Ç–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏: {', '.join(deps.reporting_standards)}",
        f"üî¢ –û–±–µ—Å–ø–µ—á—å—Ç–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {deps.min_sample_size}",
        f"üìä –í–∫–ª—é—á–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ (–º–∏–Ω–∏–º—É–º {deps.min_effect_size})",
        f"‚ö° –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –º–æ—â–Ω–æ—Å—Ç–∏ (–º–∏–Ω–∏–º—É–º {deps.min_power})",
        f"üîí –û–±–µ—Å–ø–µ—á—å—Ç–µ —Å–æ–±–ª—é–¥–µ–Ω–∏–µ —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤: {', '.join(deps.ethics_standards)}"
    ]

    return "\n".join(recommendations)


def _check_standards_compliance(
    study_data: Dict[str, Any],
    deps: ResearchAgentDependencies
) -> str:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º."""
    compliance_check = []

    for standard in deps.reporting_standards:
        compliance_check.append(f"üìã {standard}: —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —á–µ–∫-–ª–∏—Å—Ç—É")

    for standard in deps.ethics_standards:
        compliance_check.append(f"üîí {standard}: —Ç—Ä–µ–±—É–µ—Ç —ç—Ç–∏—á–µ—Å–∫–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã")

    return "\n".join(compliance_check)


def _generate_meta_analysis_checkpoints(deps: ResearchAgentDependencies) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –¥–ª—è –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞."""
    checkpoints = [
        "üìã –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –≤ PROSPERO –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–º —Ä–µ–µ—Å—Ç—Ä–µ",
        "üîç –ù–µ–∑–∞–≤–∏—Å–∏–º—ã–π —Å–∫—Ä–∏–Ω–∏–Ω–≥ –º–∏–Ω–∏–º—É–º –¥–≤—É–º—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è–º–∏",
        "üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤",
        "üìà –ê–Ω–∞–ª–∏–∑ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤–∞—Ä–∏–∞—Ü–∏–∏",
        "üéØ –ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø–æ–¥–≥—Ä—É–ø–ø",
        "üìù –°–æ–±–ª—é–¥–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ PRISMA"
    ]

    return "\n".join(checkpoints)


def _list_meta_analysis_resources() -> str:
    """–°–ø–∏—Å–æ–∫ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞."""
    resources = [
        "üõ†Ô∏è **–ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ:** RevMan, R (metafor), Comprehensive Meta-Analysis",
        "üìö **–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:** Cochrane Library, PubMed, PsycINFO, Embase",
        "üìã **–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –æ—Ü–µ–Ω–∫–∏:** RoB 2.0, ROBINS-I, AMSTAR 2",
        "üìä **–°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏:** PRISMA, PRISMA-P, PRISMA-ScR",
        "üîç **–†–µ–µ—Å—Ç—Ä—ã –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤:** PROSPERO, OSF Registries"
    ]

    return "\n".join(resources)


# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
__all__ = [
    "search_research_knowledge",
    "analyze_study_methodology",
    "validate_statistical_analysis",
    "search_literature",
    "evaluate_study_quality",
    "perform_meta_analysis_planning",
    "break_down_to_microtasks",
    "delegate_task_to_agent",
    "check_delegation_need"
]