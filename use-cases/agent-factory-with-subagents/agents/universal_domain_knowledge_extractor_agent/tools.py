# -*- coding: utf-8 -*-
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ –ª—é–±—ã—Ö –¥–æ–º–µ–Ω–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—é, –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—é, –Ω—É–º–µ—Ä–æ–ª–æ–≥–∏—é, –±–∏–∑–Ω–µ—Å –∏ –¥—Ä—É–≥–∏–µ –æ–±–ª–∞—Å—Ç–∏
"""

import asyncio
import json
from typing import List, Dict, Any, Optional
from pydantic_ai import RunContext
from .dependencies import DomainKnowledgeExtractorDependencies, AGENT_ASSIGNEE_MAP

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ MCP –∫–ª–∏–µ–Ω—Ç–∞
try:
    from ...mcp_client import mcp_archon_rag_search_knowledge_base, mcp_archon_manage_task
except ImportError:
    # Fallback –µ—Å–ª–∏ MCP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    async def mcp_archon_rag_search_knowledge_base(*args, **kwargs):
        return {"success": False, "error": "MCP –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}

    async def mcp_archon_manage_task(*args, **kwargs):
        return {"success": False, "error": "MCP –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}

async def extract_domain_knowledge(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    source_text: str,
    knowledge_type: str = "concepts",
    extraction_depth: str = "comprehensive"
) -> str:
    """
    –ò–∑–≤–ª–µ—á—å –∑–Ω–∞–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–µ –¥–æ–º–µ–Ω–∞.

    Args:
        source_text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π
        knowledge_type: –¢–∏–ø –∑–Ω–∞–Ω–∏–π (concepts, methods, patterns, frameworks)
        extraction_depth: –ì–ª—É–±–∏–Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (surface, comprehensive, expert)

    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
    """
    try:
        domain_config = ctx.deps.domain_config
        domain_type = ctx.deps.domain_type

        # –î–æ–º–µ–Ω–Ω–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        if domain_type == "psychology":
            return await _extract_psychology_knowledge(source_text, knowledge_type, domain_config)
        elif domain_type == "astrology":
            return await _extract_astrology_knowledge(source_text, knowledge_type, domain_config)
        elif domain_type == "numerology":
            return await _extract_numerology_knowledge(source_text, knowledge_type, domain_config)
        elif domain_type == "business":
            return await _extract_business_knowledge(source_text, knowledge_type, domain_config)
        else:
            return await _extract_generic_knowledge(source_text, knowledge_type)

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π: {e}"

async def _extract_psychology_knowledge(
    text: str,
    knowledge_type: str,
    config: Dict[str, Any]
) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π."""
    psychology_patterns = {
        "concepts": ["—Ç–µ—Ä–∞–ø–µ–≤—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ö–Ω–∏–∫–∏", "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã", "—ç–≥–æ-—Å–æ—Å—Ç–æ—è–Ω–∏—è"],
        "methods": ["–ö–ü–¢", "—Ç—Ä–∞–Ω–∑–∞–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "—ç—Ä–∏–∫—Å–æ–Ω–æ–≤—Å–∫–∏–π –≥–∏–ø–Ω–æ–∑"],
        "patterns": ["–¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫", "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–≥—Ä—ã", "—Å–æ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å"],
        "frameworks": ["DSM-5", "ICD-11", "–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —à–∫–∞–ª—ã"]
    }

    extracted = {
        "domain": "psychology",
        "knowledge_type": knowledge_type,
        "patterns": psychology_patterns.get(knowledge_type, []),
        "scientific_validation": config.get("scientific_validation", False),
        "therapy_approaches": config.get("therapy_approaches", []),
        "extracted_content": text[:500] + "..." if len(text) > 500 else text
    }

    return json.dumps(extracted, ensure_ascii=False, indent=2)

async def _extract_astrology_knowledge(
    text: str,
    knowledge_type: str,
    config: Dict[str, Any]
) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π."""
    astrology_patterns = {
        "concepts": ["–ø–ª–∞–Ω–µ—Ç—ã", "–∑–Ω–∞–∫–∏ –∑–æ–¥–∏–∞–∫–∞", "–¥–æ–º–∞", "–∞—Å–ø–µ–∫—Ç—ã"],
        "methods": ["—Ä–∞—Å—á–µ—Ç –≥–æ—Ä–æ—Å–∫–æ–ø–∞", "—Ç—Ä–∞–Ω–∑–∏—Ç—ã", "–ø—Ä–æ–≥—Ä–µ—Å—Å–∏–∏"],
        "patterns": ["–º–∞–∂–æ—Ä–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã", "–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏", "—ç–ª–µ–º–µ–Ω—Ç—ã"],
        "frameworks": ["—Ç—Ä–æ–ø–∏—á–µ—Å–∫–∏–π –∑–æ–¥–∏–∞–∫", "—Å–∏–¥–µ—Ä–∏—á–µ—Å–∫–∏–π –∑–æ–¥–∏–∞–∫", "—Å–∏—Å—Ç–µ–º—ã –¥–æ–º–æ–≤"]
    }

    extracted = {
        "domain": "astrology",
        "knowledge_type": knowledge_type,
        "patterns": astrology_patterns.get(knowledge_type, []),
        "house_systems": config.get("house_systems", []),
        "cultural_systems": config.get("cultural_systems", []),
        "extracted_content": text[:500] + "..." if len(text) > 500 else text
    }

    return json.dumps(extracted, ensure_ascii=False, indent=2)

async def _extract_numerology_knowledge(
    text: str,
    knowledge_type: str,
    config: Dict[str, Any]
) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω—É–º–µ—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π."""
    numerology_patterns = {
        "concepts": ["–∂–∏–∑–Ω–µ–Ω–Ω—ã–π –ø—É—Ç—å", "—á–∏—Å–ª–æ –¥—É—à–∏", "—á–∏—Å–ª–æ –ª–∏—á–Ω–æ—Å—Ç–∏"],
        "methods": ["–ø–∏—Ñ–∞–≥–æ—Ä–µ–π—Å–∫–∏–π –º–µ—Ç–æ–¥", "—Ö–∞–ª–¥–µ–π—Å–∫–∏–π –º–µ—Ç–æ–¥", "–∫–∞–±–±–∞–ª–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –Ω—É–º–µ—Ä–æ–ª–æ–≥–∏—è"],
        "patterns": ["–º–∞—Å—Ç–µ—Ä-—á–∏—Å–ª–∞", "–∫–∞—Ä–º–∞-—á–∏—Å–ª–∞", "—Ü–∏–∫–ª—ã"],
        "frameworks": ["–º–∞—Ç—Ä–∏—Ü–∞ —Å—É–¥—å–±—ã", "–ø—Å–∏—Ö–æ–º–∞—Ç—Ä–∏—Ü–∞", "–Ω—É–º–µ—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞"]
    }

    extracted = {
        "domain": "numerology",
        "knowledge_type": knowledge_type,
        "patterns": numerology_patterns.get(knowledge_type, []),
        "calculation_methods": config.get("calculation_methods", []),
        "cultural_variants": config.get("cultural_variants", False),
        "extracted_content": text[:500] + "..." if len(text) > 500 else text
    }

    return json.dumps(extracted, ensure_ascii=False, indent=2)

async def _extract_business_knowledge(
    text: str,
    knowledge_type: str,
    config: Dict[str, Any]
) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∏–∑–Ω–µ—Å –∑–Ω–∞–Ω–∏–π."""
    business_patterns = {
        "concepts": ["KPI", "–∫–æ–Ω–≤–µ—Ä—Å–∏—è", "–≤–æ—Ä–æ–Ω–∫–∞ –ø—Ä–æ–¥–∞–∂", "—é–Ω–∏—Ç-—ç–∫–æ–Ω–æ–º–∏–∫–∞"],
        "methods": ["SWOT-–∞–Ω–∞–ª–∏–∑", "–º–æ–¥–µ–ª—å –ü–æ—Ä—Ç–µ—Ä–∞", "Lean Canvas"],
        "patterns": ["customer journey", "growth hacking", "viral loops"],
        "frameworks": ["OKR", "Balanced Scorecard", "Blue Ocean Strategy"]
    }

    extracted = {
        "domain": "business",
        "knowledge_type": knowledge_type,
        "patterns": business_patterns.get(knowledge_type, []),
        "frameworks": config.get("frameworks", []),
        "metrics_focus": config.get("metrics_focus", False),
        "extracted_content": text[:500] + "..." if len(text) > 500 else text
    }

    return json.dumps(extracted, ensure_ascii=False, indent=2)

async def _extract_generic_knowledge(text: str, knowledge_type: str) -> str:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –¥–ª—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤."""
    extracted = {
        "domain": "generic",
        "knowledge_type": knowledge_type,
        "extracted_content": text[:500] + "..." if len(text) > 500 else text,
        "note": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–æ–º–µ–Ω"
    }

    return json.dumps(extracted, ensure_ascii=False, indent=2)

async def analyze_knowledge_patterns(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    knowledge_data: str,
    pattern_type: str = "structural"
) -> str:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏—è—Ö.

    Args:
        knowledge_data: –î–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        pattern_type: –¢–∏–ø –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (structural, semantic, behavioral)

    Returns:
        –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–∞–Ω–Ω—ã—Ö
        if knowledge_data.startswith("{"):
            data = json.loads(knowledge_data)
            domain = data.get("domain", "unknown")
        else:
            domain = ctx.deps.domain_type

        patterns = {
            "structural": f"–°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain}",
            "semantic": f"–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏ –≤ {domain}",
            "behavioral": f"–ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ {domain}"
        }

        analysis = {
            "domain": domain,
            "pattern_type": pattern_type,
            "analysis": patterns.get(pattern_type, "–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑"),
            "recommendations": [
                "–°–æ–∑–¥–∞—Ç—å –º–æ–¥—É–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É",
                "–í—ã–¥–µ–ª–∏—Ç—å –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã",
                "–î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö"
            ]
        }

        return json.dumps(analysis, ensure_ascii=False, indent=2)

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}"

async def create_knowledge_modules(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    analyzed_patterns: str,
    module_type: str = "functional"
) -> str:
    """
    –°–æ–∑–¥–∞—Ç—å –º–æ–¥—É–ª–∏ –∑–Ω–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.

    Args:
        analyzed_patterns: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        module_type: –¢–∏–ø –º–æ–¥—É–ª–µ–π (functional, data, presentation)

    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª–µ–π –∑–Ω–∞–Ω–∏–π
    """
    try:
        domain = ctx.deps.domain_type
        output_format = ctx.deps.output_format

        modules = {
            "domain": domain,
            "module_type": module_type,
            "output_format": output_format,
            "modules": await _generate_domain_modules(domain, module_type),
            "integration_points": [
                "RAG —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞",
                "API –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥—É–ª—è–º",
                "–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏"
            ]
        }

        return json.dumps(modules, ensure_ascii=False, indent=2)

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥—É–ª–µ–π: {e}"

async def _generate_domain_modules(domain: str, module_type: str) -> List[Dict[str, Any]]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞."""
    if domain == "psychology":
        return [
            {
                "name": "DiagnosticModule",
                "purpose": "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",
                "components": ["test_engine", "scoring_system", "interpretation"]
            },
            {
                "name": "TherapyModule",
                "purpose": "–¢–µ—Ä–∞–ø–µ–≤—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Ç–µ—Ä–≤–µ–Ω—Ü–∏–∏",
                "components": ["technique_library", "session_planner", "progress_tracker"]
            },
            {
                "name": "PersonalizationModule",
                "purpose": "VAK –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è",
                "components": ["vak_detector", "content_adapter", "delivery_optimizer"]
            }
        ]
    elif domain == "astrology":
        return [
            {
                "name": "CalculationModule",
                "purpose": "–ê—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—á–µ—Ç—ã",
                "components": ["ephemeris", "house_calculator", "aspect_engine"]
            },
            {
                "name": "InterpretationModule",
                "purpose": "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–∞—Ä—Ç—ã",
                "components": ["planet_meanings", "house_analysis", "aspect_synthesis"]
            }
        ]
    elif domain == "numerology":
        return [
            {
                "name": "CalculationModule",
                "purpose": "–ù—É–º–µ—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—á–µ—Ç—ã",
                "components": ["name_calculator", "date_calculator", "compatibility_engine"]
            },
            {
                "name": "InterpretationModule",
                "purpose": "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —á–∏—Å–µ–ª",
                "components": ["number_meanings", "life_path_analysis", "compatibility_reports"]
            }
        ]
    else:
        return [
            {
                "name": "GenericModule",
                "purpose": f"–ú–æ–¥—É–ª—å –¥–ª—è {domain}",
                "components": ["data_processor", "analyzer", "reporter"]
            }
        ]

async def search_domain_knowledge(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    query: str,
    search_scope: str = "comprehensive"
) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –¥–æ–º–µ–Ω–∞ —á–µ—Ä–µ–∑ Archon RAG.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        search_scope: –û–±–ª–∞—Å—Ç—å –ø–æ–∏—Å–∫–∞ (focused, comprehensive, experimental)

    Returns:
        –ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    """
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–º–µ–Ω–Ω–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ–≥–∏ –∫ –∑–∞–ø—Ä–æ—Å—É
        domain_tags = ctx.deps.knowledge_tags.copy()
        domain_tags.append(ctx.deps.domain_type.replace("_", "-"))

        enhanced_query = f"{query} {' '.join(domain_tags)}"

        # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Archon RAG
        result = await mcp_archon_rag_search_knowledge_base(
            query=enhanced_query,
            source_domain=ctx.deps.knowledge_domain,
            match_count=5 if search_scope == "focused" else 10
        )

        if result.get("success") and result.get("results"):
            knowledge = "\n".join([
                f"**{r['metadata']['title']}:**\n{r['content']}"
                for r in result["results"]
            ])
            return f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –¥–æ–º–µ–Ω–∞ {ctx.deps.domain_type}:\n{knowledge}"
        else:
            # Fallback –ø–æ–∏—Å–∫
            fallback_result = await mcp_archon_rag_search_knowledge_base(
                query=f"{ctx.deps.domain_type} knowledge extraction",
                match_count=3
            )

            if fallback_result.get("success") and fallback_result.get("results"):
                knowledge = "\n".join([
                    f"**{r['metadata']['title']}:**\n{r['content']}"
                    for r in fallback_result["results"]
                ])
                return f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (fallback –ø–æ–∏—Å–∫):\n{knowledge}"

            return f"""
‚ö†Ô∏è **–ü–û–ò–°–ö –í –ë–ê–ó–ï –ó–ù–ê–ù–ò–ô –î–û–ú–ï–ù–ê {ctx.deps.domain_type.upper()}**

üîç **–ó–∞–ø—Ä–æ—Å:** {query}
üìã **–¢–µ–≥–∏:** {', '.join(domain_tags)}

ü§î **–í–û–ó–ú–û–ñ–ù–´–ï –ü–†–ò–ß–ò–ù–´ –û–¢–°–£–¢–°–¢–í–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:**
1. –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è –¥–æ–º–µ–Ω–∞ {ctx.deps.domain_type} –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ
3. –ù—É–∂–Ω—ã –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã

üí° **–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –æ–±–ª–∞—Å—Ç–∏ {ctx.deps.domain_type}
- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —á–µ—Ä–µ–∑ get_available_sources

üìö **–î–û–ú–ï–ù:** {ctx.deps.domain_type}
üéØ **–û–ë–õ–ê–°–¢–¨ –ü–û–ò–°–ö–ê:** {search_scope}
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π: {e}"

async def validate_knowledge_structure(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    knowledge_modules: str,
    validation_criteria: str = "scientific"
) -> str:
    """
    –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–Ω–∞–Ω–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –¥–æ–º–µ–Ω–∞.

    Args:
        knowledge_modules: –ú–æ–¥—É–ª–∏ –∑–Ω–∞–Ω–∏–π –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        validation_criteria: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (basic, scientific, expert)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    """
    try:
        domain = ctx.deps.domain_type
        validation_level = ctx.deps.validation_level

        validation_results = {
            "domain": domain,
            "validation_level": validation_level,
            "criteria": validation_criteria,
            "status": "passed",
            "checks": await _perform_domain_validation(domain, knowledge_modules, validation_criteria),
            "recommendations": []
        }

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        if validation_criteria == "scientific" and domain == "psychology":
            validation_results["recommendations"].extend([
                "–î–æ–±–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–∞—É—á–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–ª–∏–Ω–∏—á–µ—Å–∫—É—é –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤",
                "–£—á–µ—Å—Ç—å —ç—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏"
            ])

        return json.dumps(validation_results, ensure_ascii=False, indent=2)

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}"

async def _perform_domain_validation(
    domain: str,
    modules: str,
    criteria: str
) -> List[Dict[str, Any]]:
    """–í—ã–ø–æ–ª–Ω–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –¥–ª—è –¥–æ–º–µ–Ω–∞."""
    checks = []

    if domain == "psychology":
        checks.extend([
            {"check": "scientific_validation", "status": "passed", "note": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —à–∫–∞–ª—ã"},
            {"check": "ethical_compliance", "status": "passed", "note": "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —ç—Ç–∏—á–µ—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º"},
            {"check": "cultural_adaptation", "status": "warning", "note": "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫—É–ª—å—Ç—É—Ä–Ω–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"}
        ])
    elif domain == "astrology":
        checks.extend([
            {"check": "calculation_accuracy", "status": "passed", "note": "–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—á–µ—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã"},
            {"check": "traditional_compliance", "status": "passed", "note": "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º –º–µ—Ç–æ–¥–∞–º"}
        ])
    elif domain == "numerology":
        checks.extend([
            {"check": "calculation_methods", "status": "passed", "note": "–ú–µ—Ç–æ–¥—ã —Ä–∞—Å—á–µ—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã"},
            {"check": "interpretation_consistency", "status": "passed", "note": "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã"}
        ])

    return checks

# –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã
async def break_down_to_microtasks(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    main_task: str,
    complexity_level: str = "medium"
) -> str:
    """–†–∞–∑–±–∏—Ç—å –∑–∞–¥–∞—á—É –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –Ω–∞ –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏."""
    domain = ctx.deps.domain_type

    if complexity_level == "simple":
        microtasks = [
            f"–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ {domain}",
            f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π",
            f"–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è"
        ]
    elif complexity_level == "medium":
        microtasks = [
            f"–ê–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ –¥–æ–º–µ–Ω–∞ {domain}",
            f"–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ —Ç–µ–º–µ {domain}",
            f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π, –º–µ—Ç–æ–¥–æ–≤ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤",
            f"–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥—É–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∑–Ω–∞–Ω–∏–π",
            f"–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º {domain}",
            f"–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"
        ]
    else:  # complex
        microtasks = [
            f"–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ–º–µ–Ω–∞ {domain} –∏ –µ–≥–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏",
            f"–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ RAG –∏ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö",
            f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã",
            f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ (–∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –º–µ—Ç–æ–¥—ã, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏)",
            f"–°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –º–æ–¥—É–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã",
            f"–ù–∞—É—á–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º",
            f"–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏ –∑–Ω–∞–Ω–∏–π",
            f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ä–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"
        ]

    output = f"üìã **–ú–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ –¥–æ–º–µ–Ω–∞ {domain}:**\n"
    for i, task in enumerate(microtasks, 1):
        output += f"{i}. {task}\n"
    output += "\n‚úÖ –ë—É–¥—É –æ—Ç—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –∫–∞–∂–¥–æ–π –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏"

    return output

async def report_microtask_progress(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    microtask_number: int,
    microtask_description: str,
    status: str = "completed",
    details: str = ""
) -> str:
    """–û—Ç—á–µ—Ç –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏."""
    status_emoji = {
        "started": "üîÑ",
        "in_progress": "‚è≥",
        "completed": "‚úÖ",
        "blocked": "üö´"
    }

    report = f"{status_emoji.get(status, 'üìù')} **–ú–∏–∫—Ä–æ–∑–∞–¥–∞—á–∞ {microtask_number}** ({status}): {microtask_description}"
    if details:
        report += f"\n   –î–µ—Ç–∞–ª–∏: {details}"

    return report

async def reflect_and_improve(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    completed_work: str,
    work_type: str = "knowledge_extraction"
) -> str:
    """–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π."""
    domain = ctx.deps.domain_type

    analysis = f"""
üîç **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ –¥–æ–º–µ–Ω–∞ {domain}:**

**–¢–∏–ø —Ä–∞–±–æ—Ç—ã:** {work_type}
**–î–æ–º–µ–Ω:** {domain}
**–†–µ–∑—É–ª—å—Ç–∞—Ç:** {completed_work[:200]}...

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
1. [–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å] - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
2. [–ù–∞—É—á–Ω–æ—Å—Ç—å] - –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –¥–æ–º–µ–Ω–∞ {domain}
3. [–ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å] - –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ—Å—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
4. [–ü–æ–ª–Ω–æ—Ç–∞] - –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –¥–æ–º–µ–Ω–∞

**–í–Ω–µ—Å–µ–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:**
- –£—Å–∏–ª–µ–Ω–∏–µ –¥–æ–º–µ–Ω–Ω–æ–π —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç–∏
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—É—á–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- –£–ª—É—á—à–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–¥ –ø—Ä–æ–µ–∫—Ç—ã

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –∫–∞—á–µ—Å—Ç–≤–∞:**
‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏ {domain})
‚úÖ –ù–∞—É—á–Ω–∞—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º)
‚úÖ –ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å (–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
‚úÖ –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ–¥ –∑–∞–¥–∞—á–∏)

üéØ **–§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥—É–ª–µ–π –∑–Ω–∞–Ω–∏–π –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é**
"""

    return analysis

async def check_delegation_need(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    current_task: str,
    current_agent_type: str = "domain_knowledge_extractor"
) -> str:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∑–∞–¥–∞—á –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π."""
    keywords = current_task.lower().split()

    delegation_suggestions = []

    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    if any(keyword in keywords for keyword in ['–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', 'security', '–≤–∞–ª–∏–¥–∞—Ü–∏—è', '–∞—É–¥–∏—Ç']):
        delegation_suggestions.append("Security Audit Agent - –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö")

    if any(keyword in keywords for keyword in ['–ø–æ–∏—Å–∫', 'search', 'rag', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è']):
        delegation_suggestions.append("RAG Agent - –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

    if any(keyword in keywords for keyword in ['–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', 'performance', '–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è']):
        delegation_suggestions.append("Performance Optimization Agent - –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤")

    if delegation_suggestions:
        result = "ü§ù **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π:**\n"
        for suggestion in delegation_suggestions:
            result += f"- {suggestion}\n"
        result += "\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ delegate_task_to_agent() –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–¥–∞—á."
    else:
        result = "‚úÖ –ó–∞–¥–∞—á–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ."

    return result

async def delegate_task_to_agent(
    ctx: RunContext[DomainKnowledgeExtractorDependencies],
    target_agent: str,
    task_title: str,
    task_description: str,
    priority: str = "medium",
    context_data: Dict[str, Any] = None
) -> str:
    """–î–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É –¥—Ä—É–≥–æ–º—É –∞–≥–µ–Ω—Ç—É —á–µ—Ä–µ–∑ Archon."""
    try:
        if context_data is None:
            context_data = {
                "domain_type": ctx.deps.domain_type,
                "extraction_context": "Universal Domain Knowledge Extractor Agent"
            }

        task_result = await mcp_archon_manage_task(
            action="create",
            project_id=ctx.deps.archon_project_id,
            title=task_title,
            description=f"{task_description}\n\n**–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç Domain Knowledge Extractor:**\n{json.dumps(context_data, ensure_ascii=False, indent=2)}",
            assignee=AGENT_ASSIGNEE_MAP.get(target_agent, "Archon Analysis Lead"),
            status="todo",
            feature=f"–î–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç Domain Knowledge Extractor",
            task_order=50
        )

        return f"‚úÖ –ó–∞–¥–∞—á–∞ —É—Å–ø–µ—à–Ω–æ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∞ –∞–≥–µ–Ω—Ç—É {target_agent}:\n- –ó–∞–¥–∞—á–∞ ID: {task_result.get('task_id')}\n- –°—Ç–∞—Ç—É—Å: —Å–æ–∑–¥–∞–Ω–∞ –≤ Archon\n- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}\n- –î–æ–º–µ–Ω: {ctx.deps.domain_type}"

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}"