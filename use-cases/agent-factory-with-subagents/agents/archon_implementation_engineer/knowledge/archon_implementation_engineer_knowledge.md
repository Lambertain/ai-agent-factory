# Archon Implementation Engineer Agent - Knowledge Base

## üìö –û–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤

**–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ü–ï–†–ï–î –ù–ê–ß–ê–õ–û–ú –†–ê–ë–û–¢–´:** –ü—Ä–æ—á–∏—Ç–∞–π [–û–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –∞–≥–µ–Ω—Ç–æ–≤](../_shared/agent_common_rules.md)

–í—Å–µ –∞–≥–µ–Ω—Ç—ã —Å–ª–µ–¥—É—é—Ç –µ–¥–∏–Ω—ã–º –ø—Ä–∞–≤–∏–ª–∞–º workflow, –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è. –û–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç:
- ‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ä–æ–ª—å (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
- ‚úÖ Workflow –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è
- ‚úÖ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏ (Archon + TodoWrite)
- ‚úÖ Git –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
- ‚úÖ Post-Task Checklist (–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—É–Ω–∫—Ç –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏)
- ‚úÖ –ü—Ä–æ—Ç–æ–∫–æ–ª—ã –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º –∏ —ç—Å–∫–∞–ª–∞—Ü–∏–∏
- ‚úÖ –ó–∞–±–æ—Ä–æ–Ω–∞ —è—Ä–ª–∏–∫—ñ–≤ —Ç–∞ —Ç–æ–∫–µ–Ω-–µ–∫–æ–Ω–æ–º—ñ—ó

---

## üé≠ –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢ –†–û–õ–ò: Archon Implementation Engineer Agent

**–¢—ã - Archon Implementation Engineer Agent**, —ç–∫—Å–ø–µ—Ä—Ç –≤ [–û–ë–õ–ê–°–¢–¨ –≠–ö–°–ü–ï–†–¢–ò–ó–´].

### ‚ö†Ô∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ü–ï–†–ï–î –ù–ê–ß–ê–õ–û–ú –†–ê–ë–û–¢–´:
**–ü–†–û–ß–ò–¢–ê–ô:** [`agent_common_rules.md`](../_shared/agent_common_rules.md) - —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ workflow, –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —ç—Å–∫–∞–ª–∞—Ü–∏–∏.

## –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è Archon Implementation Engineer

```
–¢—ã –≤–µ–¥—É—â–∏–π –∏–Ω–∂–µ–Ω–µ—Ä-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã Archon - —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π –≤ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–¥. –¢–≤–æ—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –≤–µ—Å—å —Å—Ç–µ–∫ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.

**–¢–≤–æ—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞:**
- Pydantic AI –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏
- Python/TypeScript/Go —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
- –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ API –¥–∏–∑–∞–π–Ω
- Database design –∏ optimization (PostgreSQL, Redis, Vector DB)
- Cloud infrastructure (AWS, GCP, Azure)
- DevOps –∏ CI/CD –ø–∞–π–ø–ª–∞–π–Ω—ã
- Performance optimization –∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

**–ö–ª—é—á–µ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:**

1. **AI Agent Development:**
   - Pydantic AI –∞–≥–µ–Ω—Ç—ã —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
   - RAG —Å–∏—Å—Ç–µ–º—ã –∏ vector search
   - LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∏ prompt engineering
   - Cost optimization –∏ model selection

2. **Backend Development:**
   - FastAPI/Flask RESTful APIs
   - –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
   - Database design –∏ ORM (SQLAlchemy, Prisma)
   - Caching strategies (Redis, Memcached)

3. **Frontend Development:**
   - Next.js 14 App Router –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
   - TypeScript –∏ type-safe development
   - React Server Components
   - Performance optimization

4. **Infrastructure & DevOps:**
   - Docker containerization
   - Kubernetes orchestration
   - CI/CD —Å GitHub Actions/GitLab CI
   - Monitoring –∏ observability

**–ü–æ–¥—Ö–æ–¥ –∫ —Ä–∞–±–æ—Ç–µ:**
1. –ù–∞—á–∏–Ω–∞–π —Å –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
2. –í—ã–±–∏—Ä–∞–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –¥–ª—è –∑–∞–¥–∞—á–∏
3. –ü–∏—à–∏ —á–∏—Å—Ç—ã–π, —Ç–µ—Å—Ç–∏—Ä—É–µ–º—ã–π, –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥
4. –°–ª–µ–¥—É–π –ø—Ä–∏–Ω—Ü–∏–ø–∞–º SOLID –∏ clean architecture
5. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞
```

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

### Clean Architecture for AI Agents
```python
# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ Pydantic AI –∞–≥–µ–Ω—Ç–∞ –ø–æ Clean Architecture
from typing import Protocol, Dict, Any
from pydantic_ai import Agent, RunContext
from abc import ABC, abstractmethod

# Domain Layer - Business Logic
class AgentUseCase(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π use case –¥–ª—è –∞–≥–µ–Ω—Ç–∞."""

    @abstractmethod
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –∞–≥–µ–Ω—Ç–∞."""
        pass

class ProcessUserQueryUseCase(AgentUseCase):
    """Use case –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤."""

    def __init__(self, knowledge_service, validation_service):
        self.knowledge_service = knowledge_service
        self.validation_service = validation_service

    async def execute(self, query: str) -> Dict[str, Any]:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        validated_query = await self.validation_service.validate(query)

        # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        context = await self.knowledge_service.search(validated_query)

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        return {
            "query": validated_query,
            "context": context,
            "status": "success"
        }

# Application Layer - Agent Implementation
@dataclass
class AgentDependencies:
    """–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞."""
    knowledge_service: 'KnowledgeService'
    validation_service: 'ValidationService'
    settings: 'AgentSettings'

def create_agent(deps: AgentDependencies) -> Agent:
    """Factory –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞."""

    agent = Agent(
        model=deps.settings.model,
        deps_type=AgentDependencies,
        system_prompt=deps.settings.system_prompt
    )

    @agent.tool
    async def search_knowledge(ctx: RunContext[AgentDependencies], query: str) -> str:
        """–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π."""
        use_case = ProcessUserQueryUseCase(
            ctx.deps.knowledge_service,
            ctx.deps.validation_service
        )
        result = await use_case.execute(query)
        return result

    return agent

# Infrastructure Layer - External Services
class KnowledgeService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π."""

    def __init__(self, vector_db, embedding_model):
        self.vector_db = vector_db
        self.embedding_model = embedding_model

    async def search(self, query: str) -> List[Dict]:
        embedding = await self.embedding_model.encode(query)
        results = await self.vector_db.similarity_search(embedding)
        return results
```

### Repository Pattern –¥–ª—è Data Access
```python
from abc import ABC, abstractmethod
from typing import List, Optional, Generic, TypeVar
import asyncpg
from pydantic import BaseModel

T = TypeVar('T', bound=BaseModel)

class Repository(ABC, Generic[T]):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π."""

    @abstractmethod
    async def create(self, entity: T) -> T:
        pass

    @abstractmethod
    async def get_by_id(self, id: str) -> Optional[T]:
        pass

    @abstractmethod
    async def update(self, entity: T) -> T:
        pass

    @abstractmethod
    async def delete(self, id: str) -> bool:
        pass

class PostgreSQLRepository(Repository[T]):
    """–†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –¥–ª—è PostgreSQL."""

    def __init__(self, pool: asyncpg.Pool, table_name: str, model_class):
        self.pool = pool
        self.table_name = table_name
        self.model_class = model_class

    async def create(self, entity: T) -> T:
        async with self.pool.acquire() as conn:
            data = entity.model_dump()
            columns = ', '.join(data.keys())
            placeholders = ', '.join(f'${i+1}' for i in range(len(data)))

            query = f"""
                INSERT INTO {self.table_name} ({columns})
                VALUES ({placeholders})
                RETURNING *
            """

            row = await conn.fetchrow(query, *data.values())
            return self.model_class(**dict(row))

    async def get_by_id(self, id: str) -> Optional[T]:
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                f"SELECT * FROM {self.table_name} WHERE id = $1", id
            )
            return self.model_class(**dict(row)) if row else None

# Usage Example
class User(BaseModel):
    id: Optional[str] = None
    name: str
    email: str

class UserRepository(PostgreSQLRepository[User]):
    def __init__(self, pool: asyncpg.Pool):
        super().__init__(pool, "users", User)

# Service Layer
class UserService:
    def __init__(self, user_repo: UserRepository):
        self.user_repo = user_repo

    async def create_user(self, name: str, email: str) -> User:
        user = User(name=name, email=email)
        return await self.user_repo.create(user)
```

## Performance Optimization Patterns

### Async Programming Best Practices
```python
import asyncio
import aiohttp
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor
import time

class PerformanceOptimizedAgent:
    """–ê–≥–µ–Ω—Ç —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""

    def __init__(self):
        self.session = None
        self.executor = ThreadPoolExecutor(max_workers=4)

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.session.close()
        self.executor.shutdown()

    async def parallel_api_calls(self, urls: List[str]) -> List[Dict]:
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã–∑–æ–≤—ã API."""
        tasks = [self.fetch_data(url) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        return [r for r in results if not isinstance(r, Exception)]

    async def fetch_data(self, url: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å retry –ª–æ–≥–∏–∫–æ–π."""
        for attempt in range(3):
            try:
                async with self.session.get(url, timeout=5) as response:
                    if response.status == 200:
                        return await response.json()
                    else:
                        raise aiohttp.ClientResponseError(
                            request_info=response.request_info,
                            history=response.history,
                            status=response.status
                        )
            except Exception as e:
                if attempt == 2:  # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                    raise e
                await asyncio.sleep(2 ** attempt)  # Exponential backoff

    async def cpu_intensive_task(self, data: List[Dict]) -> List[Dict]:
        """CPU-–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ –≤ thread pool."""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self.process_data_sync,
            data
        )

    def process_data_sync(self, data: List[Dict]) -> List[Dict]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö."""
        # –°–ª–æ–∂–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        return [self.transform_item(item) for item in data]

    def transform_item(self, item: Dict) -> Dict:
        # –¢—è–∂–µ–ª—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        time.sleep(0.01)  # –ò–º–∏—Ç–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã
        return {"processed": True, **item}

# Usage with context manager
async def main():
    async with PerformanceOptimizedAgent() as agent:
        urls = ["http://api1.com", "http://api2.com", "http://api3.com"]
        results = await agent.parallel_api_calls(urls)
        processed = await agent.cpu_intensive_task(results)
        return processed
```

### Caching Strategies
```python
import redis.asyncio as redis
import json
import hashlib
from functools import wraps
from typing import Optional, Any, Callable
import pickle

class CacheManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Å Redis."""

    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)

    async def get(self, key: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞."""
        value = await self.redis.get(key)
        if value:
            return pickle.loads(value)
        return None

    async def set(self, key: str, value: Any, ttl: int = 3600):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫—ç—à."""
        await self.redis.setex(key, ttl, pickle.dumps(value))

    async def delete(self, key: str):
        """–£–¥–∞–ª–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞."""
        await self.redis.delete(key)

    async def clear_pattern(self, pattern: str):
        """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É."""
        keys = await self.redis.keys(pattern)
        if keys:
            await self.redis.delete(*keys)

def cached(ttl: int = 3600, key_prefix: str = ""):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π."""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞
            cache_key = f"{key_prefix}:{func.__name__}:{_generate_cache_key(args, kwargs)}"

            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
            cache_manager = kwargs.get('cache_manager')
            if cache_manager:
                cached_result = await cache_manager.get(cache_key)
                if cached_result is not None:
                    return cached_result

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
            result = await func(*args, **kwargs)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
            if cache_manager:
                await cache_manager.set(cache_key, result, ttl)

            return result
        return wrapper
    return decorator

def _generate_cache_key(args, kwargs) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤."""
    key_data = f"{args}:{sorted(kwargs.items())}"
    return hashlib.md5(key_data.encode()).hexdigest()

# Usage Example
class DataService:
    def __init__(self, cache_manager: CacheManager):
        self.cache_manager = cache_manager

    @cached(ttl=1800, key_prefix="data_service")
    async def expensive_computation(self, param1: str, param2: int, cache_manager=None) -> Dict:
        """–î–æ—Ä–æ–≥–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
        # –°–∏–º—É–ª—è—Ü–∏—è —Ç—è–∂–µ–ª—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        await asyncio.sleep(2)
        return {"result": f"processed_{param1}_{param2}"}
```

## Database Optimization

### Efficient Database Operations
```python
import asyncpg
from typing import List, Dict, Any
from contextlib import asynccontextmanager

class OptimizedDatabase:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö."""

    def __init__(self, database_url: str):
        self.database_url = database_url
        self.pool = None

    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π."""
        self.pool = await asyncpg.create_pool(
            self.database_url,
            min_size=5,
            max_size=20,
            command_timeout=60,
            server_settings={
                'jit': 'off',  # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ JIT –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                'application_name': 'archon_agent'
            }
        )

    @asynccontextmanager
    async def transaction(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π."""
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                yield conn

    async def bulk_insert(self, table: str, data: List[Dict[str, Any]]) -> int:
        """–ú–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö."""
        if not data:
            return 0

        columns = list(data[0].keys())
        values = [list(row.values()) for row in data]

        async with self.pool.acquire() as conn:
            result = await conn.copy_records_to_table(
                table,
                records=values,
                columns=columns
            )
            return len(values)

    async def execute_query_with_pagination(
        self,
        base_query: str,
        params: List[Any],
        page_size: int = 1000
    ) -> List[Dict]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π."""
        all_results = []
        offset = 0

        async with self.pool.acquire() as conn:
            while True:
                paginated_query = f"{base_query} LIMIT {page_size} OFFSET {offset}"
                rows = await conn.fetch(paginated_query, *params)

                if not rows:
                    break

                all_results.extend([dict(row) for row in rows])
                offset += page_size

                if len(rows) < page_size:
                    break

        return all_results

    async def explain_query(self, query: str, params: List[Any] = None) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø–ª–∞–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞."""
        explain_query = f"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) {query}"

        async with self.pool.acquire() as conn:
            result = await conn.fetchval(explain_query, *(params or []))
            return result[0]  # JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç

# Indexing Strategies
OPTIMIZED_INDEXES = """
-- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

-- –°–æ—Å—Ç–∞–≤–Ω–æ–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø–æ–ª—è–º
CREATE INDEX CONCURRENTLY idx_users_name_email
ON users (name, email)
WHERE active = true;

-- –ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
CREATE INDEX CONCURRENTLY idx_users_active
ON users (created_at)
WHERE active = true;

-- GIN –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX CONCURRENTLY idx_documents_search
ON documents USING gin(to_tsvector('english', title || ' ' || content));

-- –ò–Ω–¥–µ–∫—Å –¥–ª—è JSON –ø–æ–ª–µ–π
CREATE INDEX CONCURRENTLY idx_metadata_tags
ON documents USING gin((metadata->>'tags'));

-- Covering index –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è table lookup
CREATE INDEX CONCURRENTLY idx_users_covering
ON users (id) INCLUDE (name, email, created_at)
WHERE active = true;
"""
```

### Vector Database Optimization
```python
import numpy as np
from typing import List, Tuple
import faiss
import pickle

class OptimizedVectorStore:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤–µ–∫—Ç–æ—Ä–æ–≤."""

    def __init__(self, dimension: int):
        self.dimension = dimension
        self.index = None
        self.metadata = []

    def build_index(self, vectors: np.ndarray, use_gpu: bool = False):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞."""
        n_vectors = vectors.shape[0]

        if n_vectors < 10000:
            # –î–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö - –ø—Ä–æ—Å—Ç–æ–π L2 –ø–æ–∏—Å–∫
            self.index = faiss.IndexFlatL2(self.dimension)
        elif n_vectors < 100000:
            # –°—Ä–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ - IVF —Å 100 –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
            nlist = min(100, n_vectors // 100)
            self.index = faiss.IndexIVFFlat(
                faiss.IndexFlatL2(self.dimension),
                self.dimension,
                nlist
            )
        else:
            # –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ - HNSW –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            self.index = faiss.IndexHNSWFlat(self.dimension, 32)
            self.index.hnsw.efConstruction = 200
            self.index.hnsw.efSearch = 50

        if use_gpu and faiss.get_num_gpus() > 0:
            self.index = faiss.index_cpu_to_gpu(
                faiss.StandardGpuResources(), 0, self.index
            )

        # –û–±—É—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ (–¥–ª—è IVF)
        if hasattr(self.index, 'train'):
            self.index.train(vectors)

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤
        self.index.add(vectors)

    def search(self, query_vector: np.ndarray, k: int = 10) -> Tuple[List[float], List[int]]:
        """–ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤."""
        query_vector = query_vector.reshape(1, -1).astype(np.float32)
        distances, indices = self.index.search(query_vector, k)
        return distances[0].tolist(), indices[0].tolist()

    def batch_search(self, query_vectors: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:
        """–ü–∞–∫–µ—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–æ–≤."""
        return self.index.search(query_vectors.astype(np.float32), k)

    def save_index(self, filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –¥–∏—Å–∫."""
        faiss.write_index(self.index, f"{filepath}.faiss")
        with open(f"{filepath}.metadata", 'wb') as f:
            pickle.dump(self.metadata, f)

    def load_index(self, filepath: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ —Å –¥–∏—Å–∫–∞."""
        self.index = faiss.read_index(f"{filepath}.faiss")
        with open(f"{filepath}.metadata", 'rb') as f:
            self.metadata = pickle.load(f)
```

## Testing Strategies

### Comprehensive Testing Framework
```python
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock
from pydantic_ai.models.test import TestModel
from pydantic_ai import Agent

class TestAgentFramework:
    """–§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è AI –∞–≥–µ–Ω—Ç–æ–≤."""

    @pytest.fixture
    async def test_agent(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞."""
        # –ú–æ–∫–∞–µ–º –≤–Ω–µ—à–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        mock_dependencies = MagicMock()
        mock_dependencies.knowledge_service = AsyncMock()
        mock_dependencies.validation_service = AsyncMock()

        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ —Å —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
        agent = Agent(
            model=TestModel(),
            deps_type=type(mock_dependencies)
        )

        @agent.tool
        async def mock_search(ctx, query: str) -> str:
            return f"Mock result for: {query}"

        return agent, mock_dependencies

    @pytest.mark.asyncio
    async def test_agent_basic_functionality(self, test_agent):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞."""
        agent, deps = test_agent

        result = await agent.run("Test query", deps=deps)

        assert result.data is not None
        assert isinstance(result.data, str)

    @pytest.mark.asyncio
    async def test_agent_tool_usage(self, test_agent):
        """–¢–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∞–≥–µ–Ω—Ç–æ–º."""
        agent, deps = test_agent

        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º TestModel –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        result = await agent.run(
            "Use the search tool to find information",
            deps=deps
        )

        assert "Mock result" in str(result.data)

    @pytest.mark.asyncio
    async def test_error_handling(self, test_agent):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫."""
        agent, deps = test_agent

        # –ú–æ–∫–∞–µ–º –æ—à–∏–±–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        deps.knowledge_service.search.side_effect = Exception("Test error")

        # –ê–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω gracefully –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—à–∏–±–∫—É
        result = await agent.run("Query that causes error", deps=deps)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∞–≥–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–ª –æ—à–∏–±–∫—É
        assert result.data is not None

# Performance Testing
class PerformanceTestSuite:
    """–ù–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""

    @pytest.mark.performance
    async def test_concurrent_requests(self, test_agent):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö."""
        agent, deps = test_agent

        # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        tasks = [
            agent.run(f"Query {i}", deps=deps)
            for i in range(100)
        ]

        start_time = asyncio.get_event_loop().time()
        results = await asyncio.gather(*tasks)
        end_time = asyncio.get_event_loop().time()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        total_time = end_time - start_time
        assert total_time < 10.0  # –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∑–∞ 10 —Å–µ–∫—É–Ω–¥
        assert len(results) == 100
        assert all(r.data is not None for r in results)

    @pytest.mark.performance
    async def test_memory_usage(self, test_agent):
        """–¢–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏."""
        import psutil
        import os

        agent, deps = test_agent

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss

        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π
        for i in range(1000):
            await agent.run(f"Query {i}", deps=deps)

        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–º—è—Ç—å –Ω–µ —É—Ç–µ–∫–∞–µ—Ç
        assert memory_increase < 100 * 1024 * 1024  # –ú–µ–Ω–µ–µ 100MB —É–≤–µ–ª–∏—á–µ–Ω–∏—è

# Integration Testing
@pytest.mark.integration
class IntegrationTestSuite:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã."""

    async def test_full_pipeline(self):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∞–≥–µ–Ω—Ç–∞."""
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        from your_app.dependencies import RealDependencies
        from your_app.agent import create_agent

        deps = RealDependencies()
        await deps.initialize()

        try:
            agent = create_agent(deps)
            result = await agent.run("Real query", deps=deps)

            assert result.data is not None
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞

        finally:
            await deps.cleanup()
```

## Deployment & DevOps

### Docker Optimization
```dockerfile
# Multi-stage build –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–∞
FROM python:3.11-slim as builder

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å–±–æ—Ä–∫–∏
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Poetry
RUN pip install poetry

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
COPY pyproject.toml poetry.lock ./

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN poetry config virtualenvs.create false \
    && poetry install --no-dev --no-interaction --no-ansi

# Production stage
FROM python:3.11-slim

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
RUN groupadd -r appuser && useradd -r -g appuser appuser

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
WORKDIR /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
COPY --chown=appuser:appuser . .

# –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞
CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: archon-agent
  labels:
    app: archon-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: archon-agent
  template:
    metadata:
      labels:
        app: archon-agent
    spec:
      containers:
      - name: archon-agent
        image: archon-agent:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: archon-secrets
              key: database-url
        - name: LLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: archon-secrets
              key: llm-api-key
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: archon-agent-service
spec:
  selector:
    app: archon-agent
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

## Monitoring & Observability

### Comprehensive Monitoring Setup
```python
import logging
import time
from functools import wraps
from typing import Any, Callable
import structlog
from prometheus_client import Counter, Histogram, Gauge
import asyncio

# Metrics
REQUEST_COUNT = Counter('agent_requests_total', 'Total agent requests', ['method', 'status'])
REQUEST_DURATION = Histogram('agent_request_duration_seconds', 'Request duration')
ACTIVE_CONNECTIONS = Gauge('agent_active_connections', 'Active connections')

# Structured logging
structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="ISO"),
        structlog.processors.add_log_level,
        structlog.processors.JSONRenderer()
    ],
    wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
    logger_factory=structlog.PrintLoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

def monitor_performance(func: Callable) -> Callable:
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        status = "success"

        try:
            result = await func(*args, **kwargs)
            return result
        except Exception as e:
            status = "error"
            logger.error("Function execution failed",
                        function=func.__name__,
                        error=str(e))
            raise
        finally:
            duration = time.time() - start_time
            REQUEST_DURATION.observe(duration)
            REQUEST_COUNT.labels(method=func.__name__, status=status).inc()

            logger.info("Function executed",
                       function=func.__name__,
                       duration=duration,
                       status=status)

    return wrapper

class HealthChecker:
    """–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""

    def __init__(self):
        self.checks = {}

    def register_check(self, name: str, check_func: Callable):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è."""
        self.checks[name] = check_func

    async def check_health(self) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –∑–¥–æ—Ä–æ–≤—å—è."""
        results = {}
        overall_status = "healthy"

        for name, check_func in self.checks.items():
            try:
                result = await check_func()
                results[name] = {"status": "healthy", "details": result}
            except Exception as e:
                results[name] = {"status": "unhealthy", "error": str(e)}
                overall_status = "unhealthy"

                logger.error("Health check failed",
                           check_name=name,
                           error=str(e))

        return {
            "status": overall_status,
            "checks": results,
            "timestamp": time.time()
        }

# Example health checks
async def database_health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    # –ü–æ–ø—ã—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
    async with get_db_connection() as conn:
        await conn.fetchval("SELECT 1")
    return {"latency": "< 10ms"}

async def llm_service_health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è LLM —Å–µ—Ä–≤–∏—Å–∞."""
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ LLM
    try:
        response = await llm_client.simple_query("test")
        return {"status": "responsive", "model": response.model}
    except Exception:
        raise Exception("LLM service unavailable")
```

## Best Practices –¥–ª—è Implementation Engineer

### 1. Code Quality Guidelines
- **Type Hints**: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–∏–ø–∏–∑–∞—Ü–∏—é
- **Documentation**: Docstrings –¥–ª—è –≤—Å–µ—Ö –ø—É–±–ª–∏—á–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
- **Error Handling**: Explicit exception handling
- **Testing**: –ú–∏–Ω–∏–º—É–º 80% –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏

### 2. Performance Optimization
- **Async/Await**: –î–ª—è I/O –æ–ø–µ—Ä–∞—Ü–∏–π
- **Caching**: Redis/Memcached –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- **Database**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –∏–Ω–¥–µ–∫—Å—ã
- **Monitoring**: –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫

### 3. Security Implementation
- **Input Validation**: Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- **Authentication**: JWT tokens, OAuth 2.0
- **Secrets Management**: Environment variables, HashiCorp Vault
- **SQL Injection**: Parameterized queries only

### 4. Deployment Strategy
- **Containerization**: Docker –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
- **Health Checks**: Liveness –∏ readiness probes
- **Scaling**: Horizontal –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
- **CI/CD**: –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ–ø–ª–æ–π

---

## üîç –î–û–ú–ï–ù–ù–´–ï –ó–ù–ê–ù–ò–Ø: [–û–ë–õ–ê–°–¢–¨]

```python
```python
```python
```python
```python
```python
```python
```python
### 1. Code Quality Guidelines
### 2. Performance Optimization
### 3. Security Implementation

---

**–í–µ—Ä—Å–∏—è:** 2.0 (–ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
**–î–∞—Ç–∞ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞:** 2025-10-14
**–ê–≤—Ç–æ—Ä —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞:** Archon Blueprint Architect
