# Module 06: Monitoring & Observability

**–í–µ—Ä—Å–∏—è:** 1.0
**–î–∞—Ç–∞:** 2025-10-17
**–ê–≤—Ç–æ—Ä:** Archon Implementation Engineer

**–ù–∞–∑–∞–¥ –∫:** [Implementation Engineer Knowledge Base](../archon_implementation_engineer_knowledge.md)

---

## üîß –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –¢–†–ò–ì–ì–ï–†–´ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –∑–∞–¥–∞—á Archon)

**–ö–æ–≥–¥–∞ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —á–∏—Ç–∞—Ç—å —ç—Ç–æ—Ç –º–æ–¥—É–ª—å:**
- Prometheus metrics implementation (RED method: Rate/Errors/Duration)
- Structured logging —Å structlog –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ
- Health check system —Å timeout, critical severity, parallel checks
- OpenTelemetry distributed tracing –¥–ª—è microservices
- Alert Manager integration —Å webhook notifications
- SLO/SLI monitoring (Service Level Objectives/Indicators)
- Performance monitoring decorator –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç—Ä–µ–∫–∏–Ω–≥–∞
- Three pillars of Observability: Metrics, Logs, Traces

---

## üîç –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê (–¥–ª—è –æ–±—â–µ–Ω–∏—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º)

**–†—É—Å—Å–∫–∏–µ:** –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, prometheus, –ª–æ–≥–∏, health check, —Ç—Ä–µ–π—Å–∏–Ω–≥, –∞–ª–µ—Ä—Ç—ã, SLO, observability, –º–µ—Ç—Ä–∏–∫–∏, distributed tracing, structured logging, correlation ID, spans

**English:** monitoring, prometheus, logs, health check, tracing, alerts, SLO, observability, metrics, distributed tracing, structured logging, correlation ID, spans

---

## üìå –ö–û–ì–î–ê –ß–ò–¢–ê–¢–¨ (–∫–æ–Ω—Ç–µ–∫—Å—Ç)

- Production –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–í–°–ï–ì–î–ê –¥–ª—è production)
- Debugging performance issues –∏ bottlenecks
- Distributed tracing –¥–ª—è microservices –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤ –∏ SLO/SLI targets
- Observability –¥–ª—è complex systems
- Proactive monitoring –∏ incident response
- Root cause analysis –¥–ª—è production incidents
- System reliability engineering (SRE)

---

## Comprehensive Monitoring Setup

### Prometheus Metrics Integration

```python
import logging
import time
from functools import wraps
from typing import Any, Callable, Dict
import structlog
from prometheus_client import Counter, Histogram, Gauge, Summary
import asyncio

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Prometheus Metrics Definitions
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Counters - –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ –≤–æ–∑—Ä–∞—Å—Ç–∞—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
REQUEST_COUNT = Counter(
    'agent_requests_total',
    'Total agent requests',
    ['method', 'status', 'endpoint']
)

ERROR_COUNT = Counter(
    'agent_errors_total',
    'Total agent errors',
    ['error_type', 'method']
)

# Histograms - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π
REQUEST_DURATION = Histogram(
    'agent_request_duration_seconds',
    'Request duration in seconds',
    ['method', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
)

LLM_TOKEN_COUNT = Histogram(
    'llm_tokens_used',
    'Number of LLM tokens used',
    ['model', 'operation'],
    buckets=[100, 500, 1000, 2000, 5000, 10000, 20000]
)

# Gauges - —Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Ä–∞—Å—Ç–∏ –∏ –ø–∞–¥–∞—Ç—å
ACTIVE_CONNECTIONS = Gauge(
    'agent_active_connections',
    'Active agent connections'
)

QUEUE_SIZE = Gauge(
    'agent_queue_size',
    'Current queue size',
    ['queue_name']
)

CACHE_SIZE = Gauge(
    'cache_entries_total',
    'Total number of cache entries'
)

# Summary - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å –∫–≤–∞–Ω—Ç–∏–ª—è–º–∏
RESPONSE_SIZE = Summary(
    'response_size_bytes',
    'Response size in bytes',
    ['endpoint']
)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Structured Logging Configuration
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,  # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        structlog.processors.TimeStamper(fmt="iso"),  # ISO timestamp
        structlog.processors.add_log_level,  # –î–æ–±–∞–≤–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å
        structlog.processors.StackInfoRenderer(),  # Stack traces
        structlog.processors.format_exc_info,  # Exception formatting
        structlog.processors.UnicodeDecoder(),  # UTF-8 –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        structlog.processors.JSONRenderer()  # JSON output
    ],
    wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
    context_class=dict,
    logger_factory=structlog.PrintLoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Performance Monitoring Decorator
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def monitor_performance(
    method: str = "unknown",
    endpoint: str = "unknown",
    track_tokens: bool = False
):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–π.

    Args:
        method: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫
        endpoint: Endpoint –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        track_tokens: –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            status = "success"

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            ACTIVE_CONNECTIONS.inc()

            try:
                result = await func(*args, **kwargs)

                # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                if track_tokens and hasattr(result, 'usage'):
                    LLM_TOKEN_COUNT.labels(
                        model=getattr(result, 'model', 'unknown'),
                        operation=method
                    ).observe(result.usage.total_tokens)

                # –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞
                if hasattr(result, 'data'):
                    response_size = len(str(result.data).encode('utf-8'))
                    RESPONSE_SIZE.labels(endpoint=endpoint).observe(response_size)

                return result

            except Exception as e:
                status = "error"
                error_type = type(e).__name__

                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
                logger.error(
                    "Function execution failed",
                    function=func.__name__,
                    method=method,
                    endpoint=endpoint,
                    error=str(e),
                    error_type=error_type,
                    exc_info=True
                )

                # –ú–µ—Ç—Ä–∏–∫–∞ –æ—à–∏–±–æ–∫
                ERROR_COUNT.labels(
                    error_type=error_type,
                    method=method
                ).inc()

                raise

            finally:
                # –ü–æ–¥—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                duration = time.time() - start_time

                # –ú–µ—Ç—Ä–∏–∫–∏
                REQUEST_DURATION.labels(
                    method=method,
                    endpoint=endpoint
                ).observe(duration)

                REQUEST_COUNT.labels(
                    method=method,
                    status=status,
                    endpoint=endpoint
                ).inc()

                ACTIVE_CONNECTIONS.dec()

                # Structured logging
                logger.info(
                    "Function executed",
                    function=func.__name__,
                    method=method,
                    endpoint=endpoint,
                    duration=duration,
                    status=status
                )

        return wrapper
    return decorator

# Usage Example
class MonitoredAgent:
    """–ê–≥–µ–Ω—Ç —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""

    @monitor_performance(method="query", endpoint="/api/query", track_tokens=True)
    async def process_query(self, query: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º."""
        # –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
        pass
```

---

## Health Check System

### Comprehensive Health Checker

```python
from typing import Dict, Any, Callable, Optional
from enum import Enum
import asyncio

class HealthStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã –∑–¥–æ—Ä–æ–≤—å—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"

class HealthChecker:
    """–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""

    def __init__(self):
        self.checks: Dict[str, Callable] = {}
        self.check_timeouts: Dict[str, int] = {}

    def register_check(
        self,
        name: str,
        check_func: Callable,
        timeout: int = 5,
        critical: bool = True
    ):
        """
        –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è.

        Args:
            name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            check_func: Async —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            timeout: Timeout –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            critical: –ö—Ä–∏—Ç–∏—á–Ω–∞ –ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –æ–±—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
        """
        self.checks[name] = {
            'func': check_func,
            'timeout': timeout,
            'critical': critical
        }

    async def check_health(self) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –∑–¥–æ—Ä–æ–≤—å—è."""
        results = {}
        overall_status = HealthStatus.HEALTHY
        start_time = time.time()

        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        check_tasks = []
        for name, check_config in self.checks.items():
            task = asyncio.create_task(
                self._execute_check(name, check_config)
            )
            check_tasks.append((name, task, check_config))

        # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        for name, task, config in check_tasks:
            try:
                result = await task
                results[name] = result

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
                if result['status'] == HealthStatus.UNHEALTHY.value:
                    if config['critical']:
                        overall_status = HealthStatus.UNHEALTHY
                    elif overall_status == HealthStatus.HEALTHY:
                        overall_status = HealthStatus.DEGRADED

            except Exception as e:
                logger.error(f"Health check {name} failed critically", error=str(e))
                results[name] = {
                    'status': HealthStatus.UNHEALTHY.value,
                    'error': str(e)
                }
                if config['critical']:
                    overall_status = HealthStatus.UNHEALTHY

        total_duration = time.time() - start_time

        return {
            'status': overall_status.value,
            'checks': results,
            'timestamp': time.time(),
            'duration_ms': int(total_duration * 1000)
        }

    async def _execute_check(
        self,
        name: str,
        config: Dict
    ) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å timeout."""
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å timeout
            check_result = await asyncio.wait_for(
                config['func'](),
                timeout=config['timeout']
            )

            return {
                'status': HealthStatus.HEALTHY.value,
                'details': check_result
            }

        except asyncio.TimeoutError:
            logger.warning(f"Health check {name} timed out")
            return {
                'status': HealthStatus.UNHEALTHY.value,
                'error': f'Timeout after {config["timeout"]}s'
            }

        except Exception as e:
            logger.error(f"Health check {name} failed", error=str(e))
            return {
                'status': HealthStatus.UNHEALTHY.value,
                'error': str(e)
            }

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Example Health Checks
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def database_health_check() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    start = time.time()

    try:
        async with get_db_connection() as conn:
            # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
            await conn.fetchval("SELECT 1")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            active_conns = await conn.fetchval(
                "SELECT count(*) FROM pg_stat_activity WHERE state = 'active'"
            )

        latency = (time.time() - start) * 1000

        return {
            'latency_ms': round(latency, 2),
            'active_connections': active_conns,
            'status': 'ok'
        }

    except Exception as e:
        raise Exception(f"Database unavailable: {str(e)}")

async def redis_health_check() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è Redis."""
    start = time.time()

    try:
        # Ping Redis
        pong = await redis_client.ping()

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        info = await redis_client.info()

        latency = (time.time() - start) * 1000

        return {
            'latency_ms': round(latency, 2),
            'used_memory_mb': round(info['used_memory'] / 1024 / 1024, 2),
            'connected_clients': info['connected_clients'],
            'status': 'ok'
        }

    except Exception as e:
        raise Exception(f"Redis unavailable: {str(e)}")

async def llm_service_health_check() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è LLM —Å–µ—Ä–≤–∏—Å–∞."""
    start = time.time()

    try:
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        response = await llm_client.simple_query("test")

        latency = (time.time() - start) * 1000

        return {
            'latency_ms': round(latency, 2),
            'model': response.model,
            'status': 'ok'
        }

    except Exception as e:
        raise Exception(f"LLM service unavailable: {str(e)}")

async def queue_health_check() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –æ—á–µ—Ä–µ–¥–µ–π."""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–µ–π
        queue_sizes = {}
        for queue_name in ['high_priority', 'normal', 'low_priority']:
            size = await get_queue_size(queue_name)
            queue_sizes[queue_name] = size
            QUEUE_SIZE.labels(queue_name=queue_name).set(size)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º dead letter queue
        dlq_size = await get_queue_size('dead_letter')

        return {
            'queue_sizes': queue_sizes,
            'dead_letter_queue': dlq_size,
            'status': 'ok' if dlq_size < 100 else 'warning'
        }

    except Exception as e:
        raise Exception(f"Queue system unavailable: {str(e)}")

# Setup Health Checker
health_checker = HealthChecker()
health_checker.register_check('database', database_health_check, timeout=5, critical=True)
health_checker.register_check('redis', redis_health_check, timeout=3, critical=True)
health_checker.register_check('llm_service', llm_service_health_check, timeout=10, critical=False)
health_checker.register_check('queues', queue_health_check, timeout=5, critical=False)
```

---

## Distributed Tracing

### OpenTelemetry Integration

```python
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.asyncpg import AsyncPGInstrumentor
from opentelemetry.instrumentation.redis import RedisInstrumentor

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# OpenTelemetry Setup
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def setup_tracing(service_name: str, otlp_endpoint: str):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ distributed tracing —Å OpenTelemetry."""

    # Resource - –æ–ø–∏—Å–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞
    resource = Resource.create({
        "service.name": service_name,
        "service.version": "1.0.0",
        "deployment.environment": os.getenv("ENVIRONMENT", "development")
    })

    # Tracer Provider
    provider = TracerProvider(resource=resource)

    # OTLP Exporter (–¥–ª—è Jaeger, Tempo, –∏–ª–∏ –¥—Ä—É–≥–æ–≥–æ backend)
    otlp_exporter = OTLPSpanExporter(
        endpoint=otlp_endpoint,
        insecure=True  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ TLS –≤ production
    )

    # Batch processor –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    processor = BatchSpanProcessor(otlp_exporter)
    provider.add_span_processor(processor)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π provider
    trace.set_tracer_provider(provider)

    # –ê–≤—Ç–æ–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ü–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫
    FastAPIInstrumentor.instrument()
    AsyncPGInstrumentor().instrument()
    RedisInstrumentor().instrument()

    return trace.get_tracer(__name__)

# Usage
tracer = setup_tracing("archon-agent", "http://localhost:4317")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Custom Tracing
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def process_with_tracing(query: str) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å —Ç—Ä–µ–π—Å–∏–Ω–≥–æ–º."""

    # –°–æ–∑–¥–∞–µ–º span –¥–ª—è –≤—Å–µ–π –æ–ø–µ—Ä–∞—Ü–∏–∏
    with tracer.start_as_current_span("process_query") as span:
        # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã
        span.set_attribute("query.length", len(query))
        span.set_attribute("query.type", "user_question")

        try:
            # –®–∞–≥ 1: –í–∞–ª–∏–¥–∞—Ü–∏—è
            with tracer.start_as_current_span("validate_query"):
                validated = await validate_query(query)
                span.set_attribute("validation.passed", True)

            # –®–∞–≥ 2: –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            with tracer.start_as_current_span("knowledge_search") as search_span:
                results = await search_knowledge(validated)
                search_span.set_attribute("results.count", len(results))

            # –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            with tracer.start_as_current_span("generate_response") as gen_span:
                response = await generate_response(results)
                gen_span.set_attribute("response.length", len(response))

            span.set_attribute("status", "success")
            return {"response": response, "status": "success"}

        except Exception as e:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –≤ span
            span.record_exception(e)
            span.set_attribute("status", "error")
            raise
```

---

## Alerting System

### Alert Manager Integration

```python
from typing import List, Dict
import aiohttp
from enum import Enum

class AlertSeverity(Enum):
    """–£—Ä–æ–≤–Ω–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∞–ª–µ—Ä—Ç–æ–≤."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class AlertManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∞–ª–µ—Ä—Ç–æ–≤ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö."""

    def __init__(self, webhook_url: str, service_name: str):
        self.webhook_url = webhook_url
        self.service_name = service_name
        self.alert_history: List[Dict] = []

    async def send_alert(
        self,
        title: str,
        message: str,
        severity: AlertSeverity = AlertSeverity.WARNING,
        metadata: Dict = None
    ):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª–µ—Ä—Ç–∞ –≤ —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""

        alert = {
            'service': self.service_name,
            'title': title,
            'message': message,
            'severity': severity.value,
            'timestamp': time.time(),
            'metadata': metadata or {}
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.alert_history.append(alert)
        if len(self.alert_history) > 1000:
            self.alert_history.pop(0)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º webhook
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.webhook_url,
                    json=alert,
                    timeout=5
                ) as response:
                    if response.status != 200:
                        logger.error(
                            "Failed to send alert",
                            status=response.status,
                            alert=title
                        )
        except Exception as e:
            logger.error("Alert delivery failed", error=str(e))

    async def check_and_alert_on_metrics(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–æ–≤."""

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ error rate
        error_rate = await self._get_error_rate()
        if error_rate > 0.05:  # 5% errors
            await self.send_alert(
                "High Error Rate Detected",
                f"Error rate is {error_rate*100:.2f}%",
                severity=AlertSeverity.ERROR,
                metadata={'error_rate': error_rate}
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ latency
        p95_latency = await self._get_p95_latency()
        if p95_latency > 2.0:  # 2 seconds
            await self.send_alert(
                "High Latency Detected",
                f"P95 latency is {p95_latency:.2f}s",
                severity=AlertSeverity.WARNING,
                metadata={'p95_latency': p95_latency}
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ queue size
        queue_size = await self._get_queue_size()
        if queue_size > 10000:
            await self.send_alert(
                "Queue Backlog",
                f"Queue size is {queue_size}",
                severity=AlertSeverity.WARNING,
                metadata={'queue_size': queue_size}
            )
```

---

## Best Practices –¥–ª—è Monitoring & Observability

### 1. –¢—Ä–∏ —Å—Ç–æ–ª–ø–∞ Observability

**Metrics (–ú–µ—Ç—Ä–∏–∫–∏):**
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π RED method: Rate, Errors, Duration
- ‚úÖ Golden signals: Latency, Traffic, Errors, Saturation
- ‚úÖ Business metrics: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –∫–æ–Ω–≤–µ—Ä—Å–∏–∏

**Logs (–õ–æ–≥–∏):**
- ‚úÖ Structured logging (JSON)
- ‚úÖ Correlation IDs –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
- ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —É—Ä–æ–≤–Ω–∏: DEBUG, INFO, WARNING, ERROR, CRITICAL

**Traces (–¢—Ä–µ–π—Å—ã):**
- ‚úÖ Distributed tracing –¥–ª—è microservices
- ‚úÖ Spans –¥–ª—è –∫–∞–∂–¥–æ–π –≤–∞–∂–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏
- ‚úÖ Attributes –∏ events –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

### 2. Alerting Best Practices

```python
# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π, actionable alert
alert_manager.send_alert(
    "Database connection pool exhausted",
    "All 20 connections in use for 5+ minutes. "
    "Consider scaling up or investigating slow queries.",
    severity=AlertSeverity.CRITICAL,
    metadata={
        'active_connections': 20,
        'max_connections': 20,
        'slow_queries_count': 15
    }
)

# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û - –Ω–µ–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π alert
alert_manager.send_alert(
    "Something wrong",
    "Check the system",
    severity=AlertSeverity.ERROR
)
```

### 3. SLO/SLI Monitoring

```python
# Service Level Indicators (SLI)
availability_sli = successful_requests / total_requests
latency_sli = requests_under_100ms / total_requests

# Service Level Objectives (SLO)
AVAILABILITY_SLO = 0.999  # 99.9% uptime
LATENCY_SLO = 0.95  # 95% requests under 100ms

# –ü—Ä–æ–≤–µ—Ä–∫–∞ SLO
if availability_sli < AVAILABILITY_SLO:
    alert_manager.send_alert(
        "SLO Breach: Availability",
        f"Current: {availability_sli*100:.2f}%, Target: {AVAILABILITY_SLO*100}%",
        severity=AlertSeverity.CRITICAL
    )
```

---

**–ù–∞–≤–∏–≥–∞—Ü–∏—è:**
- [‚Üê –ü—Ä–µ–¥—ã–¥—É—â–∏–π –º–æ–¥—É–ª—å: Deployment & DevOps](05_deployment_devops.md)
- [‚Üë –ù–∞–∑–∞–¥ –∫ Implementation Engineer Knowledge Base](../archon_implementation_engineer_knowledge.md)
