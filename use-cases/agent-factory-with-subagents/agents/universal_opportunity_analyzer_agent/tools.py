# -*- coding: utf-8 -*-
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤ –ª—é–±—ã—Ö –¥–æ–º–µ–Ω–∞—Ö
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—é, –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—é, –Ω—É–º–µ—Ä–æ–ª–æ–≥–∏—é, –±–∏–∑–Ω–µ—Å –∏ –¥—Ä—É–≥–∏–µ –æ–±–ª–∞—Å—Ç–∏
"""

import asyncio
import json
from typing import List, Dict, Any, Optional
from pydantic_ai import RunContext
from .dependencies import OpportunityAnalyzerDependencies, AGENT_ASSIGNEE_MAP

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ MCP –∫–ª–∏–µ–Ω—Ç–∞
try:
    from ...mcp_client import mcp_archon_rag_search_knowledge_base, mcp_archon_manage_task
except ImportError:
    # Fallback –µ—Å–ª–∏ MCP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    async def mcp_archon_rag_search_knowledge_base(*args, **kwargs):
        return {"success": False, "error": "MCP –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}
    
    async def mcp_archon_manage_task(*args, **kwargs):
        return {"success": False, "error": "MCP –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}

async def analyze_domain_opportunities(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    market_segment: str,
    analysis_type: str = "comprehensive",
    time_frame: str = "current"
) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ –¥–æ–º–µ–Ω–∞."""
    try:
        domain = ctx.deps.domain_type
        config = ctx.deps.analysis_config
        
        # –î–æ–º–µ–Ω–Ω–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        opportunities = {
            "domain": domain,
            "segment": market_segment,
            "analysis_type": analysis_type,
            "time_frame": time_frame,
            "opportunities": await _identify_domain_opportunities(domain, market_segment, config),
            "market_potential": await _assess_market_potential(domain, market_segment),
            "implementation_complexity": "medium",
            "competitive_landscape": "developing"
        }
        
        return json.dumps(opportunities, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π: {e}"

async def _identify_domain_opportunities(domain: str, segment: str, config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """–í—ã—è–≤–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞."""
    if domain == "psychology":
        return [
            {"type": "diagnostic_platform", "potential": "high", "description": "–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"},
            {"type": "therapy_tools", "potential": "medium", "description": "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ç–µ—Ä–∞–ø–∏–∏"},
            {"type": "educational_content", "potential": "high", "description": "–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç"}
        ]
    elif domain == "astrology":
        return [
            {"type": "calculation_service", "potential": "high", "description": "–°–µ—Ä–≤–∏—Å –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—á–µ—Ç–æ–≤"},
            {"type": "consultation_platform", "potential": "medium", "description": "–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π"}
        ]
    else:
        return [{"type": "generic_opportunity", "potential": "medium", "description": f"–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ {domain}"}]

async def _assess_market_potential(domain: str, segment: str) -> Dict[str, Any]:
    """–û—Ü–µ–Ω–∏—Ç—å —Ä—ã–Ω–æ—á–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª."""
    return {
        "size": "medium",
        "growth_rate": "15-25%",
        "saturation": "low",
        "barriers_to_entry": "medium"
    }

async def identify_pain_points(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    target_audience: str,
    research_depth: str = "comprehensive"
) -> str:
    """–í—ã—è–≤–∏—Ç—å –±–æ–ª–µ–≤—ã–µ —Ç–æ—á–∫–∏ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏."""
    try:
        domain = ctx.deps.domain_type
        pain_points = ctx.deps.get_pain_points_for_domain()
        
        analysis = {
            "domain": domain,
            "target_audience": target_audience,
            "research_depth": research_depth,
            "identified_pain_points": pain_points,
            "priority_ranking": await _rank_pain_points_by_urgency(domain, pain_points),
            "addressability": await _assess_pain_point_addressability(domain, pain_points)
        }
        
        return json.dumps(analysis, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤—ã—è–≤–ª–µ–Ω–∏—è –±–æ–ª–µ–≤—ã—Ö —Ç–æ—á–µ–∫: {e}"

async def _rank_pain_points_by_urgency(domain: str, pain_points: List[str]) -> List[Dict[str, Any]]:
    """–†–∞–Ω–∂–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–≤—ã–µ —Ç–æ—á–∫–∏ –ø–æ —Å—Ä–æ—á–Ω–æ—Å—Ç–∏."""
    # –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö
    ranked = []
    for i, point in enumerate(pain_points[:5]):  # –¢–æ–ø-5
        ranked.append({
            "pain_point": point,
            "urgency_score": 90 - (i * 10),
            "frequency": "high" if i < 2 else "medium"
        })
    return ranked

async def _assess_pain_point_addressability(domain: str, pain_points: List[str]) -> Dict[str, str]:
    """–û—Ü–µ–Ω–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏—è –±–æ–ª–µ–≤—ã—Ö —Ç–æ—á–µ–∫."""
    return {point: "high" if "depression" in point or "anxiety" in point else "medium" for point in pain_points[:3]}

async def evaluate_market_potential(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    opportunity_type: str,
    geographic_scope: str = "regional"
) -> str:
    """–û—Ü–µ–Ω–∏—Ç—å —Ä—ã–Ω–æ—á–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏."""
    try:
        evaluation = {
            "opportunity_type": opportunity_type,
            "geographic_scope": geographic_scope,
            "market_size": await _calculate_market_size(ctx.deps.domain_type, opportunity_type),
            "growth_potential": await _assess_growth_potential(ctx.deps.domain_type),
            "competition_level": "medium",
            "market_readiness": "developing",
            "revenue_potential": await _estimate_revenue_potential(opportunity_type)
        }
        
        return json.dumps(evaluation, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞: {e}"

async def _calculate_market_size(domain: str, opportunity_type: str) -> Dict[str, Any]:
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Ä–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞."""
    # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    return {
        "tam": "$1B+",  # Total Addressable Market
        "sam": "$100M",  # Serviceable Addressable Market
        "som": "$10M"    # Serviceable Obtainable Market
    }

async def _assess_growth_potential(domain: str) -> Dict[str, Any]:
    """–û—Ü–µ–Ω–∏—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞."""
    return {
        "annual_growth_rate": "15-25%",
        "market_maturity": "early",
        "adoption_curve": "accelerating"
    }

async def _estimate_revenue_potential(opportunity_type: str) -> Dict[str, Any]:
    """–û—Ü–µ–Ω–∏—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–æ—Ö–æ–¥–æ–≤."""
    return {
        "revenue_model": "subscription + services",
        "pricing_strategy": "freemium",
        "monetization_timeline": "6-12 months"
    }

async def search_opportunity_patterns(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    query: str,
    pattern_type: str = "market_trends"
) -> str:
    """–ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Archon RAG."""
    try:
        domain_tags = ctx.deps.knowledge_tags.copy()
        domain_tags.extend([ctx.deps.domain_type.replace("_", "-"), "opportunities", "market-analysis"])
        
        enhanced_query = f"{query} {pattern_type} {' '.join(domain_tags)}"
        
        result = await mcp_archon_rag_search_knowledge_base(
            query=enhanced_query,
            source_domain=ctx.deps.knowledge_domain,
            match_count=5
        )
        
        if result.get("success") and result.get("results"):
            patterns = "\n".join([
                f"**{r['metadata']['title']}:**\n{r['content']}"
                for r in result["results"]
            ])
            return f"–ü–∞—Ç—Ç–µ—Ä–Ω—ã –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è {ctx.deps.domain_type}:\n{patterns}"
        else:
            return f"‚ö†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è {ctx.deps.domain_type} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ä—ã–Ω–∫–∞."
            
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}"

# –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏)
async def break_down_to_microtasks(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    main_task: str,
    complexity_level: str = "medium"
) -> str:
    """–†–∞–∑–±–∏—Ç—å –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –Ω–∞ –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏."""
    domain = ctx.deps.domain_type
    microtasks = [
        f"–ê–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ –¥–æ–º–µ–Ω–∞ {domain} –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π",
        f"–í—ã—è–≤–ª–µ–Ω–∏–µ –±–æ–ª–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –≤ {domain}",
        f"–û—Ü–µ–Ω–∫–∞ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞",
        f"–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞",
        f"–†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π",
        f"–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"
    ]
    
    output = f"üìã **–ú–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤ {domain}:**\n"
    for i, task in enumerate(microtasks, 1):
        output += f"{i}. {task}\n"
    output += "\n‚úÖ –ë—É–¥—É –æ—Ç—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –∫–∞–∂–¥–æ–π –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏"
    return output

async def report_microtask_progress(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    microtask_number: int,
    microtask_description: str,
    status: str = "completed",
    details: str = ""
) -> str:
    """–û—Ç—á–µ—Ç –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –º–∏–∫—Ä–æ–∑–∞–¥–∞—á–∏."""
    status_emoji = {"started": "üîÑ", "in_progress": "‚è≥", "completed": "‚úÖ", "blocked": "üö´"}
    report = f"{status_emoji.get(status, 'üìù')} **–ú–∏–∫—Ä–æ–∑–∞–¥–∞—á–∞ {microtask_number}** ({status}): {microtask_description}"
    if details:
        report += f"\n   –î–µ—Ç–∞–ª–∏: {details}"
    return report

async def reflect_and_improve(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    completed_work: str,
    work_type: str = "opportunity_analysis"
) -> str:
    """–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π."""
    domain = ctx.deps.domain_type
    return f"""üîç **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤ {domain}:**

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
1. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
2. –ù—É–∂–Ω–∞ –±–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ TAM/SAM/SOM
3. –¢—Ä–µ–±—É–µ—Ç—Å—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –±–æ–ª–µ–≤—ã—Ö —Ç–æ—á–µ–∫

**–í–Ω–µ—Å–µ–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:**
- –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑ —á–µ—Ä–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏ {domain})
‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞ (–æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –¥–∞–Ω–Ω—ã—Ö)
‚úÖ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å (–≥–æ—Ç–æ–≤ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)

üéØ **–§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é**"""

async def check_delegation_need(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    current_task: str,
    current_agent_type: str = "opportunity_analyzer"
) -> str:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π."""
    keywords = current_task.lower().split()
    delegation_suggestions = []
    
    if any(keyword in keywords for keyword in ['–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã', 'competition', '–∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞']):
        delegation_suggestions.append("RAG Agent - –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ä—ã–Ω–∫–∞")
    
    if any(keyword in keywords for keyword in ['ui', 'ux', '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏', '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å']):
        delegation_suggestions.append("UI/UX Enhancement Agent - –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞")
    
    if delegation_suggestions:
        result = "ü§ù **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:**\n"
        for suggestion in delegation_suggestions:
            result += f"- {suggestion}\n"
        result += "\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ delegate_task_to_agent() –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–¥–∞—á."
    else:
        result = "‚úÖ –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ."
    
    return result

async def delegate_task_to_agent(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    target_agent: str,
    task_title: str,
    task_description: str,
    priority: str = "medium",
    context_data: Dict[str, Any] = None
) -> str:
    """–î–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É –¥—Ä—É–≥–æ–º—É –∞–≥–µ–Ω—Ç—É —á–µ—Ä–µ–∑ Archon."""
    try:
        if context_data is None:
            context_data = {
                "domain_type": ctx.deps.domain_type,
                "analysis_context": "Universal Opportunity Analyzer Agent"
            }
        
        task_result = await mcp_archon_manage_task(
            action="create",
            project_id=ctx.deps.archon_project_id,
            title=task_title,
            description=f"{task_description}\n\n**–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç Opportunity Analyzer:**\n{json.dumps(context_data, ensure_ascii=False, indent=2)}",
            assignee=AGENT_ASSIGNEE_MAP.get(target_agent, "Archon Analysis Lead"),
            status="todo",
            feature=f"–î–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç Opportunity Analyzer",
            task_order=50
        )
        
        return f"‚úÖ –ó–∞–¥–∞—á–∞ —É—Å–ø–µ—à–Ω–æ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∞ –∞–≥–µ–Ω—Ç—É {target_agent}:\n- –ó–∞–¥–∞—á–∞ ID: {task_result.get('task_id')}\n- –°—Ç–∞—Ç—É—Å: —Å–æ–∑–¥–∞–Ω–∞ –≤ Archon\n- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}\n- –î–æ–º–µ–Ω: {ctx.deps.domain_type}"
    
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}"

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
async def assess_competition_landscape(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    opportunity_area: str,
    analysis_depth: str = "comprehensive"
) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –ª–∞–Ω–¥—à–∞—Ñ—Ç."""
    try:
        domain = ctx.deps.domain_type
        landscape = {
            "opportunity_area": opportunity_area,
            "domain": domain,
            "analysis_depth": analysis_depth,
            "direct_competitors": await _identify_direct_competitors(domain, opportunity_area),
            "indirect_competitors": await _identify_indirect_competitors(domain),
            "market_gaps": await _identify_market_gaps(domain, opportunity_area),
            "competitive_advantages": await _suggest_competitive_advantages(domain)
        }
        
        return json.dumps(landscape, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {e}"

async def _identify_direct_competitors(domain: str, area: str) -> List[Dict[str, Any]]:
    """–í—ã—è–≤–∏—Ç—å –ø—Ä—è–º—ã—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤."""
    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    if domain == "psychology":
        return [{"name": "BetterHelp", "strength": "high", "focus": "online therapy"}]
    return [{"name": "Generic Competitor", "strength": "medium", "focus": area}]

async def _identify_indirect_competitors(domain: str) -> List[str]:
    """–í—ã—è–≤–∏—Ç—å –∫–æ—Å–≤–µ–Ω–Ω—ã—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤."""
    return ["Self-help books", "YouTube channels", "Traditional services"]

async def _identify_market_gaps(domain: str, area: str) -> List[str]:
    """–í—ã—è–≤–∏—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ —Ä—ã–Ω–∫–µ."""
    return ["Localized content", "Affordable solutions", "Mobile-first approach"]

async def _suggest_competitive_advantages(domain: str) -> List[str]:
    """–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞."""
    return ["AI-powered personalization", "Scientific validation", "Multi-modal content"]

async def calculate_opportunity_score(
    ctx: RunContext[OpportunityAnalyzerDependencies],
    opportunity_data: str,
    scoring_model: str = "comprehensive"
) -> str:
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å–∫–æ—Ä–∏–Ω–≥ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏."""
    try:
        criteria = ctx.deps.get_analysis_criteria()
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞
        scores = {
            "market_size": 85,
            "growth_potential": 75,
            "competition_level": 60,  # –ù–∏–∑–∫–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è = –≤—ã—Å–æ–∫–∏–π –±–∞–ª–ª
            "implementation_complexity": 70,
            "roi_potential": 80
        }
        
        # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π –æ–±—â–∏–π —Å–∫–æ—Ä
        weights = {"market_size": 0.25, "growth_potential": 0.25, "competition_level": 0.2, 
                  "implementation_complexity": 0.15, "roi_potential": 0.15}
        
        total_score = sum(scores[key] * weights[key] for key in scores)
        
        scoring_result = {
            "opportunity_score": round(total_score, 1),
            "scoring_model": scoring_model,
            "detailed_scores": scores,
            "weights_used": weights,
            "recommendation": "High Priority" if total_score > 75 else "Medium Priority" if total_score > 60 else "Low Priority",
            "confidence_level": "High" if scoring_model == "comprehensive" else "Medium"
        }
        
        return json.dumps(scoring_result, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å–∫–æ—Ä–∏–Ω–≥–∞: {e}"