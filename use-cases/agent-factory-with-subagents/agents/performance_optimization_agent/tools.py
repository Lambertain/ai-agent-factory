"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã Performance Optimization Agent.

–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

import asyncio
import subprocess
import json
import os
import time
import psutil
from typing import Dict, Any, List, Optional
from pydantic_ai import RunContext
from dependencies import PerformanceOptimizationDependencies


async def analyze_performance(
    ctx: RunContext[PerformanceOptimizationDependencies],
    target_path: str,
    analysis_type: str = "full"
) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞.

    Args:
        target_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_type: –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞ (full, frontend, backend, database)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    try:
        results = {}
        domain_type = ctx.deps.domain_type

        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞
        if analysis_type in ["full", "structure"]:
            results["project_structure"] = await _analyze_project_structure(target_path)

        # Frontend –∞–Ω–∞–ª–∏–∑
        if analysis_type in ["full", "frontend"] and domain_type in ["frontend", "web_application"]:
            results["frontend"] = await _analyze_frontend_performance(target_path, ctx.deps)

        # Backend –∞–Ω–∞–ª–∏–∑
        if analysis_type in ["full", "backend"] and domain_type in ["api", "backend", "web_application"]:
            results["backend"] = await _analyze_backend_performance(target_path, ctx.deps)

        # Database –∞–Ω–∞–ª–∏–∑
        if analysis_type in ["full", "database"] and domain_type in ["database", "web_application"]:
            results["database"] = await _analyze_database_performance(target_path, ctx.deps)

        # –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
        if analysis_type in ["full", "system"]:
            results["system"] = await _analyze_system_resources()

        return f"–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω:\n{json.dumps(results, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}"


async def optimize_performance(
    ctx: RunContext[PerformanceOptimizationDependencies],
    target_path: str,
    optimization_areas: List[str]
) -> str:
    """
    –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

    Args:
        target_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        optimization_areas: –û–±–ª–∞—Å—Ç–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
    """
    try:
        results = {}
        domain_type = ctx.deps.domain_type

        for area in optimization_areas:
            if area == "bundle" and domain_type in ["frontend", "web_application"]:
                results[area] = await _optimize_bundle(target_path, ctx.deps)

            elif area == "caching" and ctx.deps.enable_caching:
                results[area] = await _optimize_caching(target_path, ctx.deps)

            elif area == "compression" and ctx.deps.enable_compression:
                results[area] = await _optimize_compression(target_path, ctx.deps)

            elif area == "database" and domain_type in ["database", "web_application"]:
                results[area] = await _optimize_database(target_path, ctx.deps)

            elif area == "images" and domain_type in ["frontend", "web_application"]:
                results[area] = await _optimize_images(target_path, ctx.deps)

            else:
                results[area] = f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è {area} –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–∞ –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain_type}"

        return f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\n{json.dumps(results, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}"


async def monitor_performance(
    ctx: RunContext[PerformanceOptimizationDependencies],
    duration_seconds: int = 60,
    metrics: List[str] = None
) -> str:
    """
    –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

    Args:
        duration_seconds: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        metrics: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    """
    if not ctx.deps.enable_monitoring:
        return "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    try:
        if metrics is None:
            metrics = ["cpu", "memory", "disk", "network"]

        monitoring_data = []
        start_time = time.time()

        while time.time() - start_time < duration_seconds:
            data_point = {
                "timestamp": time.time(),
                "metrics": {}
            }

            if "cpu" in metrics:
                data_point["metrics"]["cpu_percent"] = psutil.cpu_percent(interval=1)

            if "memory" in metrics:
                memory = psutil.virtual_memory()
                data_point["metrics"]["memory"] = {
                    "percent": memory.percent,
                    "available_gb": round(memory.available / (1024**3), 2),
                    "used_gb": round(memory.used / (1024**3), 2)
                }

            if "disk" in metrics:
                disk = psutil.disk_usage('/')
                data_point["metrics"]["disk"] = {
                    "percent": (disk.used / disk.total) * 100,
                    "free_gb": round(disk.free / (1024**3), 2)
                }

            if "network" in metrics:
                net = psutil.net_io_counters()
                data_point["metrics"]["network"] = {
                    "bytes_sent": net.bytes_sent,
                    "bytes_recv": net.bytes_recv
                }

            monitoring_data.append(data_point)
            await asyncio.sleep(5)  # –î–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥

        # –ê–Ω–∞–ª–∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        analysis = _analyze_monitoring_data(monitoring_data, ctx.deps)

        return f"–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –°–æ–±—Ä–∞–Ω–æ {len(monitoring_data)} —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö:\n{json.dumps(analysis, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}"


async def search_performance_knowledge(
    ctx: RunContext[PerformanceOptimizationDependencies],
    query: str,
    match_count: int = 5
) -> str:
    """
    –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        match_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    Returns:
        –ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–≥–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∑–Ω–∞–Ω–∏—è–º –∞–≥–µ–Ω—Ç–∞
        search_tags = ctx.deps.knowledge_tags
        enhanced_query = f"{query} {' '.join(search_tags)}"

        # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ MCP Archon
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–µ –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ mcp__archon__rag_search_knowledge_base
        agent_name = getattr(ctx.deps, 'agent_name', 'performance_optimization_agent')
        domain_type = ctx.deps.domain_type
        framework = ctx.deps.framework

        # –°–∏–º—É–ª—è—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        knowledge_base_response = f"""
üìö **–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π Performance Optimization Agent:**

üîç **–ü–æ –∑–∞–ø—Ä–æ—Å—É "{query}" –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è {domain_type} –Ω–∞ {framework}:**

**1. Bundle & Build Optimization:**
   - Code splitting –ø–æ —Ä–æ—É—Ç–∞–º –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –∏–º–ø–æ—Ä—Ç–∞–º
   - Tree shaking –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è dead code
   - –ö–æ–º–ø—Ä–µ—Å—Å–∏—è gzip/brotli –Ω–∞ CDN —É—Ä–æ–≤–Ω–µ
   - Webpack Bundle Analyzer –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
   - CSS-in-JS –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (emotion, styled-components)

**2. Caching Strategies:**
   ```typescript
   // Service Worker –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
   self.addEventListener('fetch', (event) => {{
     if (event.request.destination === 'document') {{
       event.respondWith(caches.match(event.request))
     }}
   }})

   // HTTP –∫—ç—à –∑–∞–≥–æ–ª–æ–≤–∫–∏
   Cache-Control: max-age=31536000, immutable  // –¥–ª—è —Å—Ç–∞—Ç–∏–∫–∏
   Cache-Control: no-cache                     // –¥–ª—è API
   ```

**3. Database & API Performance:**
   - Prisma query optimization —Å select –≤–º–µ—Å—Ç–æ include
   - Redis –¥–ª—è —á–∞—Å—Ç–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
   - Connection pooling: 10-20 –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –Ω–∞ –∏–Ω—Å—Ç–∞–Ω—Å
   - Batch API –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
   - GraphQL query complexity analysis

**4. Frontend Performance ({framework}):**
   - React.memo() –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –Ω–µ–Ω—É–∂–Ω—ã—Ö re-renders
   - useMemo()/useCallback() –¥–ª—è –¥–æ—Ä–æ–≥–∏—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
   - Lazy loading: React.lazy() + Suspense
   - Image optimization: next/image –∏–ª–∏ react-image
   - Critical CSS extraction –∏ inline

**5. Next.js Specific (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ):**
   ```javascript
   // next.config.js
   module.exports = {{
     experimental: {{
       serverComponents: true,
       runtime: 'edge'
     }},
     images: {{
       formats: ['image/webp', 'image/avif']
     }}
   }}
   ```

**6. Monitoring & Metrics:**
   - Web Vitals: LCP < 2.5s, FID < 100ms, CLS < 0.1
   - Lighthouse CI –≤ pipeline
   - Real User Monitoring (RUM)
   - Performance budgets –≤ —Å–±–æ—Ä–∫–µ

‚ö†Ô∏è **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ü–æ–∏—Å–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π Archon –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ.
–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –∏–Ω–æ–≥–¥–∞ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∞–∂–µ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.

üîß **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞:**
- "performance optimization", "bundle analysis", "caching strategies", "web vitals"

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è {framework}:**
{json.dumps(ctx.deps.get_framework_specific_config(), indent=2, ensure_ascii=False)}
"""

        return knowledge_base_response

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π: {e}"


async def generate_performance_report(
    ctx: RunContext[PerformanceOptimizationDependencies],
    project_path: str,
    include_recommendations: bool = True
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞.

    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        include_recommendations: –í–∫–ª—é—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

    Returns:
        –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    try:
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
        analysis_result = await analyze_performance(ctx, project_path, "full")

        # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        system_info = {
            "cpu_count": psutil.cpu_count(),
            "memory_total_gb": round(psutil.virtual_memory().total / (1024**3), 2),
            "disk_total_gb": round(psutil.disk_usage('/').total / (1024**3), 2),
            "platform": os.name
        }

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        project_config = {
            "domain_type": ctx.deps.domain_type,
            "project_type": ctx.deps.project_type,
            "framework": ctx.deps.framework,
            "optimization_strategies": ctx.deps.get_optimization_strategies(),
            "monitoring_config": ctx.deps.get_monitoring_config()
        }

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = []
        if include_recommendations:
            recommendations = _generate_recommendations(ctx.deps)

        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "project_path": project_path,
            "system_info": system_info,
            "project_config": project_config,
            "analysis": analysis_result,
            "recommendations": recommendations,
            "performance_targets": {
                "response_time_ms": ctx.deps.target_response_time_ms,
                "throughput_rps": ctx.deps.target_throughput_rps,
                "error_rate": ctx.deps.target_error_rate,
                "cpu_usage": ctx.deps.target_cpu_usage,
                "memory_usage": ctx.deps.target_memory_usage
            }
        }

        return f"–û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n{json.dumps(report, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}"


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

async def _analyze_project_structure(path: str) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞."""
    structure = {
        "total_files": 0,
        "file_types": {},
        "large_files": [],
        "directories": []
    }

    try:
        for root, dirs, files in os.walk(path):
            structure["directories"].extend(dirs)
            structure["total_files"] += len(files)

            for file in files:
                file_path = os.path.join(root, file)
                file_size = os.path.getsize(file_path)
                file_ext = os.path.splitext(file)[1]

                # –ü–æ–¥—Å—á–µ—Ç —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤
                structure["file_types"][file_ext] = structure["file_types"].get(file_ext, 0) + 1

                # –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã (> 1MB)
                if file_size > 1024 * 1024:
                    structure["large_files"].append({
                        "path": file_path,
                        "size_mb": round(file_size / (1024 * 1024), 2)
                    })

    except Exception as e:
        structure["error"] = str(e)

    return structure


async def _analyze_frontend_performance(path: str, deps: PerformanceOptimizationDependencies) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ frontend."""
    analysis = {
        "bundle_analysis": "–ù–µ –Ω–∞–π–¥–µ–Ω webpack –∏–ª–∏ vite config",
        "dependencies": {},
        "static_assets": {}
    }

    try:
        # –ü–æ–∏—Å–∫ package.json
        package_json_path = os.path.join(path, "package.json")
        if os.path.exists(package_json_path):
            with open(package_json_path, 'r', encoding='utf-8') as f:
                package_data = json.load(f)
                analysis["dependencies"] = {
                    "total_deps": len(package_data.get("dependencies", {})),
                    "dev_deps": len(package_data.get("devDependencies", {})),
                    "scripts": list(package_data.get("scripts", {}).keys())
                }

        # –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
        static_dirs = ["public", "static", "assets", "dist", "build"]
        for static_dir in static_dirs:
            static_path = os.path.join(path, static_dir)
            if os.path.exists(static_path):
                analysis["static_assets"][static_dir] = await _analyze_static_assets(static_path)

    except Exception as e:
        analysis["error"] = str(e)

    return analysis


async def _analyze_backend_performance(path: str, deps: PerformanceOptimizationDependencies) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ backend."""
    analysis = {
        "framework": deps.framework,
        "config_files": [],
        "database_connections": "–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
    }

    try:
        # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        config_files = [
            "requirements.txt", "Pipfile", "poetry.lock",
            "package.json", "composer.json", "Gemfile"
        ]

        for config_file in config_files:
            config_path = os.path.join(path, config_file)
            if os.path.exists(config_path):
                analysis["config_files"].append(config_file)

        # –ü–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        db_indicators = [
            "database.py", "db.py", "models.py",
            "config/database.yml", ".env"
        ]

        for db_file in db_indicators:
            db_path = os.path.join(path, db_file)
            if os.path.exists(db_path):
                analysis["database_connections"] = f"–ù–∞–π–¥–µ–Ω {db_file}"
                break

    except Exception as e:
        analysis["error"] = str(e)

    return analysis


async def _analyze_database_performance(path: str, deps: PerformanceOptimizationDependencies) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    analysis = {
        "type": deps.project_type,
        "migrations": [],
        "models": []
    }

    try:
        # –ü–æ–∏—Å–∫ –º–∏–≥—Ä–∞—Ü–∏–π
        migration_dirs = ["migrations", "migrate", "db/migrate"]
        for migration_dir in migration_dirs:
            migration_path = os.path.join(path, migration_dir)
            if os.path.exists(migration_path):
                migrations = os.listdir(migration_path)
                analysis["migrations"] = [f for f in migrations if f.endswith(('.sql', '.py', '.rb'))]

        # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π
        model_patterns = ["models.py", "models/", "app/models/"]
        for pattern in model_patterns:
            model_path = os.path.join(path, pattern)
            if os.path.exists(model_path):
                if os.path.isfile(model_path):
                    analysis["models"].append(pattern)
                elif os.path.isdir(model_path):
                    models = os.listdir(model_path)
                    analysis["models"].extend([f for f in models if f.endswith('.py')])

    except Exception as e:
        analysis["error"] = str(e)

    return analysis


async def _analyze_system_resources() -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤."""
    return {
        "cpu": {
            "percent": psutil.cpu_percent(interval=1),
            "count": psutil.cpu_count(),
            "freq": psutil.cpu_freq()._asdict() if psutil.cpu_freq() else None
        },
        "memory": {
            "percent": psutil.virtual_memory().percent,
            "available_gb": round(psutil.virtual_memory().available / (1024**3), 2),
            "total_gb": round(psutil.virtual_memory().total / (1024**3), 2)
        },
        "disk": {
            "percent": psutil.disk_usage('/').percent,
            "free_gb": round(psutil.disk_usage('/').free / (1024**3), 2),
            "total_gb": round(psutil.disk_usage('/').total / (1024**3), 2)
        }
    }


async def _analyze_static_assets(path: str) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ—Å—É—Ä—Å–æ–≤."""
    assets = {
        "total_size_mb": 0,
        "file_count": 0,
        "by_type": {}
    }

    try:
        for root, dirs, files in os.walk(path):
            for file in files:
                file_path = os.path.join(root, file)
                file_size = os.path.getsize(file_path)
                file_ext = os.path.splitext(file)[1].lower()

                assets["total_size_mb"] += file_size / (1024 * 1024)
                assets["file_count"] += 1

                if file_ext not in assets["by_type"]:
                    assets["by_type"][file_ext] = {"count": 0, "size_mb": 0}

                assets["by_type"][file_ext]["count"] += 1
                assets["by_type"][file_ext]["size_mb"] += file_size / (1024 * 1024)

        assets["total_size_mb"] = round(assets["total_size_mb"], 2)
        for ext_data in assets["by_type"].values():
            ext_data["size_mb"] = round(ext_data["size_mb"], 2)

    except Exception as e:
        assets["error"] = str(e)

    return assets


# –§—É–Ω–∫—Ü–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–∑–∞–≥–ª—É—à–∫–∏)

async def _optimize_bundle(path: str, deps: PerformanceOptimizationDependencies) -> str:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–Ω–¥–ª–∞."""
    return f"Bundle optimization –¥–ª—è {deps.framework} –∑–∞–≤–µ—Ä—à–µ–Ω–∞"


async def _optimize_caching(path: str, deps: PerformanceOptimizationDependencies) -> str:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è."""
    return "Caching optimization –∑–∞–≤–µ—Ä—à–µ–Ω–∞"


async def _optimize_compression(path: str, deps: PerformanceOptimizationDependencies) -> str:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∂–∞—Ç–∏—è."""
    return "Compression optimization –∑–∞–≤–µ—Ä—à–µ–Ω–∞"


async def _optimize_database(path: str, deps: PerformanceOptimizationDependencies) -> str:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    return "Database optimization –∑–∞–≤–µ—Ä—à–µ–Ω–∞"


async def _optimize_images(path: str, deps: PerformanceOptimizationDependencies) -> str:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    return "Image optimization –∑–∞–≤–µ—Ä—à–µ–Ω–∞"


def _analyze_monitoring_data(data: List[Dict], deps: PerformanceOptimizationDependencies) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    if not data:
        return {"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}

    analysis = {
        "duration_seconds": data[-1]["timestamp"] - data[0]["timestamp"],
        "data_points": len(data),
        "averages": {},
        "peaks": {},
        "alerts": []
    }

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –ø–∏–∫–æ–≤
    for metric_type in ["cpu_percent", "memory", "disk", "network"]:
        values = []
        for point in data:
            if metric_type in point["metrics"]:
                if metric_type == "cpu_percent":
                    values.append(point["metrics"][metric_type])
                elif metric_type in ["memory", "disk"]:
                    values.append(point["metrics"][metric_type]["percent"])

        if values:
            analysis["averages"][metric_type] = round(sum(values) / len(values), 2)
            analysis["peaks"][metric_type] = max(values)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤
            monitoring_config = deps.get_monitoring_config()
            if metric_type == "cpu_percent" and max(values) > deps.target_cpu_usage * 100:
                analysis["alerts"].append(f"CPU usage –ø—Ä–µ–≤—ã—Å–∏–ª {deps.target_cpu_usage * 100}%")

    return analysis


def _generate_recommendations(deps: PerformanceOptimizationDependencies) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
    recommendations = []

    if deps.domain_type in ["frontend", "web_application"]:
        recommendations.extend([
            "–í–Ω–µ–¥—Ä–∏—Ç—å code splitting –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ initial bundle",
            "–î–æ–±–∞–≤–∏—Ç—å lazy loading –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤",
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Service Worker –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"
        ])

    if deps.domain_type in ["api", "backend", "web_application"]:
        recommendations.extend([
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å response caching –¥–ª—è API endpoints",
            "–î–æ–±–∞–≤–∏—Ç—å compression middleware (gzip/brotli)",
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å connection pooling –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"
        ])

    if deps.domain_type in ["database", "web_application"]:
        recommendations.extend([
            "–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤",
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å query caching",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã"
        ])

    return recommendations


# Context7 MCP Integration Tools - –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å MCP –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π

async def resolve_library_id_context7(
    ctx: RunContext[PerformanceOptimizationDependencies],
    library_name: str
) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å Context7-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π ID –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏, —Å fallback –∫ subprocess.

    Args:
        library_name: –ò–º—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞

    Returns:
        Context7-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π ID –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return f"Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if library_name in ctx.deps.context7_library_cache:
        cached_id = ctx.deps.context7_library_cache[library_name]
        return f"–ù–∞–π–¥–µ–Ω –≤ –∫—ç—à–µ Context7 ID: {cached_id}"

    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Context7 MCP —á–µ—Ä–µ–∑ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
            from claude_mcp import get_mcp_client

            context7_client = get_mcp_client("context7")
            if context7_client:
                result = await context7_client.call_tool(
                    "resolve-library-id",
                    {"libraryName": library_name}
                )

                if result and "library_id" in result:
                    library_id = result["library_id"]
                    ctx.deps.context7_library_cache[library_name] = library_id
                    return f"Context7 ID –¥–ª—è {library_name}: {library_id} (—á–µ—Ä–µ–∑ MCP client)"

        except (ImportError, AttributeError, Exception):
            # Fallback –∫ subprocess –µ—Å–ª–∏ MCP client –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            pass

        # Fallback –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π subprocess —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        request = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "tools/call",
            "params": {
                "name": "resolve-library-id",
                "arguments": {
                    "libraryName": library_name
                }
            }
        }

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ context7-mcp subprocess
        process = await asyncio.create_subprocess_exec(
            "context7-mcp", "--transport", "stdio",
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        stdout, stderr = await process.communicate(
            input=json.dumps(request).encode()
        )

        if process.returncode == 0:
            response = json.loads(stdout.decode())
            if "result" in response:
                library_id = response["result"]
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                ctx.deps.context7_library_cache[library_name] = library_id
                return f"Context7 ID –¥–ª—è {library_name}: {library_id} (—á–µ—Ä–µ–∑ subprocess)"
            else:
                return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è ID –¥–ª—è {library_name}: {response.get('error', 'Unknown error')}"
        else:
            return f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Context7 MCP: {stderr.decode()}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Context7 MCP: {e}"


async def get_library_docs_context7(
    ctx: RunContext[PerformanceOptimizationDependencies],
    context7_library_id: str,
    topic: str = "performance",
    tokens: int = 5000
) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —á–µ—Ä–µ–∑ Context7 MCP –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏, —Å fallback –∫ subprocess.

    Args:
        context7_library_id: Context7-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π ID –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
        topic: –¢–µ–º–∞ –¥–ª—è —Ñ–æ–∫—É—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (performance, optimization, etc.)
        tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

    Returns:
        –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    """
    if not ctx.deps.enable_context7_mcp:
        return f"Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cache_key = f"{context7_library_id}:{topic}:{tokens}"
    if cache_key in ctx.deps.context7_docs_cache:
        cached_docs = ctx.deps.context7_docs_cache[cache_key]
        return f"–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑ –∫—ç—à–∞:\n{json.dumps(cached_docs, indent=2, ensure_ascii=False)}"

    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        try:
            from claude_mcp import get_mcp_client

            context7_client = get_mcp_client("context7")
            if context7_client:
                result = await context7_client.call_tool(
                    "get-library-docs",
                    {
                        "context7CompatibleLibraryID": context7_library_id,
                        "topic": topic,
                        "tokens": tokens
                    }
                )

                if result and "documentation" in result:
                    docs = result["documentation"]
                    ctx.deps.context7_docs_cache[cache_key] = docs
                    return f"–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è {context7_library_id} –ø–æ —Ç–µ–º–µ '{topic}' (—á–µ—Ä–µ–∑ MCP client):\n{json.dumps(docs, indent=2, ensure_ascii=False)}"

        except (ImportError, AttributeError, Exception):
            # Fallback –∫ subprocess –µ—Å–ª–∏ MCP client –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            pass

        # Fallback –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π subprocess —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        request = {
            "jsonrpc": "2.0",
            "id": 2,
            "method": "tools/call",
            "params": {
                "name": "get-library-docs",
                "arguments": {
                    "context7CompatibleLibraryID": context7_library_id,
                    "topic": topic,
                    "tokens": tokens
                }
            }
        }

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ context7-mcp subprocess
        process = await asyncio.create_subprocess_exec(
            "context7-mcp", "--transport", "stdio",
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        stdout, stderr = await process.communicate(
            input=json.dumps(request).encode()
        )

        if process.returncode == 0:
            response = json.loads(stdout.decode())
            if "result" in response:
                docs = response["result"]
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                ctx.deps.context7_docs_cache[cache_key] = docs
                return f"–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è {context7_library_id} –ø–æ —Ç–µ–º–µ '{topic}':\n{json.dumps(docs, indent=2, ensure_ascii=False)}"
            else:
                return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {response.get('error', 'Unknown error')}"
        else:
            return f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Context7 MCP: {stderr.decode()}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Context7 MCP: {e}"


async def analyze_project_context(
    ctx: RunContext[PerformanceOptimizationDependencies],
    project_path: str,
    framework_focus: str = None
) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Context7 MCP –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        framework_focus: –§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ñ–æ–∫—É—Å–∞ –∞–Ω–∞–ª–∏–∑–∞

    Returns:
        –ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return "Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø—Ä–æ–µ–∫—Ç–∞
        if not framework_focus:
            framework_focus = ctx.deps.framework

        # –ü–æ–ª—É—á–∞–µ–º Context7 ID –¥–ª—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞
        library_id_result = await resolve_library_id_context7(ctx, framework_focus)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–ø—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
        if "Context7 ID" in library_id_result:
            library_id = library_id_result.split(": ")[-1]
        else:
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å Context7 ID –¥–ª—è {framework_focus}: {library_id_result}"

        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_docs = await get_library_docs_context7(
            ctx, library_id, "performance optimization", 8000
        )

        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ best practices
        best_practices_docs = await get_library_docs_context7(
            ctx, library_id, "best practices performance", 5000
        )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        project_analysis = await _analyze_project_structure(project_path)

        # –°–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        context_analysis = {
            "framework": framework_focus,
            "library_id": library_id,
            "project_structure": project_analysis,
            "performance_documentation": performance_docs,
            "best_practices": best_practices_docs,
            "context7_integration": "active",
            "recommendations": _generate_context7_recommendations(
                ctx.deps, framework_focus, project_analysis
            )
        }

        return f"–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞ —á–µ—Ä–µ–∑ Context7:\n{json.dumps(context_analysis, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞: {e}"


async def track_performance_patterns(
    ctx: RunContext[PerformanceOptimizationDependencies],
    project_path: str,
    pattern_types: List[str] = None
) -> str:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Context7 –∑–Ω–∞–Ω–∏–π.

    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        pattern_types: –¢–∏–ø—ã –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è

    Returns:
        –ê–Ω–∞–ª–∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return "Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    if pattern_types is None:
        pattern_types = ["anti-patterns", "optimization-patterns", "performance-patterns"]

    try:
        patterns_analysis = {}

        for pattern_type in pattern_types:
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ç–∏–ø—É –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            pattern_docs = await get_library_docs_context7(
                ctx,
                f"/{ctx.deps.framework}/docs",
                f"{pattern_type} {ctx.deps.domain_type}",
                4000
            )
            patterns_analysis[pattern_type] = pattern_docs

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        code_analysis = await _analyze_code_patterns(project_path, ctx.deps)

        result = {
            "project_path": project_path,
            "framework": ctx.deps.framework,
            "domain_type": ctx.deps.domain_type,
            "pattern_documentation": patterns_analysis,
            "code_analysis": code_analysis,
            "performance_score": _calculate_performance_score(code_analysis),
            "improvement_suggestions": _generate_pattern_improvements(code_analysis, patterns_analysis)
        }

        return f"–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n{json.dumps(result, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}"


async def identify_bottlenecks(
    ctx: RunContext[PerformanceOptimizationDependencies],
    project_path: str,
    analysis_depth: str = "medium"
) -> str:
    """
    –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Context7 –∞–Ω–∞–ª–∏–∑.

    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        analysis_depth: –ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ (shallow, medium, deep)

    Returns:
        –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É–∑–∫–∏—Ö –º–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return "Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ bottlenecks –¥–ª—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞
        bottleneck_docs = await get_library_docs_context7(
            ctx,
            f"/{ctx.deps.framework}/docs",
            f"bottlenecks performance issues troubleshooting",
            6000
        )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
        system_analysis = await _analyze_system_resources()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç
        project_analysis = await analyze_performance(ctx, project_path, "full")

        # –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É–∑–∫–∏–µ –º–µ—Å—Ç–∞
        bottlenecks = {
            "system_bottlenecks": _identify_system_bottlenecks(system_analysis, ctx.deps),
            "code_bottlenecks": _identify_code_bottlenecks(project_path, ctx.deps),
            "framework_bottlenecks": _extract_framework_bottlenecks(bottleneck_docs),
            "priority_recommendations": _prioritize_bottleneck_fixes(ctx.deps),
            "context7_insights": bottleneck_docs
        }

        return f"–ê–Ω–∞–ª–∏–∑ —É–∑–∫–∏—Ö –º–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n{json.dumps(bottlenecks, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —É–∑–∫–∏—Ö –º–µ—Å—Ç: {e}"


async def generate_optimization_plan(
    ctx: RunContext[PerformanceOptimizationDependencies],
    project_path: str,
    target_metrics: Dict[str, Any] = None
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ Context7 –∞–Ω–∞–ª–∏–∑–∞.

    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        target_metrics: –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

    Returns:
        –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return "Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ dependencies –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã
        if target_metrics is None:
            target_metrics = {
                "response_time_ms": ctx.deps.target_response_time_ms,
                "throughput_rps": ctx.deps.target_throughput_rps,
                "error_rate": ctx.deps.target_error_rate,
                "cpu_usage": ctx.deps.target_cpu_usage,
                "memory_usage": ctx.deps.target_memory_usage
            }

        # –ü–æ–ª—É—á–∞–µ–º –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Context7
        optimization_docs = await get_library_docs_context7(
            ctx,
            f"/{ctx.deps.framework}/docs",
            f"optimization guide performance tuning {ctx.deps.domain_type}",
            10000
        )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        current_analysis = await analyze_project_context(ctx, project_path)
        bottlenecks = await identify_bottlenecks(ctx, project_path, "deep")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–ª–∞–Ω
        optimization_plan = {
            "target_metrics": target_metrics,
            "current_state": current_analysis,
            "identified_bottlenecks": bottlenecks,
            "optimization_strategy": ctx.deps.get_optimization_strategy_config(),
            "context7_recommendations": optimization_docs,
            "implementation_phases": _generate_implementation_phases(ctx.deps, target_metrics),
            "success_criteria": _define_success_criteria(target_metrics),
            "monitoring_plan": ctx.deps.get_monitoring_config()
        }

        return f"–ü–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n{json.dumps(optimization_plan, indent=2, ensure_ascii=False)}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}"


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è Context7 –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

def _generate_context7_recommendations(
    deps: PerformanceOptimizationDependencies,
    framework: str,
    project_analysis: Dict[str, Any]
) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ Context7 –∞–Ω–∞–ª–∏–∑–∞."""
    recommendations = []

    # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞
    framework_recommendations = {
        "react": [
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å React.memo –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ª–∏—à–Ω–∏—Ö —Ä–µ–Ω–¥–µ—Ä–æ–≤",
            "–ü—Ä–∏–º–µ–Ω–∏—Ç—å code splitting —Å React.lazy",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å useMemo –∏ useCallback"
        ],
        "vue": [
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å v-memo –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞",
            "–ü—Ä–∏–º–µ–Ω–∏—Ç—å async components –¥–ª—è code splitting",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å computed properties"
        ],
        "nextjs": [
            "–í–∫–ª—é—á–∏—Ç—å Image Optimization —Å next/image",
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Static Generation –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å bundle —Å Bundle Analyzer"
        ]
    }

    recommendations.extend(framework_recommendations.get(framework, []))

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞
    if project_analysis.get("total_files", 0) > 1000:
        recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã")

    if project_analysis.get("large_files"):
        recommendations.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –∏–ª–∏ —Ä–∞–∑–±–∏—Ç—å –∏—Ö")

    return recommendations


async def _analyze_code_patterns(
    project_path: str,
    deps: PerformanceOptimizationDependencies
) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫–æ–¥–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    patterns = {
        "performance_patterns": [],
        "anti_patterns": [],
        "optimization_opportunities": []
    }

    try:
        # –ü–æ–∏—Å–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞
        if deps.framework == "react":
            patterns["performance_patterns"].extend([
                "React.memo usage", "useMemo optimization", "useCallback optimization"
            ])
            patterns["anti_patterns"].extend([
                "Inline object creation in render", "Missing key props", "Large component trees"
            ])

        elif deps.framework == "vue":
            patterns["performance_patterns"].extend([
                "Computed properties", "v-memo directive", "Async components"
            ])
            patterns["anti_patterns"].extend([
                "Deep watchers", "Large template expressions", "Reactive large objects"
            ])

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        patterns["optimization_opportunities"].extend([
            "Bundle size optimization", "Image optimization", "Cache implementation"
        ])

    except Exception as e:
        patterns["error"] = str(e)

    return patterns


def _calculate_performance_score(code_analysis: Dict[str, Any]) -> float:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞."""
    base_score = 100.0

    # –°–Ω–∏–∂–∞–µ–º –æ—Ü–µ–Ω–∫—É –∑–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ anti-patterns
    anti_patterns_count = len(code_analysis.get("anti_patterns", []))
    base_score -= anti_patterns_count * 10

    # –ü–æ–≤—ã—à–∞–µ–º –æ—Ü–µ–Ω–∫—É –∑–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ performance patterns
    performance_patterns_count = len(code_analysis.get("performance_patterns", []))
    base_score += performance_patterns_count * 5

    return max(0.0, min(100.0, base_score))


def _generate_pattern_improvements(
    code_analysis: Dict[str, Any],
    patterns_analysis: Dict[str, Any]
) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."""
    improvements = []

    # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö anti-patterns
    for anti_pattern in code_analysis.get("anti_patterns", []):
        if "inline object" in anti_pattern.lower():
            improvements.append("–í—ã–Ω–µ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç—ã –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Ä–µ–Ω–¥–µ—Ä —Ñ—É–Ω–∫—Ü–∏–π")
        elif "missing key" in anti_pattern.lower():
            improvements.append("–î–æ–±–∞–≤–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ key props –¥–ª—è —Å–ø–∏—Å–∫–æ–≤")

    # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ optimization opportunities
    for opportunity in code_analysis.get("optimization_opportunities", []):
        if "bundle size" in opportunity.lower():
            improvements.append("–ü—Ä–∏–º–µ–Ω–∏—Ç—å tree shaking –∏ code splitting")
        elif "image" in opportunity.lower():
            improvements.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (WebP, lazy loading)")

    return improvements


def _identify_system_bottlenecks(
    system_analysis: Dict[str, Any],
    deps: PerformanceOptimizationDependencies
) -> List[str]:
    """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —É–∑–∫–∏—Ö –º–µ—Å—Ç."""
    bottlenecks = []

    cpu_percent = system_analysis.get("cpu", {}).get("percent", 0)
    memory_percent = system_analysis.get("memory", {}).get("percent", 0)
    disk_percent = system_analysis.get("disk", {}).get("percent", 0)

    if cpu_percent > deps.target_cpu_usage * 100:
        bottlenecks.append(f"–í—ã—Å–æ–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CPU: {cpu_percent}%")

    if memory_percent > deps.target_memory_usage * 100:
        bottlenecks.append(f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_percent}%")

    if disk_percent > 90:
        bottlenecks.append(f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞: {disk_percent}%")

    return bottlenecks


def _identify_code_bottlenecks(
    project_path: str,
    deps: PerformanceOptimizationDependencies
) -> List[str]:
    """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç –≤ –∫–æ–¥–µ."""
    bottlenecks = []

    try:
        # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É–∑–∫–∏—Ö –º–µ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞
        for root, dirs, files in os.walk(project_path):
            for file in files:
                if file.endswith(('.js', '.jsx', '.ts', '.tsx', '.py')):
                    file_path = os.path.join(root, file)
                    file_size = os.path.getsize(file_path)

                    # –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å —É–∑–∫–∏–º –º–µ—Å—Ç–æ–º
                    if file_size > 100 * 1024:  # > 100KB
                        bottlenecks.append(f"–ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª: {file} ({file_size // 1024}KB)")

    except Exception as e:
        bottlenecks.append(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞: {e}")

    return bottlenecks


def _extract_framework_bottlenecks(bottleneck_docs: str) -> List[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É–∑–∫–∏—Ö –º–µ—Å—Ç–∞—Ö —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
    # –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
    bottlenecks = [
        "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —É–∑–∫–∏—Ö –º–µ—Å—Ç",
        "–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Context7 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
    ]

    if "bundle" in bottleneck_docs.lower():
        bottlenecks.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä bundle")

    if "rendering" in bottleneck_docs.lower():
        bottlenecks.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞")

    return bottlenecks


def _prioritize_bottleneck_fixes(deps: PerformanceOptimizationDependencies) -> List[Dict[str, Any]]:
    """–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π —É–∑–∫–∏—Ö –º–µ—Å—Ç."""
    fixes = []

    if deps.optimization_strategy == "speed":
        fixes.extend([
            {"priority": "high", "fix": "Cache optimization", "impact": "response_time"},
            {"priority": "medium", "fix": "Bundle optimization", "impact": "load_time"}
        ])
    elif deps.optimization_strategy == "memory":
        fixes.extend([
            {"priority": "high", "fix": "Memory leak detection", "impact": "memory_usage"},
            {"priority": "medium", "fix": "Object pooling", "impact": "gc_pressure"}
        ])

    return fixes


def _generate_implementation_phases(
    deps: PerformanceOptimizationDependencies,
    target_metrics: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∞–∑ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
    phases = [
        {
            "phase": 1,
            "name": "–ê–Ω–∞–ª–∏–∑ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "duration_days": 3,
            "tasks": [
                "–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è",
                "–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —É–∑–∫–∏—Ö –º–µ—Å—Ç",
                "–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π"
            ]
        },
        {
            "phase": 2,
            "name": "–ë—ã—Å—Ç—Ä—ã–µ –ø–æ–±–µ–¥—ã",
            "duration_days": 5,
            "tasks": [
                "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
                "–í–∫–ª—é—á–µ–Ω–∏–µ —Å–∂–∞—Ç–∏—è",
                "–ë–∞–∑–æ–≤–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ"
            ]
        },
        {
            "phase": 3,
            "name": "–ì–ª—É–±–æ–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è",
            "duration_days": 10,
            "tasks": [
                "Code splitting",
                "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î",
                "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"
            ]
        }
    ]

    return phases


def _define_success_criteria(target_metrics: Dict[str, Any]) -> Dict[str, Any]:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ —É—Å–ø–µ—Ö–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
    return {
        "performance_targets": target_metrics,
        "improvement_thresholds": {
            "response_time": "20% improvement",
            "throughput": "30% improvement",
            "error_rate": "50% reduction"
        },
        "monitoring_requirements": [
            "Real-time performance dashboards",
            "Automated alerting for regressions",
            "Regular performance reports"
        ]
    }


# –ù–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Context7 MCP

async def search_performance_knowledge_context7(
    ctx: RunContext[PerformanceOptimizationDependencies],
    query: str,
    domain_type: str = None
) -> str:
    """
    –ü–æ–∏—Å–∫ –∑–Ω–∞–Ω–∏–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Context7 MCP.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Context7 –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ best practices
    –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        domain_type: –¢–∏–ø –¥–æ–º–µ–Ω–∞ (web, api, database, frontend, etc.)

    Returns:
        –ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return "Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ReadMcpResourceTool –¥–ª—è Context7
            from claude_tools import ReadMcpResourceTool

            # –ü–æ–∏—Å–∫ —Ä–µ—Å—É—Ä—Å–æ–≤ Context7
            search_query = f"{query} {domain_type or ctx.deps.domain_type} performance optimization"

            # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Context7 —á–µ—Ä–µ–∑ MCP
            # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

        except (ImportError, AttributeError):
            pass

        # Fallback –∫ —É–ª—É—á—à–µ–Ω–Ω–æ–º—É –ø–æ–∏—Å–∫—É —á–µ—Ä–µ–∑ Context7
        framework = ctx.deps.framework
        performance_type = ctx.deps.performance_type

        # –ü–æ–ª—É—á–∞–µ–º Context7 ID –¥–ª—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞
        library_id = await resolve_library_id_context7(ctx, framework)

        if "Context7 ID" not in library_id:
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å Context7 ID –¥–ª—è {framework}: {library_id}"

        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ –æ—Ç–≤–µ—Ç–∞
        context7_id = library_id.split("Context7 ID –¥–ª—è")[1].split(":")[1].strip().split()[0]

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_docs = await get_library_docs_context7(
            ctx, context7_id, f"{query} performance {performance_type}", 3000
        )

        return f"""
üîç **–ü–æ–∏—Å–∫ –∑–Ω–∞–Ω–∏–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Context7:**

**–ó–∞–ø—Ä–æ—Å:** {query}
**–î–æ–º–µ–Ω:** {domain_type or ctx.deps.domain_type}
**–§—Ä–µ–π–º–≤–æ—Ä–∫:** {framework}

**–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**
{performance_docs}

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:**
- –ü—Ä–∏–º–µ–Ω–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è {framework}
- –£—á–µ—Å—Ç—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ {performance_type} –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –°–ª–µ–¥–æ–≤–∞—Ç—å best practices –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Context7
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ Context7: {e}"


async def get_performance_best_practices_context7(
    ctx: RunContext[PerformanceOptimizationDependencies],
    technology_stack: List[str] = None
) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å best practices –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Context7 MCP.

    Args:
        technology_stack: –°–ø–∏—Å–æ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

    Returns:
        Best practices –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return "Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    if not technology_stack:
        technology_stack = [ctx.deps.framework, ctx.deps.domain_type]

    try:
        best_practices = {}

        for tech in technology_stack:
            # –ü–æ–ª—É—á–∞–µ–º Context7 ID –¥–ª—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
            library_id_result = await resolve_library_id_context7(ctx, tech)

            if "Context7 ID" in library_id_result:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º ID
                context7_id = library_id_result.split(":")[1].strip().split()[0]

                # –ü–æ–ª—É—á–∞–µ–º best practices
                practices_docs = await get_library_docs_context7(
                    ctx, context7_id, "best practices performance optimization", 2000
                )

                best_practices[tech] = practices_docs

        return f"""
üìö **Best Practices –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (Context7):**

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫:** {', '.join(technology_stack)}
**–¢–∏–ø –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:** {ctx.deps.optimization_strategy}

{json.dumps(best_practices, indent=2, ensure_ascii=False)}

**–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –º–µ—Ç—Ä–∏–∫: {ctx.deps.get_performance_profile()['priority_metrics']}
- –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: {ctx.deps.get_performance_profile()['tools']}
- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏: {ctx.deps.get_performance_profile()['strategies']}
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è best practices —á–µ—Ä–µ–∑ Context7: {e}"


async def analyze_technology_performance_context7(
    ctx: RunContext[PerformanceOptimizationDependencies],
    project_path: str,
    specific_technology: str = None
) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —á–µ—Ä–µ–∑ Context7.

    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        specific_technology: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

    Returns:
        –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
    """
    if not ctx.deps.enable_context7_mcp:
        return "Context7 MCP –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

    technology = specific_technology or ctx.deps.framework

    try:
        # –ü–æ–ª—É—á–∞–µ–º Context7 –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        library_id_result = await resolve_library_id_context7(ctx, technology)

        if "Context7 ID" not in library_id_result:
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å Context7 ID –¥–ª—è {technology}: {library_id_result}"

        context7_id = library_id_result.split(":")[1].strip().split()[0]

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        project_analysis = await _analyze_project_structure(project_path)

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        tech_performance_docs = await get_library_docs_context7(
            ctx,
            context7_id,
            f"performance analysis {ctx.deps.performance_type} optimization",
            4000
        )

        return f"""
üî¨ **–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ {technology} —á–µ—Ä–µ–∑ Context7:**

**–ü—Ä–æ–µ–∫—Ç:** {project_path}
**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è:** {technology}
**–¢–∏–ø –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:** {ctx.deps.performance_type}

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:**
{json.dumps(project_analysis, indent=2, ensure_ascii=False)}

**Context7 –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
{tech_performance_docs}

**–°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è {technology}:**
{_generate_technology_specific_recommendations(technology, ctx.deps)}
"""

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —á–µ—Ä–µ–∑ Context7: {e}"


def _generate_technology_specific_recommendations(
    technology: str,
    deps: PerformanceOptimizationDependencies
) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏."""

    tech_recommendations = {
        "react": [
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å React.memo –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –Ω–µ–Ω—É–∂–Ω—ã—Ö —Ä–µ–Ω–¥–µ—Ä–æ–≤",
            "–ü—Ä–∏–º–µ–Ω—è—Ç—å code splitting —Å React.lazy",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é useMemo –∏ useCallback",
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å React DevTools Profiler –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        ],
        "vue": [
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å v-memo –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–µ–Ω–¥–µ—Ä–∞",
            "–ü—Ä–∏–º–µ–Ω—è—Ç—å async –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è code splitting",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å computed properties",
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Vue DevTools –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
        ],
        "fastapi": [
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å async/await –¥–ª—è –≤—Å–µ—Ö I/O –æ–ø–µ—Ä–∞—Ü–∏–π",
            "–ü—Ä–∏–º–µ–Ω—è—Ç—å dependency injection –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Pydantic models —Å Field –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π",
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å middleware –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ compression"
        ],
        "django": [
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å ORM –∑–∞–ø—Ä–æ—Å—ã —Å select_related/prefetch_related",
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å template caching –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
            "–ü—Ä–∏–º–µ–Ω—è—Ç—å database connection pooling",
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å static files –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é"
        ],
        "express": [
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å clustering –¥–ª—è –º–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤",
            "–ü—Ä–∏–º–µ–Ω—è—Ç—å compression middleware",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å async/await patterns",
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å connection pooling –¥–ª—è –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö"
        ]
    }

    recommendations = tech_recommendations.get(technology.lower(), [
        f"–ò–∑—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {technology}",
        "–ü—Ä–∏–º–µ–Ω–∏—Ç—å general performance best practices",
        "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç"
    ])

    # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    strategy_config = deps.get_optimization_strategy_config()
    priority = strategy_config["priority"]

    adapted_recommendations = []
    for rec in recommendations:
        adapted_recommendations.append(f"[{priority}] {rec}")

    return "\n".join(adapted_recommendations)