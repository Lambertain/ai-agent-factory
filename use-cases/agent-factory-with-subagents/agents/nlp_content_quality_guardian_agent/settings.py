"""
NLP Content Quality Guardian Agent Settings

–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ NLP –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
"""

from pydantic_settings import BaseSettings
from pydantic import Field, ConfigDict
from dotenv import load_dotenv
from typing import List, Dict, Any


class NLPQualityGuardianSettings(BaseSettings):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∏ NLP Content Quality Guardian Agent."""

    model_config = ConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="ignore"
    )

    # ===== CORE LLM SETTINGS =====
    llm_api_key: str = Field(..., description="API –∫–ª—é—á –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ LLM")
    llm_provider: str = Field(default="openai", description="–ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM")
    llm_base_url: str = Field(
        default="https://dashscope.aliyuncs.com/compatible-mode/v1",
        description="–ë–∞–∑–æ–≤—ã–π URL API"
    )

    # ===== COST-OPTIMIZED MODEL CONFIGURATION =====
    # Validation analysis - Premium Qwen for complex quality analysis
    llm_validation_model: str = Field(
        default="qwen2.5-72b-instruct",
        description="–ú–æ–¥–µ–ª—å –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞"
    )

    # Safety checking - Qwen Coder for pattern detection
    llm_safety_model: str = Field(
        default="qwen2.5-coder-32b-instruct",
        description="–ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
    )

    # Report generation - Ultra-cheap Gemini for text generation
    llm_reporting_model: str = Field(
        default="gemini-2.5-flash-lite",
        description="–ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤"
    )

    # Knowledge search - Gemini for semantic understanding
    llm_knowledge_model: str = Field(
        default="gemini-2.5-flash-lite",
        description="–ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–Ω–∞–Ω–∏–π"
    )

    # Alternative API Keys
    gemini_api_key: str = Field(..., description="Google Gemini API –∫–ª—é—á")
    openai_api_key: str = Field(default="", description="OpenAI API –∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")

    # ===== VALIDATION DOMAIN SETTINGS =====
    default_validation_domain: str = Field(default="universal", description="–î–æ–º–µ–Ω –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    default_content_type: str = Field(default="mixed_content", description="–¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")

    # Quality thresholds
    excellence_threshold: float = Field(default=90.0, description="–ü–æ—Ä–æ–≥ –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
    good_threshold: float = Field(default=70.0, description="–ü–æ—Ä–æ–≥ —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
    acceptable_threshold: float = Field(default=50.0, description="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ –ø—Ä–∏–µ–º–ª–µ–º—ã–π –ø–æ—Ä–æ–≥")

    # ===== PATTERNSHIFT METHODOLOGY VALIDATION =====
    # Test validation
    min_test_questions: int = Field(default=15, description="–ú–∏–Ω–∏–º—É–º –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ —Ç–µ—Å—Ç–∞—Ö")
    require_life_situations: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –∂–∏–∑–Ω–µ–Ω–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏")
    avoid_clinical_terms: bool = Field(default=True, description="–ò–∑–±–µ–≥–∞—Ç—å –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤")

    # Program structure validation
    require_three_level_structure: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å —Ç—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É")
    crisis_days: int = Field(default=21, description="–î–Ω–∏ –∫—Ä–∏–∑–∏—Å–Ω–æ–≥–æ —ç—Ç–∞–ø–∞")
    stabilization_days: int = Field(default=21, description="–î–Ω–∏ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏")
    development_days: int = Field(default=14, description="–î–Ω–∏ —Ä–∞–∑–≤–∏—Ç–∏—è")

    # VAK personalization
    require_vak_personalization: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å VAK –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é")
    require_multiformat_content: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –º—É–ª—å—Ç–∏—Ñ–æ—Ä–º–∞—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç")
    require_anti_repetition: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –∞–Ω—Ç–∏–ø–æ–≤—Ç–æ—Ä–Ω—É—é —Å–∏—Å—Ç–µ–º—É")

    # ===== NLP TECHNIQUES VALIDATION =====
    require_scientific_basis: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –Ω–∞—É—á–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ")
    require_ethical_safety: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å —ç—Ç–∏—á–µ—Å–∫—É—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å")
    require_informed_consent: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ")
    require_contraindications: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è")

    # Ericksonian patterns validation
    validate_ericksonian_principles: bool = Field(default=True, description="–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø—ã –≠—Ä–∏–∫—Å–æ–Ω–∞")
    require_utilization_approach: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –ø–æ–¥—Ö–æ–¥ utilization")
    require_indirect_methods: bool = Field(default=True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –Ω–µ–ø—Ä—è–º—ã–µ –º–µ—Ç–æ–¥—ã")

    # ===== SAFETY AND ETHICS SETTINGS =====
    enable_safety_scanning: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
    enable_ethics_validation: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é —ç—Ç–∏–∫–∏")

    # Critical flags sensitivity
    strict_safety_mode: bool = Field(default=True, description="–°—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
    auto_flag_manipulation: bool = Field(default=True, description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–º–µ—á–∞—Ç—å –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏")
    auto_flag_pseudoscience: bool = Field(default=True, description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–º–µ—á–∞—Ç—å –ø—Å–µ–≤–¥–æ–Ω–∞—É–∫—É")

    # Age appropriateness
    min_age_restriction: int = Field(default=16, description="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç")
    max_age_restriction: int = Field(default=80, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç")
    enable_age_validation: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤–æ–∑—Ä–∞—Å—Ç–∞")

    # ===== MULTILINGUAL AND CULTURAL SETTINGS =====
    primary_language: str = Field(default="ru", description="–û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫")
    supported_languages: List[str] = Field(
        default_factory=lambda: ["ru", "uk", "en"],
        description="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏"
    )
    enable_multilingual_validation: bool = Field(default=True, description="–ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è")
    enable_cultural_validation: bool = Field(default=True, description="–ö—É–ª—å—Ç—É—Ä–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è")

    # Cultural sensitivity
    cultural_contexts: List[str] = Field(
        default_factory=lambda: ["slavic", "western", "eastern"],
        description="–ö—É–ª—å—Ç—É—Ä–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã"
    )

    # ===== RAG AND KNOWLEDGE SETTINGS =====
    enable_knowledge_search: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –ø–æ–∏—Å–∫ –∑–Ω–∞–Ω–∏–π")
    knowledge_match_count: int = Field(default=5, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞")
    enable_pattern_matching: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω-–º–∞—Ç—á–∏–Ω–≥")

    # Archon integration
    archon_project_id: str = Field(
        default="c75ef8e3-6f4d-4da2-9e81-8d38d04a341a",
        description="ID –ø—Ä–æ–µ–∫—Ç–∞ Archon"
    )
    enable_archon_integration: bool = Field(default=True, description="–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Archon")
    enable_task_delegation: bool = Field(default=True, description="–î–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á")

    # ===== PERFORMANCE AND OPTIMIZATION =====
    validation_timeout_minutes: int = Field(default=10, description="–¢–∞–π–º–∞—É—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –º–∏–Ω—É—Ç–∞—Ö")
    max_content_length: int = Field(default=100000, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
    enable_parallel_validation: bool = Field(default=True, description="–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è")

    # Cost optimization
    enable_smart_routing: bool = Field(default=True, description="–£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π")
    gemini_use_batch_api: bool = Field(default=True, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Batch API Gemini")
    qwen_enable_context_cache: bool = Field(default=True, description="–ö—ç—à –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ Qwen")
    auto_compress_context: bool = Field(default=True, description="–ê–≤—Ç–æ—Å–∂–∞—Ç–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")

    # ===== REPORTING AND OUTPUT SETTINGS =====
    generate_detailed_reports: bool = Field(default=True, description="–î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã")
    include_improvement_suggestions: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
    include_examples_in_reports: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã")
    export_format: str = Field(default="markdown", description="–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞")

    # Report customization
    report_include_scores: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –±–∞–ª–ª—ã –≤ –æ—Ç—á–µ—Ç")
    report_include_metadata: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
    report_include_recommendations: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

    # ===== VALIDATION WORKFLOW SETTINGS =====
    enable_four_stage_process: bool = Field(default=True, description="4-—ç—Ç–∞–ø–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å")
    enable_progressive_validation: bool = Field(default=True, description="–ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è")
    enable_automated_checks: bool = Field(default=True, description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏")

    # Validation aspects
    validate_methodology_compliance: bool = Field(default=True, description="–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é")
    validate_psychological_correctness: bool = Field(default=True, description="–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å")
    validate_nlp_technique_quality: bool = Field(default=True, description="–ö–∞—á–µ—Å—Ç–≤–æ NLP —Ç–µ—Ö–Ω–∏–∫")
    validate_ethical_safety: bool = Field(default=True, description="–≠—Ç–∏—á–µ—Å–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å")
    validate_scientific_validity: bool = Field(default=True, description="–ù–∞—É—á–Ω–∞—è –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å")
    validate_cultural_sensitivity: bool = Field(default=True, description="–ö—É–ª—å—Ç—É—Ä–Ω–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")

    # ===== DEBUGGING AND MONITORING =====
    log_level: str = Field(default="INFO", description="–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è")
    enable_detailed_logging: bool = Field(default=True, description="–î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ")
    track_validation_metrics: bool = Field(default=True, description="–û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏")

    # Performance monitoring
    enable_performance_tracking: bool = Field(default=True, description="–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    max_validation_time_seconds: int = Field(default=300, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")

    # ===== RATE LIMITING =====
    max_requests_per_minute: int = Field(default=30, description="–ú–∞–∫—Å–∏–º—É–º –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É")
    enable_rate_limiting: bool = Field(default=True, description="–í–∫–ª—é—á–∏—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã")

    def get_model_for_task(self, task_type: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏."""
        model_mapping = {
            "validation": self.llm_validation_model,
            "safety": self.llm_safety_model,
            "reporting": self.llm_reporting_model,
            "knowledge": self.llm_knowledge_model
        }
        return model_mapping.get(task_type, self.llm_validation_model)

    def get_quality_thresholds(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Ä–æ–≥–∏ –∫–∞—á–µ—Å—Ç–≤–∞."""
        return {
            "excellent": self.excellence_threshold,
            "good": self.good_threshold,
            "acceptable": self.acceptable_threshold,
            "unacceptable": 0.0
        }

    def get_patternshift_requirements(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è PatternShift –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏."""
        return {
            "min_test_questions": self.min_test_questions,
            "require_life_situations": self.require_life_situations,
            "avoid_clinical_terms": self.avoid_clinical_terms,
            "require_three_level_structure": self.require_three_level_structure,
            "crisis_days": self.crisis_days,
            "stabilization_days": self.stabilization_days,
            "development_days": self.development_days,
            "require_vak_personalization": self.require_vak_personalization,
            "require_multiformat_content": self.require_multiformat_content,
            "require_anti_repetition": self.require_anti_repetition
        }

    def get_safety_requirements(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."""
        return {
            "enable_safety_scanning": self.enable_safety_scanning,
            "enable_ethics_validation": self.enable_ethics_validation,
            "strict_safety_mode": self.strict_safety_mode,
            "auto_flag_manipulation": self.auto_flag_manipulation,
            "auto_flag_pseudoscience": self.auto_flag_pseudoscience,
            "require_informed_consent": self.require_informed_consent,
            "require_contraindications": self.require_contraindications,
            "min_age_restriction": self.min_age_restriction,
            "max_age_restriction": self.max_age_restriction
        }

    def get_validation_config(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
        return {
            "quality_thresholds": self.get_quality_thresholds(),
            "patternshift_requirements": self.get_patternshift_requirements(),
            "safety_requirements": self.get_safety_requirements(),
            "languages": self.supported_languages,
            "cultural_contexts": self.cultural_contexts,
            "validation_aspects": {
                "methodology_compliance": self.validate_methodology_compliance,
                "psychological_correctness": self.validate_psychological_correctness,
                "nlp_technique_quality": self.validate_nlp_technique_quality,
                "ethical_safety": self.validate_ethical_safety,
                "scientific_validity": self.validate_scientific_validity,
                "cultural_sensitivity": self.validate_cultural_sensitivity
            }
        }


def load_settings() -> NLPQualityGuardianSettings:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≥–µ–Ω—Ç–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞."""
    load_dotenv()

    try:
        return NLPQualityGuardianSettings()
    except Exception as e:
        error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ NLP Quality Guardian: {e}"
        if "llm_api_key" in str(e).lower():
            error_msg += "\nüîë –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ LLM_API_KEY —É–∫–∞–∑–∞–Ω –≤ —Ñ–∞–π–ª–µ .env"
        if "gemini_api_key" in str(e).lower():
            error_msg += "\nüîë –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ GEMINI_API_KEY —É–∫–∞–∑–∞–Ω –≤ —Ñ–∞–π–ª–µ .env"
        raise ValueError(error_msg) from e


def get_domain_specific_settings(domain: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –¥–æ–º–µ–Ω–∞."""
    domain_configs = {
        "psychology": {
            "excellence_threshold": 85.0,  # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
            "require_scientific_basis": True,
            "strict_safety_mode": True,
            "enable_age_validation": True,
            "min_age_restriction": 16
        },
        "astrology": {
            "excellence_threshold": 75.0,
            "require_scientific_basis": False,  # –°–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞
            "enable_cultural_validation": True,
            "validate_cultural_sensitivity": True
        },
        "tarot": {
            "excellence_threshold": 75.0,
            "require_scientific_basis": False,
            "enable_cultural_validation": True,
            "validate_cultural_sensitivity": True
        },
        "numerology": {
            "excellence_threshold": 75.0,
            "require_scientific_basis": False,
            "enable_cultural_validation": True
        },
        "universal": {
            "excellence_threshold": 80.0,
            "require_scientific_basis": True,
            "enable_cultural_validation": True,
            "validate_cultural_sensitivity": True
        }
    }

    return domain_configs.get(domain, domain_configs["universal"])


def create_validation_settings_for_domain(
    domain: str,
    api_key: str,
    **overrides
) -> NLPQualityGuardianSettings:
    """–°–æ–∑–¥–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞."""
    base_settings = {
        "llm_api_key": api_key,
        "default_validation_domain": domain,
        **get_domain_specific_settings(domain),
        **overrides
    }

    # –í—Ä–µ–º–µ–Ω–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã
    import os
    for key, value in base_settings.items():
        env_key = key.upper()
        os.environ[env_key] = str(value)

    return NLPQualityGuardianSettings(**base_settings)